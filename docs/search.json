[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Renan Xavier Cortes",
    "section": "",
    "text": "Website\n  \n  \n    \n     E-mail\n  \n  \n    \n     Github\n  \n  \n    \n     LinkedIn\n  \n  \n     Lattes\n  \n\n  \n  \nEste é um Website do\nConstante Evolução\nConceitos Gerais de Probabilidade, Estatística e afins\nFalar que ao longo do site códigos serão abordados.. seguindo planos de ensino\nSinta-se livre para sugerir melhorias abrindo uma issue neste link\nEste é um website baseado no Quarto da empresa Posit.\n\nLinks interessantes que me inspiram e que podem te inspirar também\nTemplates de Quarto úteis do prof. Gang He\nSite da Disciplina de Probabilidade e Estatística EDA da UFRGS\nLivro de Estatística Básica do Prof. Filipe Zabala\nLivro R for Data Science\nSite do prof. André Zibetti\nLivro de Probabilidade de Leonardo T. Rolla e Bernardo N. B. de Lima\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre",
    "section": "",
    "text": "This is a Quarto website.\nTemplates úteis: https://drganghe.github.io/quarto-academic-site-examples.html\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\nTo add a plotly graph:\nytd library(plotly) fig &lt;- plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length) fig}"
  },
  {
    "objectID": "LGN.html",
    "href": "LGN.html",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "Este é uma página da LGN."
  },
  {
    "objectID": "TCL.html",
    "href": "TCL.html",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Este é uma página do TCL."
  },
  {
    "objectID": "Probabilidade/TCL.html",
    "href": "Probabilidade/TCL.html",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "O Teorema Central do Limite (TCL) é um dos resultados mais famosos e mais bonitos da Teoria da Probabilidade.\nSejam \\(X_1, X_2, ...\\) variáveis aleatórias independentes e identicamente distribuídas (\\(iid\\)) com média e variância existentes e finitas, isto é \\(-\\infty &lt; \\mu &lt; +\\infty\\) e \\(0 &lt; \\sigma^2 &lt; +\\infty\\).\nAlém disso, defina \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n}\\) como sendo a média amostral.\nPela Lei dos Grandes Números, sabemos que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\), mas a qual taxa? Como que é a distribuição dessa quantidade?\n\n\nDefinição. Sejam \\(X, X_1, X_2, ...\\) variáveis aleatórias com, respectivamente, funções de distribuições \\(F, F_1, F_2, ...\\). Dizemos que \\(X_n\\) converge em distribuição para \\(X\\), quando \\(n \\rightarrow +\\infty\\), se \\(F_n(x) \\rightarrow F(x)\\) para todo \\(x\\) ponto de continuidade de \\(F\\).\nNotação: \\(X_n \\xrightarrow{D} X\\) ou \\(X_n \\xrightarrow{D} F\\).\n\n\n\nPodemos reescrever a quantidade da introdução como sendo \\(\\bar{X} - \\mu \\xrightarrow{n \\rightarrow + \\infty} 0\\). Assim, uma das maneiras de buscar entender a distribuição de uma quantidade quando ela vai zero é multiplicá-la por uma quantidade que vai para infinito de uma maneira que seu valor de convergência não “exploda” (ou “degenere”) para o infinito e nem para zero. De fato se multiplicarmos a quantidade acima por \\(n\\) elevando-o à um exponencial buscando controlar as taxas de convergência. Neste caso, o exponencial é o valor de \\(\\frac{1}{2}\\), ou seja, \\(\\sqrt{n}\\).1\nLogo, o TCL pode ser definido por:\n\\(\\sqrt{n} \\left(\\bar{X} - \\mu \\right) \\xrightarrow{n \\rightarrow + \\infty} N(0, \\sigma^{2})\\) em distribuição\nOu, alternativamente, na sua forma mais popular:\n\\[\n\\sqrt{n} \\left(\\frac{\\bar{X} - \\mu}{\\sigma} \\right) \\xrightarrow{D} N(0, 1)\n\\tag{1}\\]\nO TCL retrata um dos teoremas mais lindos de toda a probabilidade tendo em vista que com poucas condições iniciais (neste caso, média e variância finitas) conseguimos provar que a média amostral \\(\\bar{X}\\) padronizada converge em distribuição para a distribuição normal padrão. Observe que o teorema não faz nenhuma alusão ao tipo de variável aleatória, podendo ser discreto ou contínuo, e nem sobre o suporte da distribuição, podendo ser positivo, negativo ou ambos.\nEste teorema é um dos principais motivos pela ampla difusão da distribuição Normal em diversas áreas do conhecimento científico. Tendo em vista que, dadas às devidas condições, a média amostral pode ser aproximada pela distribuição normal padrão, as aplicações desses resultados são diversos.\nProva. Faça \\(S_n = X_1 + X_2 + ... +X_n\\) e multiplicando e dividindo por \\(n\\) o termo da Equação 1 chegamos em\n\\[\n\\frac{1}{\\sqrt{n}}\\left(\\frac{S_n - n\\mu}{\\sigma} \\right) = \\frac{1}{\\sqrt{n}}\\left(\\frac{\\sum_{i=1}^nX_i- n\\mu}{\\sigma} \\right) \\overset{\\text{Expandindo o somatório}}{=} \\frac{1}{\\sqrt{n}}\\sum_{i=1}^n\\left(\\frac{X_i- \\mu}{\\sigma} \\right) \\xrightarrow{D} N(0, 1)\n\\]\nPodemos assumir, sem perda de generalidade que \\(\\mu = 0\\) e \\(\\sigma = 1\\), pois poderíamos fazer a prova definindo uma variável aleatória sendo \\(Z_i = \\frac{X_i- \\mu}{\\sigma}\\), onde esta variável teria média 0 e desvio padrão 1. Sendo assim, basta provar\n\\[\\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}} \\xrightarrow{D} N(0, 1)\\]\nPara isso, faremos o uso da função geradora de momentos (\\(M\\)) da quantidade acima e avaliando o seu valor quanto \\(n \\rightarrow +\\infty\\) a fim de identificar qual a distribuição limite obtida.2 Ou seja:\n\\(M_{X_n}(x) \\xrightarrow{n \\rightarrow + \\infty} M_{X}(x) \\implies X_n \\xrightarrow{D} X\\)\nPor notação, vamos estabelecer \\(Q_n = \\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}}\\) e aplicar o teorema acima:\n\\(M_{Q_n}(t) = E\\left( e^{t\\left(\\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}}\\right)} \\right) \\overset{\\text{Prop. de Exponencial}}{=} E\\left( e^{\\frac{tX_1}{\\sqrt{n}}} \\times e^{\\frac{tX_2}{\\sqrt{n}}} \\times \\dots \\times e^{\\frac{tX_n}{\\sqrt{n}}} \\right) \\overset{\\text{Independência}}{=} \\prod_{i=1}^{n}E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right)\\)\nComo todos os \\(X_i\\) são identicamente distribuídos, podemos simplificar a expressão para:\n\\(M_{Q_n}(t) = \\prod_{i=1}^{n}E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right) = E\\left( e^{\\frac{tX_1}{\\sqrt{n}}} \\right) \\times E\\left( e^{\\frac{tX_2}{\\sqrt{n}}} \\right) \\times \\dots \\times E\\left( e^{\\frac{tX_n}{\\sqrt{n}}} \\right) = \\left( E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right) \\right)^n, \\ \\forall i\\)\nNo entanto, note acima que \\(E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right)\\) é exatamente a função geradora de momentos aplicada no ponto \\(\\frac{t}{\\sqrt{n}}\\). Logo:\n\\(M_{Q_n}(t) = \\left( M_{X_i}\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n, \\ \\forall i\\)\nPor simplificação de notação, vamos suprimir o \\(X_i\\)3 nos passos seguintes e vamos avaliar esta expressão quando \\(n \\rightarrow +\\infty\\).\nObserve que da maneira como está estruturado \\(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n\\) converge para uma indefinição do tipo \\(1^\\infty\\), pois \\(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n = \\left( E\\left( e^{\\frac{tX}{\\sqrt{n}}} \\right) \\right)^n \\rightarrow \\left( E\\left( e^0 \\right) \\right)^\\infty\\).\nPara tratar essa indefinição, aplicaremos o logaritmo natural (\\(log\\)) na expressão e, depois de avaliado o limite, podemos reverter o valor aplicando o exponencial. Logo,\n\\[log\\left(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n \\right) = n\\times log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)\\]\nQuando aplicamos \\(n \\rightarrow +\\infty\\) caímos numa indefinição do tipo \\(+\\infty \\times 0\\), logo vamos reescrever a equação para \\(n\\times log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right) = \\frac{log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)}{\\frac{1}{n}}\\) e, desta maneira, caírmos numa indefinição do tipo \\(\\frac{0}{0}\\) para aplicarmos l’Hôpital. Como o \\(n\\) é um número inteiro natural e para melhor tratativa algébrica, vamos fazer uma transforção de variável para facilitar o desenvolvimento e poder aplicar a derivada em um número real. Assim,\n\\[\n\\lim_{n\\to\\infty}\\frac{log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)}{\\frac{1}{n}} \\overset{y=\\frac{1}{\\sqrt{n}}, \\ y \\in \\mathbb{R} }{=} \\lim_{y\\to 0}\\frac{log\\left( M\\left( yt \\right) \\right)}{y^2}\n\\]\nQue é uma indefinição do tipo \\(\\frac{0}{0}\\). Logo, aplicando l’Hôpital:4\n\\[\n\\lim_{y\\to 0}\\frac{tM'(yt)}{M(yt)}\\frac{1}{2y}\n\\]\nEste limite continua sendo uma indefinição do tipo \\(\\frac{0}{0}\\), porque pela definição da função geradora do momento, quando aplicamos as suposições no ponto \\(t=0\\) temos:\n\\[\n\\begin{aligned}\nM(t) = E\\left(e^{tX}\\right) \\implies M(0) = 1 \\\\\n\\mu = 0 \\implies M'(0) = 0 \\\\\n\\sigma^2 = 1 \\implies M''(0) = 1\n\\end{aligned}\n\\] Logo, simplificando os limites e aplicando l’Hôpital novamente temos:\n\\[\n\\lim_{y\\to 0}\\frac{tM'(yt)}{M(yt)}\\frac{1}{2y} \\overset{\\lim_{y\\to 0}{M(yt)}=1}{=} \\lim_{y\\to 0}\\frac{tM'(yt)}{2y} = \\lim_{y\\to 0}\\frac{t^2M''(yt)}{2} = \\frac{t^2}{2} \\lim_{y\\to 0}M''(yt) = \\frac{t^2}{2}\n\\]\nAplicando o exponencial para reverter o logaritmo aplicado originalmente temos:\n\\[M_{Q_n}(t) \\xrightarrow{n \\rightarrow +\\infty} e^{\\frac{t^2}{2}}\\]\nQue coindide com a função geradora de momentos da Normal Padrão.\n\\(\\square\\)\nUma discussão mais aprofundada do Teorema Central do Limite pode ser encontrada no Capítulo 7 de James (2023) ou no Capítulo 6 de DeGroot e Schervish (2012).\n\n\n\nFazendo \\(S_n = X_1 + X_2 + ... +X_n\\), James (2023) trata o problema central do limite atavés do estudo da convergência em distribuição das somas parciais normalizadas e formula o TCL como sendo:\n\\[\\frac{{S}_n - E({S}_n)}{\\sqrt{Var(S_n)}} \\xrightarrow{D} N(0, 1)\\]\nOutras maneiras de representar o TCL são:\n\\[\\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}} \\xrightarrow{D} N(0, 1)\\]\n\\[\\sqrt{n} \\bar{X} \\xrightarrow{D} N(\\mu, \\sigma^2)\\]\n\n\n\nSe \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(S_n = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\).\nA seguir, apresentamos a distribuição da quantidade:\n\\[\\frac{{S}_n - E({S}_n)}{\\sqrt{Var(S_n)}} = \\frac{{S}_n - np}{\\sqrt{np(1-p)}} \\xrightarrow{D} N(0, 1)\\]\nNo R:\n\n\nMostrar Código\nlibrary(ggplot2)\n\nset.seed(123)\n\n# Parâmetros\nn_simulacoes &lt;- 1000 # Número de Simulações\nn_lancamentos &lt;- 300 # Número de lançamentos por simulação\nprob_cara &lt;- 0.5     # Probabilidade de sair cara\n\n# Simulação\nSn &lt;- replicate(n_simulacoes, {\n  \n  lancamentos &lt;- sample(c(0,1), n_lancamentos, replace = TRUE, prob = c(1 - prob_cara, prob_cara))\n  sum(lancamentos)\n  \n})\n\n# Valores Normal Padrão\nvalores_pad &lt;- (Sn - n_lancamentos * prob_cara) / sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Dados para o gráfico\ndados &lt;- data.frame(valores = valores_pad)\n\n# Valores Teóricos\nmedia_pop &lt;- 0\ndesvio_padrao_pop &lt;- 1\n\n# Gráfico\nggplot(dados, aes(x = valores)) +\n  geom_histogram(aes(y = ..density..), fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  stat_function(fun = dnorm, args = list(mean = media_pop, sd = desvio_padrao_pop), col = \"red\", size = 1) +\n  labs(title = \"Teorema Central do Limite - Moeda Honesta\",\n       x = \"Média Padronizada dos Lançamentos\",\n       y = \"Densidade\")\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Parâmetros\nn_simulacoes = 1000  # Número de Simulações\nn_lancamentos = 300  # Número de lançamentos por simulação\nprob_cara = 0.5      # Probabilidade de sair cara\n\n# Simulação\nSn = np.array([\n    np.sum(np.random.choice([0, 1], size=n_lancamentos, p=[1 - prob_cara, prob_cara]))\n    for _ in range(n_simulacoes)\n])\n\n# Valores Normal Padrão\nvalores_pad = (Sn - n_lancamentos * prob_cara) / np.sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Valores Teóricos\nmedia_pop = 0\ndesvio_padrao_pop = 1\n\n# Gráfico\nplt.figure(figsize=(6, 4))\ncount, bins, ignored = plt.hist(valores_pad, bins=30, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n\n# Curva Teórica Normal Padrão\nx = np.linspace(min(bins), max(bins), 1000)\nplt.plot(x, norm.pdf(x, media_pop, desvio_padrao_pop), color='red', lw=2, label='Normal(0,1)')\n\n# Labels e Título\nplt.title(\"Teorema Central do Limite - Moeda Honesta\")\nplt.xlabel(\"Média Padronizada dos Lançamentos\")\nplt.ylabel(\"Densidade\")\nplt.legend()\n\n# Exibir\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nEsta aproximação, também conhecida como Teorema de De Moivre–Laplace, ilustra como o TCL pode ser usado para aproximar a distribuição discreta Binomial pela distribuição contínua Normal.\nLembrando que se \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(X = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\) (pela notação, \\(X = S_n\\) do exemplo computacional anterior) e queremos calcular a probabilidade da variável aleatória \\(X\\) estar entre dois valores inteiros \\(a\\) e \\(b\\) o que pode ser computacionalmente intenso. Nesse sentido, vamos aproximar essa probabilidade através do TCL usando o fato de que \\(\\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}} \\xrightarrow{D} N(0, 1)\\):\n\\[\nP(a \\le X \\le b) = P\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\le \\frac{X-np}{\\sqrt{np(1-p)}} \\le \\frac{b-np}{\\sqrt{np(1-p)}} \\right) \\approx \\Phi\\left( \\frac{b-np}{\\sqrt{np(1-p)}} \\right) - \\Phi\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\right)\n\\]\nEsta expressão representa a diferença das distribuição acumuladas da Normal Padrão entre os pontos \\(\\frac{b-np}{\\sqrt{np(1-p)}}\\) e \\(\\frac{a-np}{\\sqrt{np(1-p)}}\\).\n\n\nObserve que esta aproximação se mostra útil, no entanto temos que ter um cuidado adicional ao aproximarmos distribuições contínuas de discretas para evitarmos conclusões equivocadas. Por exemplo, suponha que gostaríamos de usar esta aproximação para calcular a probabilidade de a variável assumir um ponto específico \\(a\\), então podemos concluir, erroneamente, que:\n\\[P(X = a) = P(a \\le X \\le a) \\neq \\Phi(a) - \\Phi(a) = 0, \\ \\forall a\\]\nLogo, podemos melhorar essa aproximação de probabilidade através de uma especificação de um intervalo contínuo no entorno do valor \\(a\\):\n\\[P(X=a) \\overset{a \\ é \\ inteiro!}{=} P\\left( a - \\frac{1}{2} \\lt X \\lt a + \\frac{1}{2} \\right) \\approx \\Phi\\left( a - \\frac{1}{2} \\right) - \\Phi\\left( a + \\frac{1}{2} \\right)\\]",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html",
    "href": "Probabilidade/LGN.html",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei dos Grandes Números (LGN) é um dos resultados mais famosos da Teoria da Probabilidade.\nSejam \\(X_1, X_2, ...\\) variáveis aleatórias independentes e identicamente distribuídas (\\(iid\\)) com média e variância existentes e finitas, isto é \\(-\\infty &lt; \\mu &lt; +\\infty\\) e \\(0 &lt; \\sigma^2 &lt; +\\infty\\).\nAlém disso, defina \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n}\\) como sendo a média amostral.\n\n\nA Lei Forte estabelece que a média amostral converge para \\(\\mu\\) no infinito com probabilidade 1. Ou seja, \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\[P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória (a média amostral) para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).\n\\(\\square\\)\n\n\n\nA Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\[P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\[\n\\begin{align*}\nP\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\\\\n= \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\n\\end{align*}\n\\]\n\\(\\square\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).\n\n\n\nÉ intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\[Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\]\nentão,\n\\[Lei\\ Forte \\implies Lei\\ Fraca\\]\nO contrário não vale para nenhuma das duas afirmativas acima.\n\n\n\nSuponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\[X_i \\overset{iid}{\\sim}Bernoulli(p)\\]\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\[\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\]\nEste resultado mostra que a medida que ao jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy.\n\n\n\nNo R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(6, 4))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#seção-2",
    "href": "Probabilidade/LGN.html#seção-2",
    "title": "Lei dos Grandes Números",
    "section": "Seção 2",
    "text": "Seção 2\nColocando uma equação:\n\\(E = mc^2\\)\nE colocando um ggplot2:\n\n\nMostrar Código\n# Definindo parâmetros\nset.seed(123)           # Para reprodutibilidade\nn_lancamentos &lt;- 1000  # Número total de lançamentos\n\n# Simulando lançamentos: 1 representa \"cara\", 0 representa \"coroa\"\nresultados &lt;- sample(c(0, 1), size = n_lancamentos, replace = TRUE)\n\n# Calculando a média acumulada (frequência relativa de \"cara\")\nmedia_acumulada &lt;- cumsum(resultados) / (1:n_lancamentos)\n\n# Valor esperado teórico\nvalor_esperado &lt;- 0.5\n\n# Plotando o gráfico\nplot(media_acumulada, type = \"l\", col = \"blue\", lwd = 2,\n     xlab = \"Número de lançamentos\", ylab = \"Frequência relativa de 'cara'\",\n     main = \"Lei dos Grandes Números - Moeda Honesta\")\nabline(h = valor_esperado, col = \"red\", lty = 2, lwd = 2)\nlegend(\"bottomright\", legend = c(\"Frequência relativa\", \"Valor esperado (0.5)\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\n\n\n\n\n\n\n\n\n\n\nSeção 3\nEla tem também um table of contents.\nEste é uma página da LGN citando .\n\n\nLinks Úteis:\nAula de Harvard de Lei dos Grandes Números e Teorema Central do Limite\nPágina da Wikipedia da Lei dos Grandes Números",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#lei-forte-dos-grande-números",
    "href": "Probabilidade/LGN.html#lei-forte-dos-grande-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Forte estabelece que:\n\\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\(P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\)\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#lei-fraca-dos-grande-números",
    "href": "Probabilidade/LGN.html#lei-fraca-dos-grande-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\(P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\)\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\(P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#exemplo-computacional",
    "href": "Probabilidade/LGN.html#exemplo-computacional",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "No R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(6, 4))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#relação-entre-leis-e-convergências",
    "href": "Probabilidade/LGN.html#relação-entre-leis-e-convergências",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "É intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\[Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\]\nentão,\n\\[Lei\\ Forte \\implies Lei\\ Fraca\\]\nO contrário não vale para nenhuma das duas afirmativas acima.",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#exemplo-o-caso-bernoulli",
    "href": "Probabilidade/LGN.html#exemplo-o-caso-bernoulli",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "Suponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\[X_i \\overset{iid}{\\sim}Bernoulli(p)\\]\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\[\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\]\nEste resultado mostra que a medida que ao jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy.",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#lei-forte-dos-grandes-números",
    "href": "Probabilidade/LGN.html#lei-forte-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Forte estabelece que a média amostral converge para \\(\\mu\\) no infinito com probabilidade 1. Ou seja, \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\[P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória (a média amostral) para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).\n\\(\\square\\)",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#lei-fraca-dos-grandes-números",
    "href": "Probabilidade/LGN.html#lei-fraca-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\[P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\[\n\\begin{align*}\nP\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\\\\n= \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\n\\end{align*}\n\\]\n\\(\\square\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/TCL.html#teorema-central-do-limite",
    "href": "Probabilidade/TCL.html#teorema-central-do-limite",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Podemos reescrever a quantidade da introdução como sendo \\(\\bar{X} - \\mu \\xrightarrow{n \\rightarrow + \\infty} 0\\). Assim, uma das maneiras de buscar entender a distribuição de uma quantidade quando ela vai zero é multiplicá-la por uma quantidade que vai para infinito de uma maneira que seu valor de convergência não “exploda” (ou “degenere”) para o infinito e nem para zero. De fato se multiplicarmos a quantidade acima por \\(n\\) elevando-o à um exponencial buscando controlar as taxas de convergência. Neste caso, o exponencial é o valor de \\(\\frac{1}{2}\\), ou seja, \\(\\sqrt{n}\\).1\nLogo, o TCL pode ser definido por:\n\\(\\sqrt{n} \\left(\\bar{X} - \\mu \\right) \\xrightarrow{n \\rightarrow + \\infty} N(0, \\sigma^{2})\\) em distribuição\nOu, alternativamente, na sua forma mais popular:\n\\[\n\\sqrt{n} \\left(\\frac{\\bar{X} - \\mu}{\\sigma} \\right) \\xrightarrow{D} N(0, 1)\n\\tag{1}\\]\nO TCL retrata um dos teoremas mais lindos de toda a probabilidade tendo em vista que com poucas condições iniciais (neste caso, média e variância finitas) conseguimos provar que a média amostral \\(\\bar{X}\\) padronizada converge em distribuição para a distribuição normal padrão. Observe que o teorema não faz nenhuma alusão ao tipo de variável aleatória, podendo ser discreto ou contínuo, e nem sobre o suporte da distribuição, podendo ser positivo, negativo ou ambos.\nEste teorema é um dos principais motivos pela ampla difusão da distribuição Normal em diversas áreas do conhecimento científico. Tendo em vista que, dadas às devidas condições, a média amostral pode ser aproximada pela distribuição normal padrão, as aplicações desses resultados são diversos.\nProva. Faça \\(S_n = X_1 + X_2 + ... +X_n\\) e multiplicando e dividindo por \\(n\\) o termo da Equação 1 chegamos em\n\\[\n\\frac{1}{\\sqrt{n}}\\left(\\frac{S_n - n\\mu}{\\sigma} \\right) = \\frac{1}{\\sqrt{n}}\\left(\\frac{\\sum_{i=1}^nX_i- n\\mu}{\\sigma} \\right) \\overset{\\text{Expandindo o somatório}}{=} \\frac{1}{\\sqrt{n}}\\sum_{i=1}^n\\left(\\frac{X_i- \\mu}{\\sigma} \\right) \\xrightarrow{D} N(0, 1)\n\\]\nPodemos assumir, sem perda de generalidade que \\(\\mu = 0\\) e \\(\\sigma = 1\\), pois poderíamos fazer a prova definindo uma variável aleatória sendo \\(Z_i = \\frac{X_i- \\mu}{\\sigma}\\), onde esta variável teria média 0 e desvio padrão 1. Sendo assim, basta provar\n\\[\\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}} \\xrightarrow{D} N(0, 1)\\]\nPara isso, faremos o uso da função geradora de momentos (\\(M\\)) da quantidade acima e avaliando o seu valor quanto \\(n \\rightarrow +\\infty\\) a fim de identificar qual a distribuição limite obtida.2 Ou seja:\n\\(M_{X_n}(x) \\xrightarrow{n \\rightarrow + \\infty} M_{X}(x) \\implies X_n \\xrightarrow{D} X\\)\nPor notação, vamos estabelecer \\(Q_n = \\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}}\\) e aplicar o teorema acima:\n\\(M_{Q_n}(t) = E\\left( e^{t\\left(\\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}}\\right)} \\right) \\overset{\\text{Prop. de Exponencial}}{=} E\\left( e^{\\frac{tX_1}{\\sqrt{n}}} \\times e^{\\frac{tX_2}{\\sqrt{n}}} \\times \\dots \\times e^{\\frac{tX_n}{\\sqrt{n}}} \\right) \\overset{\\text{Independência}}{=} \\prod_{i=1}^{n}E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right)\\)\nComo todos os \\(X_i\\) são identicamente distribuídos, podemos simplificar a expressão para:\n\\(M_{Q_n}(t) = \\prod_{i=1}^{n}E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right) = E\\left( e^{\\frac{tX_1}{\\sqrt{n}}} \\right) \\times E\\left( e^{\\frac{tX_2}{\\sqrt{n}}} \\right) \\times \\dots \\times E\\left( e^{\\frac{tX_n}{\\sqrt{n}}} \\right) = \\left( E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right) \\right)^n, \\ \\forall i\\)\nNo entanto, note acima que \\(E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right)\\) é exatamente a função geradora de momentos aplicada no ponto \\(\\frac{t}{\\sqrt{n}}\\). Logo:\n\\(M_{Q_n}(t) = \\left( M_{X_i}\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n, \\ \\forall i\\)\nPor simplificação de notação, vamos suprimir o \\(X_i\\)3 nos passos seguintes e vamos avaliar esta expressão quando \\(n \\rightarrow +\\infty\\).\nObserve que da maneira como está estruturado \\(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n\\) converge para uma indefinição do tipo \\(1^\\infty\\), pois \\(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n = \\left( E\\left( e^{\\frac{tX}{\\sqrt{n}}} \\right) \\right)^n \\rightarrow \\left( E\\left( e^0 \\right) \\right)^\\infty\\).\nPara tratar essa indefinição, aplicaremos o logaritmo natural (\\(log\\)) na expressão e, depois de avaliado o limite, podemos reverter o valor aplicando o exponencial. Logo,\n\\[log\\left(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n \\right) = n\\times log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)\\]\nQuando aplicamos \\(n \\rightarrow +\\infty\\) caímos numa indefinição do tipo \\(+\\infty \\times 0\\), logo vamos reescrever a equação para \\(n\\times log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right) = \\frac{log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)}{\\frac{1}{n}}\\) e, desta maneira, caírmos numa indefinição do tipo \\(\\frac{0}{0}\\) para aplicarmos l’Hôpital. Como o \\(n\\) é um número inteiro natural e para melhor tratativa algébrica, vamos fazer uma transforção de variável para facilitar o desenvolvimento e poder aplicar a derivada em um número real. Assim,\n\\[\n\\lim_{n\\to\\infty}\\frac{log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)}{\\frac{1}{n}} \\overset{y=\\frac{1}{\\sqrt{n}}, \\ y \\in \\mathbb{R} }{=} \\lim_{y\\to 0}\\frac{log\\left( M\\left( yt \\right) \\right)}{y^2}\n\\]\nQue é uma indefinição do tipo \\(\\frac{0}{0}\\). Logo, aplicando l’Hôpital:4\n\\[\n\\lim_{y\\to 0}\\frac{tM'(yt)}{M(yt)}\\frac{1}{2y}\n\\]\nEste limite continua sendo uma indefinição do tipo \\(\\frac{0}{0}\\), porque pela definição da função geradora do momento, quando aplicamos as suposições no ponto \\(t=0\\) temos:\n\\[\n\\begin{aligned}\nM(t) = E\\left(e^{tX}\\right) \\implies M(0) = 1 \\\\\n\\mu = 0 \\implies M'(0) = 0 \\\\\n\\sigma^2 = 1 \\implies M''(0) = 1\n\\end{aligned}\n\\] Logo, simplificando os limites e aplicando l’Hôpital novamente temos:\n\\[\n\\lim_{y\\to 0}\\frac{tM'(yt)}{M(yt)}\\frac{1}{2y} \\overset{\\lim_{y\\to 0}{M(yt)}=1}{=} \\lim_{y\\to 0}\\frac{tM'(yt)}{2y} = \\lim_{y\\to 0}\\frac{t^2M''(yt)}{2} = \\frac{t^2}{2} \\lim_{y\\to 0}M''(yt) = \\frac{t^2}{2}\n\\]\nAplicando o exponencial para reverter o logaritmo aplicado originalmente temos:\n\\[M_{Q_n}(t) \\xrightarrow{n \\rightarrow +\\infty} e^{\\frac{t^2}{2}}\\]\nQue coindide com a função geradora de momentos da Normal Padrão.\n\\(\\square\\)\nUma discussão mais aprofundada do Teorema Central do Limite pode ser encontrada no Capítulo 7 de James (2023) ou no Capítulo 6 de DeGroot e Schervish (2012).",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade/TCL.html#footnotes",
    "href": "Probabilidade/TCL.html#footnotes",
    "title": "Teorema Central do Limite",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nUma discussão sobre este fator de convergência é discutido aqui↩︎\nEste teorema é um caso particular do Teorema de Continuidade de Levy para funções características. Ele pode ser melhor detalhado em Curtiss (1942) ou aqui.↩︎\nMagalhães (2006) também realiza esta simplificação de notação em uma prova similar do TCL fazendo uso da Função Característica.↩︎\nLembrando que \\(\\frac{d\\log(f(x))}{dx} = \\frac{1}{f(x)} \\cdot \\frac{df(x)}{dx} = \\frac{f'(x)}{f(x)}\\)↩︎",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade/TCL.html#convergência-em-distribuição",
    "href": "Probabilidade/TCL.html#convergência-em-distribuição",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Definição. Sejam \\(X, X_1, X_2, ...\\) variáveis aleatórias com, respectivamente, funções de distribuições \\(F, F_1, F_2, ...\\). Dizemos que \\(X_n\\) converge em distribuição para \\(X\\), quando \\(n \\rightarrow +\\infty\\), se \\(F_n(x) \\rightarrow F(x)\\) para todo \\(x\\) ponto de continuidade de \\(F\\).\nNotação: \\(X_n \\xrightarrow{D} X\\) ou \\(X_n \\xrightarrow{D} F\\).",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade/TCL.html#usando-o-tcl-pra-aproximar-a-binomial-pela-normal",
    "href": "Probabilidade/TCL.html#usando-o-tcl-pra-aproximar-a-binomial-pela-normal",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Esta aproximação, também conhecida como Teorema de De Moivre–Laplace, ilustra como o TCL pode ser usado para aproximar a distribuição discreta Binomial pela distribuição contínua Normal.\nSeja \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(X = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\) e queremos calcular a probabilidade da variável aleatória \\(X\\) estar entre dois valores inteiros \\(a\\) e \\(b\\) o que pode ser computacionalmente intenso. Nesse sentido, vamos aproximar essa probabilidade através do TCL usando o fato de que \\(\\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}} \\xrightarrow{D} N(0, 1)\\):\n\\[\nP(a \\le X \\le b) = P\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\le \\frac{X-np}{\\sqrt{np(1-p)}} \\le \\frac{b-np}{\\sqrt{np(1-p)}} \\right) \\approx \\Phi\\left( \\frac{b-np}{\\sqrt{np(1-p)}} \\right) - \\Phi\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\right)\n\\]\nEsta expressão representa a diferença das distribuição acumuladas da Normal Padrão entre os pontos \\(\\frac{b-np}{\\sqrt{np(1-p)}}\\) e \\(\\frac{a-np}{\\sqrt{np(1-p)}}\\).\n\n\nObserve que esta aproximação se mostra útil, no entanto temos que ter um cuidado adicional ao aproximarmos distribuições contínuas de discretas para evitarmos conclusões equivocadas. Por exemplo, suponha que gostaríamos de usar esta aproximação para calcular a probabilidade de a variável assumir um ponto específico \\(a\\), então podemos concluir, erroneamente, que:\n\\(P(X = a) = P(a \\le X \\le a) \\neq \\Phi(a) - \\Phi(a) = 0, \\ \\forall a\\)\nLogo, podemos melhorar essa aproximação de probabilidade através de uma especificação de um intervalo contínuo no entorno do valor \\(a\\):\n\\(P(X=a) \\overset{a \\ é \\ inteiro!}{=} P\\left( a - \\frac{1}{2} \\lt X \\lt a + \\frac{1}{2} \\right) \\approx \\Phi\\left( a - \\frac{1}{2} \\right) - \\Phi\\left( a + \\frac{1}{2} \\right)\\)",
    "crumbs": [
      "Probabilidade",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade/TCL.html#diferentes-formulações-e-versões-do-tcl",
    "href": "Probabilidade/TCL.html#diferentes-formulações-e-versões-do-tcl",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Fazendo \\(S_n = X_1 + X_2 + ... +X_n\\), James (2023) trata o problema central do limite atavés do estudo da convergência em distribuição das somas parciais normalizadas e formula o TCL como sendo:\n\\[\\frac{{S}_n - E({S}_n)}{\\sqrt{Var(S_n)}} \\xrightarrow{D} N(0, 1)\\]\nOutras maneiras de representar o TCL são:\n\\[\\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}} \\xrightarrow{D} N(0, 1)\\]\n\\[\\sqrt{n} \\bar{X} \\xrightarrow{D} N(\\mu, \\sigma^2)\\]",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade/TCL.html#exemplo-computacional",
    "href": "Probabilidade/TCL.html#exemplo-computacional",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Lembrando que se \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(S_n = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\)\nA seguir, apresentamos a distribuição da quantidade:\n\\(\\frac{{S}_n - E({S}_n)}{\\sqrt{Var(S_n)}} = \\frac{{S}_n - np}{\\sqrt{np(1-p)}} \\xrightarrow{D} N(0, 1)\\).\nNo R:\n\n\nMostrar Código\nlibrary(ggplot2)\n\nset.seed(123)\n\n# Parâmetros\nn_simulacoes &lt;- 1000 # Número de Simulações\nn_lancamentos &lt;- 300 # Número de lançamentos por simulação\nprob_cara &lt;- 0.5     # Probabilidade de sair cara\n\n# Simulação\nSn &lt;- replicate(n_simulacoes, {\n  \n  lancamentos &lt;- sample(c(0,1), n_lancamentos, replace = TRUE, prob = c(1 - prob_cara, prob_cara))\n  sum(lancamentos)\n  \n})\n\n# Valores Normal Padrão\nvalores_pad &lt;- (Sn - n_lancamentos * prob_cara) / sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Dados para o gráfico\ndados &lt;- data.frame(valores = valores_pad)\n\n# Valores Teóricos\nmedia_pop &lt;- 0\ndesvio_padrao_pop &lt;- 1\n\n# Gráfico\nggplot(dados, aes(x = valores)) +\n  geom_histogram(aes(y = ..density..), fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  stat_function(fun = dnorm, args = list(mean = media_pop, sd = desvio_padrao_pop), col = \"red\", size = 1) +\n  labs(title = \"Teorema Central do Limite - Moeda Honesta\",\n       x = \"Média Padronizada dos Lançamentos\",\n       y = \"Densidade\")\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Parâmetros\nn_simulacoes = 1000  # Número de Simulações\nn_lancamentos = 300  # Número de lançamentos por simulação\nprob_cara = 0.5      # Probabilidade de sair cara\n\n# Simulação\nSn = np.array([\n    np.sum(np.random.choice([0, 1], size=n_lancamentos, p=[1 - prob_cara, prob_cara]))\n    for _ in range(n_simulacoes)\n])\n\n# Valores Normal Padrão\nvalores_pad = (Sn - n_lancamentos * prob_cara) / np.sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Valores Teóricos\nmedia_pop = 0\ndesvio_padrao_pop = 1\n\n# Gráfico\nplt.figure(figsize=(10, 6))\ncount, bins, ignored = plt.hist(valores_pad, bins=30, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n\n# Curva Teórica Normal Padrão\nx = np.linspace(min(bins), max(bins), 1000)\nplt.plot(x, norm.pdf(x, media_pop, desvio_padrao_pop), color='red', lw=2, label='Normal(0,1)')\n\n# Labels e Título\nplt.title(\"Teorema Central do Limite - Moeda Honesta\")\nplt.xlabel(\"Média Padronizada dos Lançamentos\")\nplt.ylabel(\"Densidade\")\nplt.legend()\n\n# Exibir\nplt.grid(True)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Probabilidade",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade/TCL.html#exemplo-computacional-o-caso-binomial",
    "href": "Probabilidade/TCL.html#exemplo-computacional-o-caso-binomial",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Se \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(S_n = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\).\nA seguir, apresentamos a distribuição da quantidade:\n\\[\\frac{{S}_n - E({S}_n)}{\\sqrt{Var(S_n)}} = \\frac{{S}_n - np}{\\sqrt{np(1-p)}} \\xrightarrow{D} N(0, 1)\\]\nNo R:\n\n\nMostrar Código\nlibrary(ggplot2)\n\nset.seed(123)\n\n# Parâmetros\nn_simulacoes &lt;- 1000 # Número de Simulações\nn_lancamentos &lt;- 300 # Número de lançamentos por simulação\nprob_cara &lt;- 0.5     # Probabilidade de sair cara\n\n# Simulação\nSn &lt;- replicate(n_simulacoes, {\n  \n  lancamentos &lt;- sample(c(0,1), n_lancamentos, replace = TRUE, prob = c(1 - prob_cara, prob_cara))\n  sum(lancamentos)\n  \n})\n\n# Valores Normal Padrão\nvalores_pad &lt;- (Sn - n_lancamentos * prob_cara) / sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Dados para o gráfico\ndados &lt;- data.frame(valores = valores_pad)\n\n# Valores Teóricos\nmedia_pop &lt;- 0\ndesvio_padrao_pop &lt;- 1\n\n# Gráfico\nggplot(dados, aes(x = valores)) +\n  geom_histogram(aes(y = ..density..), fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  stat_function(fun = dnorm, args = list(mean = media_pop, sd = desvio_padrao_pop), col = \"red\", size = 1) +\n  labs(title = \"Teorema Central do Limite - Moeda Honesta\",\n       x = \"Média Padronizada dos Lançamentos\",\n       y = \"Densidade\")\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Parâmetros\nn_simulacoes = 1000  # Número de Simulações\nn_lancamentos = 300  # Número de lançamentos por simulação\nprob_cara = 0.5      # Probabilidade de sair cara\n\n# Simulação\nSn = np.array([\n    np.sum(np.random.choice([0, 1], size=n_lancamentos, p=[1 - prob_cara, prob_cara]))\n    for _ in range(n_simulacoes)\n])\n\n# Valores Normal Padrão\nvalores_pad = (Sn - n_lancamentos * prob_cara) / np.sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Valores Teóricos\nmedia_pop = 0\ndesvio_padrao_pop = 1\n\n# Gráfico\nplt.figure(figsize=(6, 4))\ncount, bins, ignored = plt.hist(valores_pad, bins=30, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n\n# Curva Teórica Normal Padrão\nx = np.linspace(min(bins), max(bins), 1000)\nplt.plot(x, norm.pdf(x, media_pop, desvio_padrao_pop), color='red', lw=2, label='Normal(0,1)')\n\n# Labels e Título\nplt.title(\"Teorema Central do Limite - Moeda Honesta\")\nplt.xlabel(\"Média Padronizada dos Lançamentos\")\nplt.ylabel(\"Densidade\")\nplt.legend()\n\n# Exibir\nplt.grid(True)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade/TCL.html#usando-o-tcl-pra-aproximar-probabilidades-da-binomial-pela-normal",
    "href": "Probabilidade/TCL.html#usando-o-tcl-pra-aproximar-probabilidades-da-binomial-pela-normal",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Esta aproximação, também conhecida como Teorema de De Moivre–Laplace, ilustra como o TCL pode ser usado para aproximar a distribuição discreta Binomial pela distribuição contínua Normal.\nLembrando que se \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(X = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\) (pela notação, \\(X = S_n\\) do exemplo computacional anterior) e queremos calcular a probabilidade da variável aleatória \\(X\\) estar entre dois valores inteiros \\(a\\) e \\(b\\) o que pode ser computacionalmente intenso. Nesse sentido, vamos aproximar essa probabilidade através do TCL usando o fato de que \\(\\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}} \\xrightarrow{D} N(0, 1)\\):\n\\[\nP(a \\le X \\le b) = P\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\le \\frac{X-np}{\\sqrt{np(1-p)}} \\le \\frac{b-np}{\\sqrt{np(1-p)}} \\right) \\approx \\Phi\\left( \\frac{b-np}{\\sqrt{np(1-p)}} \\right) - \\Phi\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\right)\n\\]\nEsta expressão representa a diferença das distribuição acumuladas da Normal Padrão entre os pontos \\(\\frac{b-np}{\\sqrt{np(1-p)}}\\) e \\(\\frac{a-np}{\\sqrt{np(1-p)}}\\).\n\n\nObserve que esta aproximação se mostra útil, no entanto temos que ter um cuidado adicional ao aproximarmos distribuições contínuas de discretas para evitarmos conclusões equivocadas. Por exemplo, suponha que gostaríamos de usar esta aproximação para calcular a probabilidade de a variável assumir um ponto específico \\(a\\), então podemos concluir, erroneamente, que:\n\\[P(X = a) = P(a \\le X \\le a) \\neq \\Phi(a) - \\Phi(a) = 0, \\ \\forall a\\]\nLogo, podemos melhorar essa aproximação de probabilidade através de uma especificação de um intervalo contínuo no entorno do valor \\(a\\):\n\\[P(X=a) \\overset{a \\ é \\ inteiro!}{=} P\\left( a - \\frac{1}{2} \\lt X \\lt a + \\frac{1}{2} \\right) \\approx \\Phi\\left( a - \\frac{1}{2} \\right) - \\Phi\\left( a + \\frac{1}{2} \\right)\\]",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Multivariada/Componentes_Principais.html",
    "href": "Multivariada/Componentes_Principais.html",
    "title": "Componentes Principais",
    "section": "",
    "text": "\\[\n\\newcommand{\\bs}[1]{\\boldsymbol{#1}}\n\\]",
    "crumbs": [
      "Principais Tópicos",
      "Componentes Principais"
    ]
  },
  {
    "objectID": "Multivariada/Cluster.html",
    "href": "Multivariada/Cluster.html",
    "title": "Análise de Cluster",
    "section": "",
    "text": "Introdução\nAnálise de Cluster",
    "crumbs": [
      "Principais Tópicos",
      "Análise de Cluster"
    ]
  },
  {
    "objectID": "section2/topic2.html",
    "href": "section2/topic2.html",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei dos Grandes Números (LGN) é um dos resultados mais famosos da Teoria da Probabilidade.\nSejam \\(X_1, X_2, ...\\) variáveis aleatórias independentes e identicamente distribuídas (\\(iid\\)) com média e variância existentes e finitas, isto é \\(-\\infty &lt; \\mu &lt; +\\infty\\) e \\(0 &lt; \\sigma^2 &lt; +\\infty\\).\nAlém disso, defina \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n}\\) como sendo a média amostral.\n\n\nA Lei Forte estabelece que a média amostral converge para \\(\\mu\\) no infinito com probabilidade 1. Ou seja, \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\[P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória (a média amostral) para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).\n\\(\\square\\)\n\n\n\nA Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\[P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\[\n\\begin{align*}\nP\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\\\\n= \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\n\\end{align*}\n\\]\n\\(\\square\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).\n\n\n\nÉ intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\[Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\]\nentão,\n\\[Lei\\ Forte \\implies Lei\\ Fraca\\]\nO contrário não vale para nenhuma das duas afirmativas acima.\n\n\n\nSuponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\[X_i \\overset{iid}{\\sim}Bernoulli(p)\\]\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\[\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\]\nEste resultado mostra que a medida que ao jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy.\n\n\n\nNo R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(6, 4))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "section2/topic2.html#lei-forte-dos-grandes-números",
    "href": "section2/topic2.html#lei-forte-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Forte estabelece que a média amostral converge para \\(\\mu\\) no infinito com probabilidade 1. Ou seja, \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\[P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória (a média amostral) para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).\n\\(\\square\\)"
  },
  {
    "objectID": "section2/topic2.html#lei-fraca-dos-grandes-números",
    "href": "section2/topic2.html#lei-fraca-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\[P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\[\n\\begin{align*}\nP\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\\\\n= \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\n\\end{align*}\n\\]\n\\(\\square\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\)."
  },
  {
    "objectID": "section2/topic2.html#relação-entre-leis-e-convergências",
    "href": "section2/topic2.html#relação-entre-leis-e-convergências",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "É intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\[Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\]\nentão,\n\\[Lei\\ Forte \\implies Lei\\ Fraca\\]\nO contrário não vale para nenhuma das duas afirmativas acima."
  },
  {
    "objectID": "section2/topic2.html#exemplo-o-caso-bernoulli",
    "href": "section2/topic2.html#exemplo-o-caso-bernoulli",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "Suponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\[X_i \\overset{iid}{\\sim}Bernoulli(p)\\]\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\[\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\]\nEste resultado mostra que a medida que ao jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy."
  },
  {
    "objectID": "section2/topic2.html#exemplo-computacional",
    "href": "section2/topic2.html#exemplo-computacional",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "No R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(6, 4))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "section1/topic1.html",
    "href": "section1/topic1.html",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei dos Grandes Números (LGN) é um dos resultados mais famosos da Teoria da Probabilidade.\nSejam \\(X_1, X_2, ...\\) variáveis aleatórias independentes e identicamente distribuídas (\\(iid\\)) com média e variância existentes e finitas, isto é \\(-\\infty &lt; \\mu &lt; +\\infty\\) e \\(0 &lt; \\sigma^2 &lt; +\\infty\\).\nAlém disso, defina \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n}\\) como sendo a média amostral.\n\n\nA Lei Forte estabelece que a média amostral converge para \\(\\mu\\) no infinito com probabilidade 1. Ou seja, \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\[P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória (a média amostral) para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).\n\\(\\square\\)\n\n\n\nA Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\[P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\[\n\\begin{align*}\nP\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\\\\n= \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\n\\end{align*}\n\\]\n\\(\\square\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).\n\n\n\nÉ intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\[Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\]\nentão,\n\\[Lei\\ Forte \\implies Lei\\ Fraca\\]\nO contrário não vale para nenhuma das duas afirmativas acima.\n\n\n\nSuponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\[X_i \\overset{iid}{\\sim}Bernoulli(p)\\]\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\[\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\]\nEste resultado mostra que a medida que ao jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy.\n\n\n\nNo R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(6, 4))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "section1/topic1.html#lei-forte-dos-grandes-números",
    "href": "section1/topic1.html#lei-forte-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Forte estabelece que a média amostral converge para \\(\\mu\\) no infinito com probabilidade 1. Ou seja, \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\[P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória (a média amostral) para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).\n\\(\\square\\)"
  },
  {
    "objectID": "section1/topic1.html#lei-fraca-dos-grandes-números",
    "href": "section1/topic1.html#lei-fraca-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\[P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\[\n\\begin{align*}\nP\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\\\\n= \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\n\\end{align*}\n\\]\n\\(\\square\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\)."
  },
  {
    "objectID": "section1/topic1.html#relação-entre-leis-e-convergências",
    "href": "section1/topic1.html#relação-entre-leis-e-convergências",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "É intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\[Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\]\nentão,\n\\[Lei\\ Forte \\implies Lei\\ Fraca\\]\nO contrário não vale para nenhuma das duas afirmativas acima."
  },
  {
    "objectID": "section1/topic1.html#exemplo-o-caso-bernoulli",
    "href": "section1/topic1.html#exemplo-o-caso-bernoulli",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "Suponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\[X_i \\overset{iid}{\\sim}Bernoulli(p)\\]\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\[\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\]\nEste resultado mostra que a medida que ao jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy."
  },
  {
    "objectID": "section1/topic1.html#exemplo-computacional",
    "href": "section1/topic1.html#exemplo-computacional",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "No R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(6, 4))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "section1/index.html",
    "href": "section1/index.html",
    "title": "Sobre",
    "section": "",
    "text": "Este é um Website do\nConstante Evolução\nConceitos Gerais de Probabilidade, Estatística e afins\nSinta-se livre para sugerir melhorias abrindo uma issue neste link\nEste é um website baseado no Quarto da empresa Posit.\n\nLinks Úteis\nSite oficial do Quarto\nTemplates úteis do prof. Gang He\nSite do prof. André Zibetti\n\n\nConsiderações de Desenvolvimento do Site\nO código para geração deste site por ser acessado neste link.\nPara rodar códigos em Python, é necessário instalar as bibliotecas usando o reticulate. Especificamente, o Quarto cria um ambiente virtual temporário chamado r-reticulate. Ou seja, as bibliotecas usadas durante a geração do site serão as bibliotecas instaladas neste ambiente.\nExemplo de instalação de biblioteca do Python usando o reticulate:\nreticulate::py_install(\"matplotlib\")\nreticulate::py_install(\"scipy\")\nAlém disso, cuidado com o gerenciamento das engines no momento de compilar o website. Segundo a documentação do Quarto, é importante sabermos as diferentes distinções de engine e suas coexistências conforme a seguir:\nEngine Conflicts:\n\nKnitr vs. Jupyter: If you explicitly set the engine to jupyter in your YAML, R code chunks will not be executed, and only Python (or the kernel’s language) will run. For mixed R and Python, engine: knitr is typically used, relying on reticulate for Python execution."
  },
  {
    "objectID": "section2/index.html",
    "href": "section2/index.html",
    "title": "Sobre",
    "section": "",
    "text": "Este é um Website do\nConstante Evolução\nConceitos Gerais de Probabilidade, Estatística e afins\nSinta-se livre para sugerir melhorias abrindo uma issue neste link\nEste é um website baseado no Quarto da empresa Posit.\n\nLinks Úteis\nSite oficial do Quarto\nTemplates úteis do prof. Gang He\nSite do prof. André Zibetti\n\n\nConsiderações de Desenvolvimento do Site\nO código para geração deste site por ser acessado neste link.\nPara rodar códigos em Python, é necessário instalar as bibliotecas usando o reticulate. Especificamente, o Quarto cria um ambiente virtual temporário chamado r-reticulate. Ou seja, as bibliotecas usadas durante a geração do site serão as bibliotecas instaladas neste ambiente.\nExemplo de instalação de biblioteca do Python usando o reticulate:\nreticulate::py_install(\"matplotlib\")\nreticulate::py_install(\"scipy\")\nAlém disso, cuidado com o gerenciamento das engines no momento de compilar o website. Segundo a documentação do Quarto, é importante sabermos as diferentes distinções de engine e suas coexistências conforme a seguir:\nEngine Conflicts:\n\nKnitr vs. Jupyter: If you explicitly set the engine to jupyter in your YAML, R code chunks will not be executed, and only Python (or the kernel’s language) will run. For mixed R and Python, engine: knitr is typically used, relying on reticulate for Python execution."
  },
  {
    "objectID": "Multivariada/Componentes_Principais.html#footnotes",
    "href": "Multivariada/Componentes_Principais.html#footnotes",
    "title": "Componentes Principais",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nJohnson e Wichern (2007) chama essa quantidade de “vetor aleatório”. No entanto, imagino que pensar como sendo uma base de dados com “p” colunas mais intuitivo.↩︎",
    "crumbs": [
      "Principais Tópicos",
      "Componentes Principais"
    ]
  },
  {
    "objectID": "Multivariada/Componentes_Principais.html#formulação",
    "href": "Multivariada/Componentes_Principais.html#formulação",
    "title": "Componentes Principais",
    "section": "Formulação",
    "text": "Formulação\nSeja \\(X_1, X_2, ..., X_p\\) variáveis aleatórias e assuma \\(\\bs{X'} = [X_1, X_2, ..., X_p]\\) ser toda a sua base de dados1 tendo uma matriz de covariância \\(\\bs{\\Sigma}\\) com os pares de autovalores e autovetores associados \\((\\lambda_1, \\bs{e_1}), (\\lambda_2, \\bs{e_2}), ..., (\\lambda_p, \\bs{e_p})\\) onde \\(\\lambda_1 \\ge \\lambda_2 \\ge ... \\ge \\lambda_p \\ge 0\\) e \\(||\\bs{e_i}|| = 1, \\forall i\\). Então, o i-ésimo componente principal será dado por:\n\\[\nY_i = \\bs{e_i'X} = e_{i1}X_1 + e_{i2}X_2 + ... +  e_{ip}X_p, \\ \\ \\ \\ i = 1, ..., p\n\\]\nEspecificamente com essas escolhas:\n\\[\n\\begin{align*}\nVar(Y_i) = \\bs{e_i'\\Sigma e_i} &= \\lambda_i  \\ \\ \\ \\ i = 1, ..., p \\\\\nCov(Y_i,Y_k) = \\bs{e_i'\\Sigma e_k} &= 0,  \\ \\ \\ \\ i \\ne k\n\\end{align*}\n\\]\nAs quantidades \\(Y_i\\)’s são considerados os componentes principais da base de dados \\(\\bs{X'}\\). Observe que \\(Y_i\\)’s são novas variáveis criadas a partir das variáveis \\(X_i\\)’s originais. Além disso, os \\(Y_i\\)’s não são correlacionados entre si.\nA análise de componentes principais nada mais é do que uma aplicação prática da Decomposição Espectral da matriz de covariância/correlação de uma base de dados.\nExpandindo a notação, os \\(p\\) componentes principais podem ser escritos como:\n\\[\n\\begin{align*}\nY_1 = \\bs{e_1'X} &= e_{11}X_1 + e_{12}X_2 + ... +  e_{1p}X_p \\\\\nY_2 = \\bs{e_2'X} &= e_{21}X_1 + e_{22}X_2 + ... +  e_{2p}X_p \\\\\n&\\;\\;\\vdots \\notag \\\\\nY_p = \\bs{e_p'X} &= e_{p1}X_1 + e_{p2}X_2 + ... +  e_{pp}X_p\n\\end{align*}\n\\]\nAs quantidades \\(e_{ij}\\) são denominadas loadings associado do componente \\(i\\) à variável \\(j\\).",
    "crumbs": [
      "Principais Tópicos",
      "Componentes Principais"
    ]
  },
  {
    "objectID": "Multivariada/Componentes_Principais.html#componentes-principais-na-matriz-de-correlação-bsrho",
    "href": "Multivariada/Componentes_Principais.html#componentes-principais-na-matriz-de-correlação-bsrho",
    "title": "Componentes Principais",
    "section": "Componentes Principais na Matriz de Correlação \\(\\bs{\\rho}\\)",
    "text": "Componentes Principais na Matriz de Correlação \\(\\bs{\\rho}\\)\nIncluir aqui",
    "crumbs": [
      "Principais Tópicos",
      "Componentes Principais"
    ]
  },
  {
    "objectID": "Multivariada/Componentes_Principais.html#o-cuidado-com-a-arbitrariedade-dos-autovetores",
    "href": "Multivariada/Componentes_Principais.html#o-cuidado-com-a-arbitrariedade-dos-autovetores",
    "title": "Componentes Principais",
    "section": "O cuidado com a arbitrariedade dos autovetores",
    "text": "O cuidado com a arbitrariedade dos autovetores\nIncluir aqui…",
    "crumbs": [
      "Principais Tópicos",
      "Componentes Principais"
    ]
  },
  {
    "objectID": "Multivariada/Componentes_Principais.html#o-cuidado-com-a-arbitrariedade-do-sentido-dos-autovetores",
    "href": "Multivariada/Componentes_Principais.html#o-cuidado-com-a-arbitrariedade-do-sentido-dos-autovetores",
    "title": "Componentes Principais",
    "section": "O cuidado com a arbitrariedade do sentido dos autovetores",
    "text": "O cuidado com a arbitrariedade do sentido dos autovetores\nIncluir aqui…",
    "crumbs": [
      "Principais Tópicos",
      "Componentes Principais"
    ]
  },
  {
    "objectID": "Probabilidade_B/TCL.html",
    "href": "Probabilidade_B/TCL.html",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "O Teorema Central do Limite (TCL) é um dos resultados mais famosos e mais bonitos da Teoria da Probabilidade.\nSejam \\(X_1, X_2, ...\\) variáveis aleatórias independentes e identicamente distribuídas (\\(iid\\)) com média e variância existentes e finitas, isto é \\(-\\infty &lt; \\mu &lt; +\\infty\\) e \\(0 &lt; \\sigma^2 &lt; +\\infty\\).\nAlém disso, defina \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n}\\) como sendo a média amostral.\nPela Lei dos Grandes Números, sabemos que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\), mas a qual taxa? Como que é a distribuição dessa quantidade?\n\n\nDefinição. Sejam \\(X, X_1, X_2, ...\\) variáveis aleatórias com, respectivamente, funções de distribuições \\(F, F_1, F_2, ...\\). Dizemos que \\(X_n\\) converge em distribuição para \\(X\\), quando \\(n \\rightarrow +\\infty\\), se \\(F_n(x) \\rightarrow F(x)\\) para todo \\(x\\) ponto de continuidade de \\(F\\).\nNotação: \\(X_n \\xrightarrow{D} X\\) ou \\(X_n \\xrightarrow{D} F\\).\n\n\n\nPodemos reescrever a quantidade da introdução como sendo \\(\\bar{X} - \\mu \\xrightarrow{n \\rightarrow + \\infty} 0\\). Assim, uma das maneiras de buscar entender a distribuição de uma quantidade quando ela vai zero é multiplicá-la por uma quantidade que vai para infinito de uma maneira que seu valor de convergência não “exploda” (ou “degenere”) para o infinito e nem para zero. De fato se multiplicarmos a quantidade acima por \\(n\\) elevando-o à um exponencial buscando controlar as taxas de convergência. Neste caso, o exponencial é o valor de \\(\\frac{1}{2}\\), ou seja, \\(\\sqrt{n}\\).1\nLogo, o TCL pode ser definido por:\n\\(\\sqrt{n} \\left(\\bar{X} - \\mu \\right) \\xrightarrow{n \\rightarrow + \\infty} N(0, \\sigma^{2})\\) em distribuição\nOu, alternativamente, na sua forma mais popular:\n\\[\n\\sqrt{n} \\left(\\frac{\\bar{X} - \\mu}{\\sigma} \\right) \\xrightarrow{D} N(0, 1)\n\\tag{1}\\]\nO TCL retrata um dos teoremas mais lindos de toda a probabilidade tendo em vista que com poucas condições iniciais (neste caso, média e variância finitas) conseguimos provar que a média amostral \\(\\bar{X}\\) padronizada converge em distribuição para a distribuição normal padrão. Observe que o teorema não faz nenhuma alusão ao tipo de variável aleatória, podendo ser discreto ou contínuo, e nem sobre o suporte da distribuição, podendo ser positivo, negativo ou ambos.\nEste teorema é um dos principais motivos pela ampla difusão da distribuição Normal em diversas áreas do conhecimento científico. Tendo em vista que, dadas às devidas condições, a média amostral pode ser aproximada pela distribuição normal padrão, as aplicações desses resultados são diversos.\nProva. Faça \\(S_n = X_1 + X_2 + ... +X_n\\) e multiplicando e dividindo por \\(n\\) o termo da Equação 1 chegamos em\n\\[\n\\frac{1}{\\sqrt{n}}\\left(\\frac{S_n - n\\mu}{\\sigma} \\right) = \\frac{1}{\\sqrt{n}}\\left(\\frac{\\sum_{i=1}^nX_i- n\\mu}{\\sigma} \\right) \\overset{\\text{Expandindo o somatório}}{=} \\frac{1}{\\sqrt{n}}\\sum_{i=1}^n\\left(\\frac{X_i- \\mu}{\\sigma} \\right) \\xrightarrow{D} N(0, 1)\n\\]\nPodemos assumir, sem perda de generalidade que \\(\\mu = 0\\) e \\(\\sigma = 1\\), pois poderíamos fazer a prova definindo uma variável aleatória sendo \\(Z_i = \\frac{X_i- \\mu}{\\sigma}\\), onde esta variável teria média 0 e desvio padrão 1. Sendo assim, basta provar\n\\[\\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}} \\xrightarrow{D} N(0, 1)\\]\nPara isso, faremos o uso da função geradora de momentos (\\(M\\)) da quantidade acima e avaliando o seu valor quanto \\(n \\rightarrow +\\infty\\) a fim de identificar qual a distribuição limite obtida.2 Ou seja:\n\\(M_{X_n}(x) \\xrightarrow{n \\rightarrow + \\infty} M_{X}(x) \\implies X_n \\xrightarrow{D} X\\)\nPor notação, vamos estabelecer \\(Q_n = \\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}}\\) e aplicar o teorema acima:\n\\(M_{Q_n}(t) = E\\left( e^{t\\left(\\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}}\\right)} \\right) \\overset{\\text{Prop. de Exponencial}}{=} E\\left( e^{\\frac{tX_1}{\\sqrt{n}}} \\times e^{\\frac{tX_2}{\\sqrt{n}}} \\times \\dots \\times e^{\\frac{tX_n}{\\sqrt{n}}} \\right) \\overset{\\text{Independência}}{=} \\prod_{i=1}^{n}E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right)\\)\nComo todos os \\(X_i\\) são identicamente distribuídos, podemos simplificar a expressão para:\n\\(M_{Q_n}(t) = \\prod_{i=1}^{n}E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right) = E\\left( e^{\\frac{tX_1}{\\sqrt{n}}} \\right) \\times E\\left( e^{\\frac{tX_2}{\\sqrt{n}}} \\right) \\times \\dots \\times E\\left( e^{\\frac{tX_n}{\\sqrt{n}}} \\right) = \\left( E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right) \\right)^n, \\ \\forall i\\)\nNo entanto, note acima que \\(E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right)\\) é exatamente a função geradora de momentos aplicada no ponto \\(\\frac{t}{\\sqrt{n}}\\). Logo:\n\\(M_{Q_n}(t) = \\left( M_{X_i}\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n, \\ \\forall i\\)\nPor simplificação de notação, vamos suprimir o \\(X_i\\)3 nos passos seguintes e vamos avaliar esta expressão quando \\(n \\rightarrow +\\infty\\).\nObserve que da maneira como está estruturado \\(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n\\) converge para uma indefinição do tipo \\(1^\\infty\\), pois \\(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n = \\left( E\\left( e^{\\frac{tX}{\\sqrt{n}}} \\right) \\right)^n \\rightarrow \\left( E\\left( e^0 \\right) \\right)^\\infty\\).\nPara tratar essa indefinição, aplicaremos o logaritmo natural (\\(log\\)) na expressão e, depois de avaliado o limite, podemos reverter o valor aplicando o exponencial. Logo,\n\\[log\\left(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n \\right) = n\\times log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)\\]\nQuando aplicamos \\(n \\rightarrow +\\infty\\) caímos numa indefinição do tipo \\(+\\infty \\times 0\\), logo vamos reescrever a equação para \\(n\\times log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right) = \\frac{log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)}{\\frac{1}{n}}\\) e, desta maneira, caírmos numa indefinição do tipo \\(\\frac{0}{0}\\) para aplicarmos l’Hôpital. Como o \\(n\\) é um número inteiro natural e para melhor tratativa algébrica, vamos fazer uma transforção de variável para facilitar o desenvolvimento e poder aplicar a derivada em um número real. Assim,\n\\[\n\\lim_{n\\to\\infty}\\frac{log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)}{\\frac{1}{n}} \\overset{y=\\frac{1}{\\sqrt{n}}, \\ y \\in \\mathbb{R} }{=} \\lim_{y\\to 0}\\frac{log\\left( M\\left( yt \\right) \\right)}{y^2}\n\\]\nQue é uma indefinição do tipo \\(\\frac{0}{0}\\). Logo, aplicando l’Hôpital:4\n\\[\n\\lim_{y\\to 0}\\frac{tM'(yt)}{M(yt)}\\frac{1}{2y}\n\\]\nEste limite continua sendo uma indefinição do tipo \\(\\frac{0}{0}\\), porque pela definição da função geradora do momento, quando aplicamos as suposições no ponto \\(t=0\\) temos:\n\\[\n\\begin{aligned}\nM(t) = E\\left(e^{tX}\\right) \\implies M(0) = 1 \\\\\n\\mu = 0 \\implies M'(0) = 0 \\\\\n\\sigma^2 = 1 \\implies M''(0) = 1\n\\end{aligned}\n\\] Logo, simplificando os limites e aplicando l’Hôpital novamente temos:\n\\[\n\\lim_{y\\to 0}\\frac{tM'(yt)}{M(yt)}\\frac{1}{2y} \\overset{\\lim_{y\\to 0}{M(yt)}=1}{=} \\lim_{y\\to 0}\\frac{tM'(yt)}{2y} = \\lim_{y\\to 0}\\frac{t^2M''(yt)}{2} = \\frac{t^2}{2} \\lim_{y\\to 0}M''(yt) = \\frac{t^2}{2}\n\\]\nAplicando o exponencial para reverter o logaritmo aplicado originalmente temos:\n\\[M_{Q_n}(t) \\xrightarrow{n \\rightarrow +\\infty} e^{\\frac{t^2}{2}}\\]\nQue coindide com a função geradora de momentos da Normal Padrão.\n\\(\\square\\)\nUma discussão mais aprofundada do Teorema Central do Limite pode ser encontrada no Capítulo 7 de James (2023) ou no Capítulo 6 de DeGroot e Schervish (2012).\n\n\n\nFazendo \\(S_n = X_1 + X_2 + ... +X_n\\), James (2023) trata o problema central do limite atavés do estudo da convergência em distribuição das somas parciais normalizadas e formula o TCL como sendo:\n\\[\\frac{{S}_n - E({S}_n)}{\\sqrt{Var(S_n)}} \\xrightarrow{D} N(0, 1)\\]\nOutras maneiras de representar o TCL são:\n\\[\\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}} \\xrightarrow{D} N(0, 1)\\]\n\\[\\sqrt{n} \\bar{X} \\xrightarrow{D} N(\\mu, \\sigma^2)\\]\n\n\n\nSe \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(S_n = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\).\nA seguir, apresentamos a distribuição da quantidade:\n\\[\\frac{{S}_n - E({S}_n)}{\\sqrt{Var(S_n)}} = \\frac{{S}_n - np}{\\sqrt{np(1-p)}} \\xrightarrow{D} N(0, 1)\\]\nNo R:\n\n\nMostrar Código\nlibrary(ggplot2)\n\nset.seed(123)\n\n# Parâmetros\nn_simulacoes &lt;- 1000 # Número de Simulações\nn_lancamentos &lt;- 300 # Número de lançamentos por simulação\nprob_cara &lt;- 0.5     # Probabilidade de sair cara\n\n# Simulação\nSn &lt;- replicate(n_simulacoes, {\n  \n  lancamentos &lt;- sample(c(0,1), n_lancamentos, replace = TRUE, prob = c(1 - prob_cara, prob_cara))\n  sum(lancamentos)\n  \n})\n\n# Valores Normal Padrão\nvalores_pad &lt;- (Sn - n_lancamentos * prob_cara) / sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Dados para o gráfico\ndados &lt;- data.frame(valores = valores_pad)\n\n# Valores Teóricos\nmedia_pop &lt;- 0\ndesvio_padrao_pop &lt;- 1\n\n# Gráfico\nggplot(dados, aes(x = valores)) +\n  geom_histogram(aes(y = ..density..), fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  stat_function(fun = dnorm, args = list(mean = media_pop, sd = desvio_padrao_pop), col = \"red\", size = 1) +\n  labs(title = \"Teorema Central do Limite - Moeda Honesta\",\n       x = \"Média Padronizada dos Lançamentos\",\n       y = \"Densidade\")\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Parâmetros\nn_simulacoes = 1000  # Número de Simulações\nn_lancamentos = 300  # Número de lançamentos por simulação\nprob_cara = 0.5      # Probabilidade de sair cara\n\n# Simulação\nSn = np.array([\n    np.sum(np.random.choice([0, 1], size=n_lancamentos, p=[1 - prob_cara, prob_cara]))\n    for _ in range(n_simulacoes)\n])\n\n# Valores Normal Padrão\nvalores_pad = (Sn - n_lancamentos * prob_cara) / np.sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Valores Teóricos\nmedia_pop = 0\ndesvio_padrao_pop = 1\n\n# Gráfico\nplt.figure(figsize=(6, 4))\ncount, bins, ignored = plt.hist(valores_pad, bins=30, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n\n# Curva Teórica Normal Padrão\nx = np.linspace(min(bins), max(bins), 1000)\nplt.plot(x, norm.pdf(x, media_pop, desvio_padrao_pop), color='red', lw=2, label='Normal(0,1)')\n\n# Labels e Título\nplt.title(\"Teorema Central do Limite - Moeda Honesta\")\nplt.xlabel(\"Média Padronizada dos Lançamentos\")\nplt.ylabel(\"Densidade\")\nplt.legend()\n\n# Exibir\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nEsta aproximação, também conhecida como Teorema de De Moivre–Laplace, ilustra como o TCL pode ser usado para aproximar a distribuição discreta Binomial pela distribuição contínua Normal.\nLembrando que se \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(X = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\) (pela notação, \\(X = S_n\\) do exemplo computacional anterior) e queremos calcular a probabilidade da variável aleatória \\(X\\) estar entre dois valores inteiros \\(a\\) e \\(b\\) o que pode ser computacionalmente intenso. Nesse sentido, vamos aproximar essa probabilidade através do TCL usando o fato de que \\(\\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}} \\xrightarrow{D} N(0, 1)\\):\n\\[\nP(a \\le X \\le b) = P\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\le \\frac{X-np}{\\sqrt{np(1-p)}} \\le \\frac{b-np}{\\sqrt{np(1-p)}} \\right) \\approx \\Phi\\left( \\frac{b-np}{\\sqrt{np(1-p)}} \\right) - \\Phi\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\right)\n\\]\nEsta expressão representa a diferença das distribuição acumuladas da Normal Padrão entre os pontos \\(\\frac{b-np}{\\sqrt{np(1-p)}}\\) e \\(\\frac{a-np}{\\sqrt{np(1-p)}}\\).\n\n\nObserve que esta aproximação se mostra útil, no entanto temos que ter um cuidado adicional ao aproximarmos distribuições contínuas de discretas para evitarmos conclusões equivocadas. Por exemplo, suponha que gostaríamos de usar esta aproximação para calcular a probabilidade de a variável assumir um ponto específico \\(a\\), então podemos concluir, erroneamente, que:\n\\[P(X = a) = P(a \\le X \\le a) \\neq \\Phi(a) - \\Phi(a) = 0, \\ \\forall a\\]\nLogo, podemos melhorar essa aproximação de probabilidade através de uma especificação de um intervalo contínuo no entorno do valor \\(a\\):\n\\[P(X=a) \\overset{a \\ é \\ inteiro!}{=} P\\left( a - \\frac{1}{2} \\lt X \\lt a + \\frac{1}{2} \\right) \\approx \\Phi\\left( a - \\frac{1}{2} \\right) - \\Phi\\left( a + \\frac{1}{2} \\right)\\]",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade_B/TCL.html#convergência-em-distribuição",
    "href": "Probabilidade_B/TCL.html#convergência-em-distribuição",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Definição. Sejam \\(X, X_1, X_2, ...\\) variáveis aleatórias com, respectivamente, funções de distribuições \\(F, F_1, F_2, ...\\). Dizemos que \\(X_n\\) converge em distribuição para \\(X\\), quando \\(n \\rightarrow +\\infty\\), se \\(F_n(x) \\rightarrow F(x)\\) para todo \\(x\\) ponto de continuidade de \\(F\\).\nNotação: \\(X_n \\xrightarrow{D} X\\) ou \\(X_n \\xrightarrow{D} F\\).",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade_B/TCL.html#teorema-central-do-limite",
    "href": "Probabilidade_B/TCL.html#teorema-central-do-limite",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Podemos reescrever a quantidade da introdução como sendo \\(\\bar{X} - \\mu \\xrightarrow{n \\rightarrow + \\infty} 0\\). Assim, uma das maneiras de buscar entender a distribuição de uma quantidade quando ela vai zero é multiplicá-la por uma quantidade que vai para infinito de uma maneira que seu valor de convergência não “exploda” (ou “degenere”) para o infinito e nem para zero. De fato se multiplicarmos a quantidade acima por \\(n\\) elevando-o à um exponencial buscando controlar as taxas de convergência. Neste caso, o exponencial é o valor de \\(\\frac{1}{2}\\), ou seja, \\(\\sqrt{n}\\).1\nLogo, o TCL pode ser definido por:\n\\(\\sqrt{n} \\left(\\bar{X} - \\mu \\right) \\xrightarrow{n \\rightarrow + \\infty} N(0, \\sigma^{2})\\) em distribuição\nOu, alternativamente, na sua forma mais popular:\n\\[\n\\sqrt{n} \\left(\\frac{\\bar{X} - \\mu}{\\sigma} \\right) \\xrightarrow{D} N(0, 1)\n\\tag{1}\\]\nO TCL retrata um dos teoremas mais lindos de toda a probabilidade tendo em vista que com poucas condições iniciais (neste caso, média e variância finitas) conseguimos provar que a média amostral \\(\\bar{X}\\) padronizada converge em distribuição para a distribuição normal padrão. Observe que o teorema não faz nenhuma alusão ao tipo de variável aleatória, podendo ser discreto ou contínuo, e nem sobre o suporte da distribuição, podendo ser positivo, negativo ou ambos.\nEste teorema é um dos principais motivos pela ampla difusão da distribuição Normal em diversas áreas do conhecimento científico. Tendo em vista que, dadas às devidas condições, a média amostral pode ser aproximada pela distribuição normal padrão, as aplicações desses resultados são diversos.\nProva. Faça \\(S_n = X_1 + X_2 + ... +X_n\\) e multiplicando e dividindo por \\(n\\) o termo da Equação 1 chegamos em\n\\[\n\\frac{1}{\\sqrt{n}}\\left(\\frac{S_n - n\\mu}{\\sigma} \\right) = \\frac{1}{\\sqrt{n}}\\left(\\frac{\\sum_{i=1}^nX_i- n\\mu}{\\sigma} \\right) \\overset{\\text{Expandindo o somatório}}{=} \\frac{1}{\\sqrt{n}}\\sum_{i=1}^n\\left(\\frac{X_i- \\mu}{\\sigma} \\right) \\xrightarrow{D} N(0, 1)\n\\]\nPodemos assumir, sem perda de generalidade que \\(\\mu = 0\\) e \\(\\sigma = 1\\), pois poderíamos fazer a prova definindo uma variável aleatória sendo \\(Z_i = \\frac{X_i- \\mu}{\\sigma}\\), onde esta variável teria média 0 e desvio padrão 1. Sendo assim, basta provar\n\\[\\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}} \\xrightarrow{D} N(0, 1)\\]\nPara isso, faremos o uso da função geradora de momentos (\\(M\\)) da quantidade acima e avaliando o seu valor quanto \\(n \\rightarrow +\\infty\\) a fim de identificar qual a distribuição limite obtida.2 Ou seja:\n\\(M_{X_n}(x) \\xrightarrow{n \\rightarrow + \\infty} M_{X}(x) \\implies X_n \\xrightarrow{D} X\\)\nPor notação, vamos estabelecer \\(Q_n = \\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}}\\) e aplicar o teorema acima:\n\\(M_{Q_n}(t) = E\\left( e^{t\\left(\\frac{\\sum_{i=1}^n X_i}{\\sqrt{n}}\\right)} \\right) \\overset{\\text{Prop. de Exponencial}}{=} E\\left( e^{\\frac{tX_1}{\\sqrt{n}}} \\times e^{\\frac{tX_2}{\\sqrt{n}}} \\times \\dots \\times e^{\\frac{tX_n}{\\sqrt{n}}} \\right) \\overset{\\text{Independência}}{=} \\prod_{i=1}^{n}E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right)\\)\nComo todos os \\(X_i\\) são identicamente distribuídos, podemos simplificar a expressão para:\n\\(M_{Q_n}(t) = \\prod_{i=1}^{n}E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right) = E\\left( e^{\\frac{tX_1}{\\sqrt{n}}} \\right) \\times E\\left( e^{\\frac{tX_2}{\\sqrt{n}}} \\right) \\times \\dots \\times E\\left( e^{\\frac{tX_n}{\\sqrt{n}}} \\right) = \\left( E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right) \\right)^n, \\ \\forall i\\)\nNo entanto, note acima que \\(E\\left( e^{\\frac{tX_i}{\\sqrt{n}}} \\right)\\) é exatamente a função geradora de momentos aplicada no ponto \\(\\frac{t}{\\sqrt{n}}\\). Logo:\n\\(M_{Q_n}(t) = \\left( M_{X_i}\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n, \\ \\forall i\\)\nPor simplificação de notação, vamos suprimir o \\(X_i\\)3 nos passos seguintes e vamos avaliar esta expressão quando \\(n \\rightarrow +\\infty\\).\nObserve que da maneira como está estruturado \\(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n\\) converge para uma indefinição do tipo \\(1^\\infty\\), pois \\(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n = \\left( E\\left( e^{\\frac{tX}{\\sqrt{n}}} \\right) \\right)^n \\rightarrow \\left( E\\left( e^0 \\right) \\right)^\\infty\\).\nPara tratar essa indefinição, aplicaremos o logaritmo natural (\\(log\\)) na expressão e, depois de avaliado o limite, podemos reverter o valor aplicando o exponencial. Logo,\n\\[log\\left(\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)^n \\right) = n\\times log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)\\]\nQuando aplicamos \\(n \\rightarrow +\\infty\\) caímos numa indefinição do tipo \\(+\\infty \\times 0\\), logo vamos reescrever a equação para \\(n\\times log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right) = \\frac{log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)}{\\frac{1}{n}}\\) e, desta maneira, caírmos numa indefinição do tipo \\(\\frac{0}{0}\\) para aplicarmos l’Hôpital. Como o \\(n\\) é um número inteiro natural e para melhor tratativa algébrica, vamos fazer uma transforção de variável para facilitar o desenvolvimento e poder aplicar a derivada em um número real. Assim,\n\\[\n\\lim_{n\\to\\infty}\\frac{log\\left( M\\left( \\frac{t}{\\sqrt{n}} \\right) \\right)}{\\frac{1}{n}} \\overset{y=\\frac{1}{\\sqrt{n}}, \\ y \\in \\mathbb{R} }{=} \\lim_{y\\to 0}\\frac{log\\left( M\\left( yt \\right) \\right)}{y^2}\n\\]\nQue é uma indefinição do tipo \\(\\frac{0}{0}\\). Logo, aplicando l’Hôpital:4\n\\[\n\\lim_{y\\to 0}\\frac{tM'(yt)}{M(yt)}\\frac{1}{2y}\n\\]\nEste limite continua sendo uma indefinição do tipo \\(\\frac{0}{0}\\), porque pela definição da função geradora do momento, quando aplicamos as suposições no ponto \\(t=0\\) temos:\n\\[\n\\begin{aligned}\nM(t) = E\\left(e^{tX}\\right) \\implies M(0) = 1 \\\\\n\\mu = 0 \\implies M'(0) = 0 \\\\\n\\sigma^2 = 1 \\implies M''(0) = 1\n\\end{aligned}\n\\] Logo, simplificando os limites e aplicando l’Hôpital novamente temos:\n\\[\n\\lim_{y\\to 0}\\frac{tM'(yt)}{M(yt)}\\frac{1}{2y} \\overset{\\lim_{y\\to 0}{M(yt)}=1}{=} \\lim_{y\\to 0}\\frac{tM'(yt)}{2y} = \\lim_{y\\to 0}\\frac{t^2M''(yt)}{2} = \\frac{t^2}{2} \\lim_{y\\to 0}M''(yt) = \\frac{t^2}{2}\n\\]\nAplicando o exponencial para reverter o logaritmo aplicado originalmente temos:\n\\[M_{Q_n}(t) \\xrightarrow{n \\rightarrow +\\infty} e^{\\frac{t^2}{2}}\\]\nQue coindide com a função geradora de momentos da Normal Padrão.\n\\(\\square\\)\nUma discussão mais aprofundada do Teorema Central do Limite pode ser encontrada no Capítulo 7 de James (2023) ou no Capítulo 6 de DeGroot e Schervish (2012).",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade_B/TCL.html#diferentes-formulações-e-versões-do-tcl",
    "href": "Probabilidade_B/TCL.html#diferentes-formulações-e-versões-do-tcl",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Fazendo \\(S_n = X_1 + X_2 + ... +X_n\\), James (2023) trata o problema central do limite atavés do estudo da convergência em distribuição das somas parciais normalizadas e formula o TCL como sendo:\n\\[\\frac{{S}_n - E({S}_n)}{\\sqrt{Var(S_n)}} \\xrightarrow{D} N(0, 1)\\]\nOutras maneiras de representar o TCL são:\n\\[\\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}} \\xrightarrow{D} N(0, 1)\\]\n\\[\\sqrt{n} \\bar{X} \\xrightarrow{D} N(\\mu, \\sigma^2)\\]",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade_B/TCL.html#exemplo-computacional-o-caso-binomial",
    "href": "Probabilidade_B/TCL.html#exemplo-computacional-o-caso-binomial",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Se \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(S_n = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\).\nA seguir, apresentamos a distribuição da quantidade:\n\\[\\frac{{S}_n - E({S}_n)}{\\sqrt{Var(S_n)}} = \\frac{{S}_n - np}{\\sqrt{np(1-p)}} \\xrightarrow{D} N(0, 1)\\]\nNo R:\n\n\nMostrar Código\nlibrary(ggplot2)\n\nset.seed(123)\n\n# Parâmetros\nn_simulacoes &lt;- 1000 # Número de Simulações\nn_lancamentos &lt;- 300 # Número de lançamentos por simulação\nprob_cara &lt;- 0.5     # Probabilidade de sair cara\n\n# Simulação\nSn &lt;- replicate(n_simulacoes, {\n  \n  lancamentos &lt;- sample(c(0,1), n_lancamentos, replace = TRUE, prob = c(1 - prob_cara, prob_cara))\n  sum(lancamentos)\n  \n})\n\n# Valores Normal Padrão\nvalores_pad &lt;- (Sn - n_lancamentos * prob_cara) / sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Dados para o gráfico\ndados &lt;- data.frame(valores = valores_pad)\n\n# Valores Teóricos\nmedia_pop &lt;- 0\ndesvio_padrao_pop &lt;- 1\n\n# Gráfico\nggplot(dados, aes(x = valores)) +\n  geom_histogram(aes(y = ..density..), fill = \"skyblue\", color = \"black\", alpha = 0.7) +\n  stat_function(fun = dnorm, args = list(mean = media_pop, sd = desvio_padrao_pop), col = \"red\", size = 1) +\n  labs(title = \"Teorema Central do Limite - Moeda Honesta\",\n       x = \"Média Padronizada dos Lançamentos\",\n       y = \"Densidade\")\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n\n# Parâmetros\nn_simulacoes = 1000  # Número de Simulações\nn_lancamentos = 300  # Número de lançamentos por simulação\nprob_cara = 0.5      # Probabilidade de sair cara\n\n# Simulação\nSn = np.array([\n    np.sum(np.random.choice([0, 1], size=n_lancamentos, p=[1 - prob_cara, prob_cara]))\n    for _ in range(n_simulacoes)\n])\n\n# Valores Normal Padrão\nvalores_pad = (Sn - n_lancamentos * prob_cara) / np.sqrt(n_lancamentos * prob_cara * (1 - prob_cara))\n\n# Valores Teóricos\nmedia_pop = 0\ndesvio_padrao_pop = 1\n\n# Gráfico\nplt.figure(figsize=(6, 4))\ncount, bins, ignored = plt.hist(valores_pad, bins=30, density=True, color='skyblue', edgecolor='black', alpha=0.7)\n\n# Curva Teórica Normal Padrão\nx = np.linspace(min(bins), max(bins), 1000)\nplt.plot(x, norm.pdf(x, media_pop, desvio_padrao_pop), color='red', lw=2, label='Normal(0,1)')\n\n# Labels e Título\nplt.title(\"Teorema Central do Limite - Moeda Honesta\")\nplt.xlabel(\"Média Padronizada dos Lançamentos\")\nplt.ylabel(\"Densidade\")\nplt.legend()\n\n# Exibir\nplt.grid(True)\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade_B/TCL.html#usando-o-tcl-pra-aproximar-probabilidades-da-binomial-pela-normal",
    "href": "Probabilidade_B/TCL.html#usando-o-tcl-pra-aproximar-probabilidades-da-binomial-pela-normal",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Esta aproximação, também conhecida como Teorema de De Moivre–Laplace, ilustra como o TCL pode ser usado para aproximar a distribuição discreta Binomial pela distribuição contínua Normal.\nLembrando que se \\(X_i \\overset{iid}{\\sim} Bernoulli(p)\\), então \\(X = \\sum_{i=1}^{n}X_i \\sim Binomial(n, p)\\) (pela notação, \\(X = S_n\\) do exemplo computacional anterior) e queremos calcular a probabilidade da variável aleatória \\(X\\) estar entre dois valores inteiros \\(a\\) e \\(b\\) o que pode ser computacionalmente intenso. Nesse sentido, vamos aproximar essa probabilidade através do TCL usando o fato de que \\(\\frac{\\bar{X} - E(\\bar{X})}{\\sqrt{Var(\\bar{X})}} \\xrightarrow{D} N(0, 1)\\):\n\\[\nP(a \\le X \\le b) = P\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\le \\frac{X-np}{\\sqrt{np(1-p)}} \\le \\frac{b-np}{\\sqrt{np(1-p)}} \\right) \\approx \\Phi\\left( \\frac{b-np}{\\sqrt{np(1-p)}} \\right) - \\Phi\\left( \\frac{a-np}{\\sqrt{np(1-p)}} \\right)\n\\]\nEsta expressão representa a diferença das distribuição acumuladas da Normal Padrão entre os pontos \\(\\frac{b-np}{\\sqrt{np(1-p)}}\\) e \\(\\frac{a-np}{\\sqrt{np(1-p)}}\\).\n\n\nObserve que esta aproximação se mostra útil, no entanto temos que ter um cuidado adicional ao aproximarmos distribuições contínuas de discretas para evitarmos conclusões equivocadas. Por exemplo, suponha que gostaríamos de usar esta aproximação para calcular a probabilidade de a variável assumir um ponto específico \\(a\\), então podemos concluir, erroneamente, que:\n\\[P(X = a) = P(a \\le X \\le a) \\neq \\Phi(a) - \\Phi(a) = 0, \\ \\forall a\\]\nLogo, podemos melhorar essa aproximação de probabilidade através de uma especificação de um intervalo contínuo no entorno do valor \\(a\\):\n\\[P(X=a) \\overset{a \\ é \\ inteiro!}{=} P\\left( a - \\frac{1}{2} \\lt X \\lt a + \\frac{1}{2} \\right) \\approx \\Phi\\left( a - \\frac{1}{2} \\right) - \\Phi\\left( a + \\frac{1}{2} \\right)\\]",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade_B/TCL.html#footnotes",
    "href": "Probabilidade_B/TCL.html#footnotes",
    "title": "Teorema Central do Limite",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nUma discussão sobre este fator de convergência é discutido aqui↩︎\nEste teorema é um caso particular do Teorema de Continuidade de Levy para funções características. Ele pode ser melhor detalhado em Curtiss (1942) ou aqui.↩︎\nMagalhães (2006) também realiza esta simplificação de notação em uma prova similar do TCL fazendo uso da Função Característica.↩︎\nLembrando que \\(\\frac{d\\log(f(x))}{dx} = \\frac{1}{f(x)} \\cdot \\frac{df(x)}{dx} = \\frac{f'(x)}{f(x)}\\)↩︎",
    "crumbs": [
      "Grandes Amostras",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade_B/LGN.html",
    "href": "Probabilidade_B/LGN.html",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei dos Grandes Números (LGN) é um dos resultados mais famosos da Teoria da Probabilidade.\nSejam \\(X_1, X_2, ...\\) variáveis aleatórias independentes e identicamente distribuídas (\\(iid\\)) com média e variância existentes e finitas, isto é \\(-\\infty &lt; \\mu &lt; +\\infty\\) e \\(0 &lt; \\sigma^2 &lt; +\\infty\\).\nAlém disso, defina \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n}\\) como sendo a média amostral.\n\n\nA Lei Forte estabelece que a média amostral converge para \\(\\mu\\) no infinito com probabilidade 1. Ou seja, \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\[P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória (a média amostral) para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).\n\\(\\square\\)\n\n\n\nA Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\[P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\[\n\\begin{align*}\nP\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\\\\n= \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\n\\end{align*}\n\\]\n\\(\\square\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).\n\n\n\nÉ intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\[Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\]\nentão,\n\\[Lei\\ Forte \\implies Lei\\ Fraca\\]\nO contrário não vale para nenhuma das duas afirmativas acima.\n\n\n\nSuponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\[X_i \\overset{iid}{\\sim}Bernoulli(p)\\]\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\[\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\]\nEste resultado mostra que a medida que ao jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy.\n\n\n\nNo R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(6, 4))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade_B/LGN.html#lei-forte-dos-grandes-números",
    "href": "Probabilidade_B/LGN.html#lei-forte-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Forte estabelece que a média amostral converge para \\(\\mu\\) no infinito com probabilidade 1. Ou seja, \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\[P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória (a média amostral) para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).\n\\(\\square\\)",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade_B/LGN.html#lei-fraca-dos-grandes-números",
    "href": "Probabilidade_B/LGN.html#lei-fraca-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\[P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\]\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\[\n\\begin{align*}\nP\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\\\\n= \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\n\\end{align*}\n\\]\n\\(\\square\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade_B/LGN.html#relação-entre-leis-e-convergências",
    "href": "Probabilidade_B/LGN.html#relação-entre-leis-e-convergências",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "É intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\[Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\]\nentão,\n\\[Lei\\ Forte \\implies Lei\\ Fraca\\]\nO contrário não vale para nenhuma das duas afirmativas acima.",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade_B/LGN.html#exemplo-o-caso-bernoulli",
    "href": "Probabilidade_B/LGN.html#exemplo-o-caso-bernoulli",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "Suponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\[X_i \\overset{iid}{\\sim}Bernoulli(p)\\]\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\[\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\]\nEste resultado mostra que a medida que ao jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy.",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade_B/LGN.html#exemplo-computacional",
    "href": "Probabilidade_B/LGN.html#exemplo-computacional",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "No R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(6, 4))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()",
    "crumbs": [
      "Grandes Amostras",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Int_Prob/experimento_aleatorio.html",
    "href": "Int_Prob/experimento_aleatorio.html",
    "title": "Experimento Aleatório, Espaço Amostral e Eventos",
    "section": "",
    "text": "Experimentos aleatórios são situação na natureza que envolvem incertezas. A busca por avaliar as diversas probabilidades de ocorrência é um dos objetivos no estudo desses fenômenos.\nO espaço amostral é o conjunto de todos os possíveis resultados de um experimento aleatório e é representado por \\(\\Omega\\). Cada resultado possível é denominado ponto ou elemento de \\(\\Omega\\) e denotado por \\(\\omega\\). Assim, escrevemos \\(\\omega \\in \\Omega\\) para indicar que \\(\\omega\\) está em \\(\\Omega\\). O conjunto sem elementos é o conjunto vazio, denotado por \\(\\emptyset\\). Muitos autores (Magalhães (2006), James (2023), DeGroot e Schervish (2012)), denominam eventos (ou conjunto) como sendo letras maiúsculas do alfabeto, tais como A, B, etc. Assim:\nDefinição Seja \\(\\Omega\\) o espaço amostral do experimento. Todo subconjunto \\(A \\in \\Omega\\) será chamado evento. \\(\\Omega\\) é o evento certo, \\(\\emptyset\\) o evento impossível. Se \\(\\omega \\in \\Omega\\), o evento \\(\\{\\omega\\}\\) é dito elementar (ou simples).\n\n\n\n\n\nLei Comutativa: \\(A \\cup B = B \\cup A\\) e, também, \\(A \\cap B = B \\cap A\\)\nLei Associativa: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\) e, também, \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\)\nLei Distributiva: \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) e, também, \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A^c\\) (ou \\(\\bar{A}\\)) é o complementar de \\(A\\), isto é, todos os elementos de \\(\\Omega\\) exceto os de \\(A\\)\n\\(A_1 \\cup A_2 ... \\cup A_n\\) ou \\(\\bigcup\\limits_{i=1}^{n}A_i\\) é a união de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem à pelo menos um \\(A_i\\)\n\\(A_1 \\cap A_2 ... \\cap A_n\\) ou \\(\\bigcap\\limits_{i=1}^{n}A_i\\) é a intersecção de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem simultaneamente à todos os \\(A_i\\)’s.\n\\(A-B\\) é a diferença entre \\(A\\) e \\(B\\), isto é, todos os elementos de \\(A\\), exceto os que estão em \\(B\\). Outra forma de notação é \\(A \\cap B^c\\), pois \\(A-B = A \\cap B^c\\)\nSe todo o elemento de \\(A\\) é também um elemento de \\(B\\), então \\(A\\) é definido como um subconjunto de \\(B\\) e escrevemos \\(A \\subset B\\) ou \\(B \\supset A\\). Interpretamos como sendo “\\(A\\) está contido em \\(B\\)” ou “\\(B\\) contém \\(A\\)”\nDois conjuntos são disjuntos ou mutuamente excludentes se a sua interseção é vazio. Assim, \\(A\\ e\\ B\\ disjuntos \\iff A \\cap B = \\emptyset\\)\n\n\n\n\nUma maneiras mais intuitivas de visualizar essas relações entre conjuntos é via Diagramas de Venn. Abaixo, podemos ver algumas das relações:\n\n\n\nExtraído do Mood, Graybill, e Boes (1974)\n\n\n\n\n\nAs Leis de DeMorgan, ilustrada também no Diagrama de Venn anterior, são teoremas fundamentais que descrevem relações entre a união e interesecção entre conjuntos e de seus complementos.\nO caso simples pode ser descrito abaixo:\n\\[\n\\begin{align*}\n(A \\cup B)^c = A^c \\cap B^c \\\\\n(A \\cap B)^c = A^c \\cup B^c\n\\end{align*}\n\\]\nImagine as duas frases:\n\nA: “Está chovendo”\nB: “Está frio”\n\nPortanto:\n\nA negação de “Está chovendo e está frio” (\\(A \\cap B\\)) é “Não está chovendo ou não está frio” (\\(A^c \\cup B^c\\));\nA negação de “Está chovendo ou está frio” (\\(A \\cap B\\)) é “Não está chovendo e não está frio” (\\(A^c \\cap B^c\\)).\n\nCaso geral:\n\\[\n\\begin{align*}\n\\left( \\bigcup\\limits_{i=1}^{n} A_i \\right)^c = \\bigcap\\limits_{i=1}^{n} A_i^c \\\\\n\\left( \\bigcap\\limits_{i=1}^{n} A_i \\right)^c = \\bigcup\\limits_{i=1}^{n} A_i^c\n\\end{align*}\n\\]\nVale ressaltar também que essa relação vale também quando \\(n = \\infty\\), ou seja:\n\\[\n\\begin{align*}\n\\left( \\bigcup\\limits_{i=1}^{\\infty} A_i \\right)^c = \\bigcap\\limits_{i=1}^{\\infty} A_i^c \\\\\n\\left( \\bigcap\\limits_{i=1}^{\\infty} A_i \\right)^c = \\bigcup\\limits_{i=1}^{\\infty} A_i^c\n\\end{align*}\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Experimento Aleatório, Espaço Amostral e Eventos"
    ]
  },
  {
    "objectID": "Int_Prob/experimento_aleatorio.html#operações-básicas",
    "href": "Int_Prob/experimento_aleatorio.html#operações-básicas",
    "title": "Experimento Aleatório, Espaço Amostral e Eventos",
    "section": "",
    "text": "\\(A^c\\) é o complementar de \\(A\\), isto é, todos os elementos de \\(\\Omega\\) exceto os de \\(A\\)\n\\(A_1 \\cup A_2 ... \\cup A_n\\) ou \\(\\bigcup_{i=1}^n\\)",
    "crumbs": [
      "Conceitos Básicos",
      "Experimento Aleatório, Espaço Amostral e Eventos"
    ]
  },
  {
    "objectID": "Int_Prob/experimento_aleatorio.html#operações-básicas-e-definições",
    "href": "Int_Prob/experimento_aleatorio.html#operações-básicas-e-definições",
    "title": "Experimento Aleatório, Espaço Amostral e Eventos",
    "section": "",
    "text": "\\(A^c\\) é o complementar de \\(A\\), isto é, todos os elementos de \\(\\Omega\\) exceto os de \\(A\\)\n\\(A_1 \\cup A_2 ... \\cup A_n\\) ou \\(\\bigcup\\limits_{i=1}^{n}\\) é a união de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem à pelo menos um \\(A_i\\)\n\\(A_1 \\cap A_2 ... \\cap A_n\\) ou \\(\\bigcap\\limits_{i=1}^{n}\\) é a intersecção de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem simultaneamente à todos os \\(A_i\\)’s.\n\\(A-B\\) é a diferença entre \\(A\\) e \\(B\\), isto é, todos os elementos de \\(A\\), exceto os que estão em \\(B\\). Outra forma de notação é \\(A \\cap B^c\\), pois \\(A-B = A \\cap B^c\\)\nSe todo o elemento de \\(A\\) é também um elemento de \\(B\\), então \\(A\\) é definido como um subconjunto de \\(B\\) e escrevemos \\(A \\subset B\\) ou \\(B \\supset A\\). Interpretamos como sendo “\\(A\\) está contido em \\(B\\)” ou “\\(B\\) contém \\(A\\)”",
    "crumbs": [
      "Conceitos Básicos",
      "Experimento Aleatório, Espaço Amostral e Eventos"
    ]
  },
  {
    "objectID": "Int_Prob/experimento_aleatorio.html#eventosconjuntos",
    "href": "Int_Prob/experimento_aleatorio.html#eventosconjuntos",
    "title": "Experimento Aleatório, Espaço Amostral e Eventos",
    "section": "",
    "text": "Lei Comutativa: \\(A \\cup B = B \\cup A\\) e, também, \\(A \\cap B = B \\cap A\\)\nLei Associativa: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\) e, também, \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\)\nLei Distributiva: \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) e, também, \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A^c\\) (ou \\(\\bar{A}\\)) é o complementar de \\(A\\), isto é, todos os elementos de \\(\\Omega\\) exceto os de \\(A\\)\n\\(A_1 \\cup A_2 ... \\cup A_n\\) ou \\(\\bigcup\\limits_{i=1}^{n}A_i\\) é a união de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem à pelo menos um \\(A_i\\)\n\\(A_1 \\cap A_2 ... \\cap A_n\\) ou \\(\\bigcap\\limits_{i=1}^{n}A_i\\) é a intersecção de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem simultaneamente à todos os \\(A_i\\)’s.\n\\(A-B\\) é a diferença entre \\(A\\) e \\(B\\), isto é, todos os elementos de \\(A\\), exceto os que estão em \\(B\\). Outra forma de notação é \\(A \\cap B^c\\), pois \\(A-B = A \\cap B^c\\)\nSe todo o elemento de \\(A\\) é também um elemento de \\(B\\), então \\(A\\) é definido como um subconjunto de \\(B\\) e escrevemos \\(A \\subset B\\) ou \\(B \\supset A\\). Interpretamos como sendo “\\(A\\) está contido em \\(B\\)” ou “\\(B\\) contém \\(A\\)”\nDois conjuntos são disjuntos ou mutuamente excludentes se a sua interseção é vazio. Assim, \\(A\\ e\\ B\\ disjuntos \\iff A \\cap B = \\emptyset\\)\n\n\n\n\nUma maneiras mais intuitivas de visualizar essas relações entre conjuntos é via Diagramas de Venn. Abaixo, podemos ver algumas das relações:\n\n\n\nExtraído do Mood, Graybill, e Boes (1974)\n\n\n\n\n\nAs Leis de DeMorgan, ilustrada também no Diagrama de Venn anterior, são teoremas fundamentais que descrevem relações entre a união e interesecção entre conjuntos e de seus complementos.\nO caso simples pode ser descrito abaixo:\n\\[\n\\begin{align*}\n(A \\cup B)^c = A^c \\cap B^c \\\\\n(A \\cap B)^c = A^c \\cup B^c\n\\end{align*}\n\\]\nImagine as duas frases:\n\nA: “Está chovendo”\nB: “Está frio”\n\nPortanto:\n\nA negação de “Está chovendo e está frio” (\\(A \\cap B\\)) é “Não está chovendo ou não está frio” (\\(A^c \\cup B^c\\));\nA negação de “Está chovendo ou está frio” (\\(A \\cap B\\)) é “Não está chovendo e não está frio” (\\(A^c \\cap B^c\\)).\n\nCaso geral:\n\\[\n\\begin{align*}\n\\left( \\bigcup\\limits_{i=1}^{n} A_i \\right)^c = \\bigcap\\limits_{i=1}^{n} A_i^c \\\\\n\\left( \\bigcap\\limits_{i=1}^{n} A_i \\right)^c = \\bigcup\\limits_{i=1}^{n} A_i^c\n\\end{align*}\n\\]\nVale ressaltar também que essa relação vale também quando \\(n = \\infty\\), ou seja:\n\\[\n\\begin{align*}\n\\left( \\bigcup\\limits_{i=1}^{\\infty} A_i \\right)^c = \\bigcap\\limits_{i=1}^{\\infty} A_i^c \\\\\n\\left( \\bigcap\\limits_{i=1}^{\\infty} A_i \\right)^c = \\bigcup\\limits_{i=1}^{\\infty} A_i^c\n\\end{align*}\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Experimento Aleatório, Espaço Amostral e Eventos"
    ]
  },
  {
    "objectID": "Int_Prob/conceitos_de_probabilidade.html",
    "href": "Int_Prob/conceitos_de_probabilidade.html",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "Segundo Magalhães (2006), a definição clássica de probabilidade se refere à subconjuntos unitários equiprováveis. No caso enumerável finito temos:\n\\[\nP(A) = \\frac{Número\\ de\\ Elementos\\ em\\ A}{Número\\ total\\ de\\ Elementos\\ em\\ \\Omega}\n\\]\nSe \\(\\Omega\\) tiver uma quantidade infinita de elementos, precisamos tratar a a definição acima com o uso de limites.\n\n\n\nQuando \\(\\Omega\\) é não enumerável, o conceito se aplicará ao comprimento de intervalos, medidas de áreas ou similares, dando origem ao que chamamos de probabilidade geométrica. Por exemplo, se \\(\\Omega\\) é um intervalo onde \\(\\Omega \\in \\mathbb{R}\\), então:\n\\[\nP(A) = \\frac{Comprimento\\ de\\ A}{Comprimento\\ de\\ \\Omega}\n\\]\n\n\n\nA definição frequentista considera o limite de frequências relativas como o valor da probabilidade. Para tal, seja \\(n_{A}\\) o número de ocorrências de \\(A\\) em \\(n\\) repetições independentes do experimento em questão. Assim,\n\\[\nP(A) = \\lim_{n\\rightarrow{+\\infty}} \\frac{n_A}{n}\n\\]\n\n\n\nAs definições anteriores não são suficientes para uma formulação matemática mais rigorosa da probabilidade. Assim, na primeira metade do século XX, Kolmogorov (1933) apresentou um conjunto de axiomas matemáticos para definir probabilidade e, assim, pavimentando toda a evolução da probabilidade moderna.\nÉ importante, e ao mesmo tempo fascinante, destacar que apenas com esses três axiomas todos os teoremas da Teoria da Probabilidade são viabilizados. Assim, podemos destacar que toda a evolução da probabilidade foi pavimentada pelo trabalho de Kolmogorov (1933).\nDefinição axiomática\nAssumindo que podemos atribuir um número real \\(P(A)\\) para um evento \\(A\\):\n\nAxioma 1. \\(P(A) \\ge 0\\)\nAxioma 2. \\(P(\\Omega) = 1\\)\nAxioma 3. Se \\(A_1, A_2, ..., A_n\\) são disjuntos (2 a 2) (isto é, mutuamente excludentes), então\n\n\\[\nP\\left( \\bigcup_{k=1}^{n} A_k \\right) = \\sum_{k=1}^{n} P (A_k)\n\\]\n(Os eventos são disjuntos 2 a 2, se \\(A_i \\cap A_j = \\emptyset, \\forall i \\ne j\\))\nUma discussão mais aprofundada desses axiomas, incluindo uma versão mais conveniente para o Axioma 3 (para o caso \\(n = \\infty\\)) e uma “Axioma 4” de continuidade no vazio, que pode ser derivado dos outros axiomas, é discutida no Capítulo 1 de James (2023).\n\n\nComo comentado, os Axiomas de Kolmogorov sustentam toda a teoria da probabilidade e alguns resultados diretos são:\n\n\\(P(\\emptyset) = 0\\).\n\nProva.\n\\[\n\\begin{align*}\nP(A \\cup \\emptyset) &= P(A) + P(\\emptyset) \\\\\nP(A) &= P(A) + P(\\emptyset) \\\\\nP(\\emptyset) &= 0\n\\end{align*}\n\\]\n\nPara qualquer evento \\(A\\), \\(P(A^c) = 1-P(A)\\).\n\nProva.\n\\[\n\\begin{align*}\nP(\\Omega) &= P(A \\cup A^c) = P(A) + P(A^c) \\\\\n1 &= P(A) + P(A^c) \\overset{\\text{Isolando}}{\\implies} P(A^c) = 1-P(A)\n\\end{align*}\n\\]\n\nSe \\(A \\subset B\\), então \\(P(A) \\le P(B)\\).\n\nProva.\n\\[\n\\begin{align*}\nP(B) &= P(A \\cup (B \\cap A^c)) = P(A) + P(B \\cap A^c) \\\\\nP(B) &\\ge P(A)\n\\end{align*}\n\\]\n\nSe \\(A \\subset B\\), então \\(P(A \\cap B) = P(A)\\).\nPara qualquer evento \\(A\\), \\(0 \\le P(A) \\le 1\\).\n\nProva. Como \\(A \\subset \\Omega\\), então \\(0 \\le P(A) \\le P(\\Omega) = 1\\)\n\nPara quaisquer eventos \\(A\\) e \\(B\\), \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) (Esta relação é mais fácil de visualizar via Diagrama de Venn)\n\nProva.\nPrimeiro, vamos escrever \\(P(A)\\) e \\(P(B)\\) como a soma de suas partes:\n\\[\nP(A) = P(A \\cap B^c) + P(A \\cap B) \\\\\nP(B) = P(B \\cap A^c) + P(B \\cap A)\n\\]\nAgora, vamos escrever a união como a soma de suas partes:\n\\[\nP(A \\cup B) = P(A \\cap B^c) + P(A \\cap B) + P(B \\cap A^c)\n\\]\nAgora, somando e substraindo \\(P(A \\cap B)\\):\n\\[\n\\begin{align*}\nP(A \\cup B) &= \\overbrace{P(A \\cap B^c) + P(A \\cap B)}^{P(A)} + \\overbrace{P(B \\cap A^c) + P(A \\cap B)}^{P(B)} - P(A \\cap B) \\\\\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B)\n\\end{align*}\n\\]\n\n(Desigualdade de Boole) Sejam \\(A_1, A_2, ..., A_n\\) então\n\n\\[\nP\\left( \\bigcup_{i=1}^{n} A_i  \\right) \\le \\sum_{i=1}^{n}P(A_i)\n\\]\n\n\n\n\nUm Espaço de Probabilidade é um constructo que provê um modelo formal de um processo aleatório. Ele é composto por uma tríplice de valores \\((\\Omega, \\mathcal{F}, P)\\) onde\n\n\\(\\Omega\\) é todo o espaço amostral\n\\(\\mathcal{F}\\) (ou \\(\\sigma\\)-álgebra) é o espaço de eventos (domínio)\n\\(P\\) é uma função de probabilidade aplicada em \\(\\mathcal{F}\\) que produz valores no intervalo \\([0,1]\\)\n\nPara um entendimento mais consistente da importância da definição de um espaço de probabilidade, bem como da importância da definição de uma \\(\\sigma\\)-álgebra, que é o domínio do espaço, recomenda-se a leitura do Capítulo 1 de James (2023), Capítulo 1 de Magalhães (2006), Capítulo 2B e 12 de Axler (2020).1 No entanto, como esta discussão é mais aprofundada, para uma visão mais geral recomendo fortemente o leitor a assitir o vídeo Bertrand’s Paradox (with 3blue1brown) - Numberphile (explicação do Exemplo 1.8 de Magalhães (2006)) para esclarecer qual o efeito da definição de diferentes espaços de probabiidade para um mesmo problema e assim produzir probabilidades significativamente diferentes dependendo da maneira como são definidos \\(\\Omega\\) e \\(\\sigma\\)-álgebra e, assim, produzindo diferentes processos geradores de eventos.",
    "crumbs": [
      "Conceitos Básicos",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/conceitos_de_probabilidade.html#probabilidade-axiomática",
    "href": "Int_Prob/conceitos_de_probabilidade.html#probabilidade-axiomática",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "As definições anteriores não são suficientes para uma formulação matemática mais rigorosa da probabilidade. Assim, na primeira metade do século XX, Kolmogorov (1933) apresentou um conjunto de axiomas matemáticos para definir probabilidade e, assim, pavimentando toda a evolução da probabilidade moderna.\nÉ importante, e ao mesmo tempo fascinante, destacar que apenas com esses três axiomas todos os teoremas da Teoria da Probabilidade são viabilizados. Assim, podemos destacar que toda a evolução da probabilidade foi pavimentada pelo trabalho de Kolmogorov (1933).\nDefinição axiomática\nAssumindo que podemos atribuir um número real \\(P(A)\\) para um evento \\(A\\):\n\nAxioma 1. \\(P(A) \\ge 0\\)\nAxioma 2. \\(P(\\Omega) = 1\\)\nAxioma 3. Se \\(A_1, A_2, ..., A_n\\) são disjuntos (2 a 2) (isto é, mutuamente excludentes), então\n\n\\[\nP\\left( \\bigcup_{k=1}^{n} A_k \\right) = \\sum_{k=1}^{n} P (A_k)\n\\]\n(Os eventos são disjuntos 2 a 2, se \\(A_i \\cap A_j = \\emptyset, \\forall i \\ne j\\))\nUma discussão mais aprofundada desses axiomas, incluindo uma versão mais conveniente para o Axioma 3 (para o caso \\(n = \\infty\\)) e uma “Axioma 4” de continuidade no vazio, que pode ser derivado dos outros axiomas, é discutida no Capítulo 1 de James (2023).\n\n\nComo comentado, os Axiomas de Kolmogorov sustentam toda a teoria da probabilidade e alguns resultados diretos são:\n\n\\(P(\\emptyset) = 0\\).\n\nProva.\n\\[\n\\begin{align*}\nP(A \\cup \\emptyset) &= P(A) + P(\\emptyset) \\\\\nP(A) &= P(A) + P(\\emptyset) \\\\\nP(\\emptyset) &= 0\n\\end{align*}\n\\]\n\nPara qualquer evento \\(A\\), \\(P(A^c) = 1-P(A)\\).\n\nProva.\n\\[\n\\begin{align*}\nP(\\Omega) &= P(A \\cup A^c) = P(A) + P(A^c) \\\\\n1 &= P(A) + P(A^c) \\overset{\\text{Isolando}}{\\implies} P(A^c) = 1-P(A)\n\\end{align*}\n\\]\n\nSe \\(A \\subset B\\), então \\(P(A) \\le P(B)\\).\n\nProva.\n\\[\n\\begin{align*}\nP(B) &= P(A \\cup (B \\cap A^c)) = P(A) + P(B \\cap A^c) \\\\\nP(B) &\\ge P(A)\n\\end{align*}\n\\]\n\nSe \\(A \\subset B\\), então \\(P(A \\cap B) = P(A)\\).\nPara qualquer evento \\(A\\), \\(0 \\le P(A) \\le 1\\).\n\nProva. Como \\(A \\subset \\Omega\\), então \\(0 \\le P(A) \\le P(\\Omega) = 1\\)\n\nPara quaisquer eventos \\(A\\) e \\(B\\), \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) (Esta relação é mais fácil de visualizar via Diagrama de Venn)\n\nProva.\nPrimeiro, vamos escrever \\(P(A)\\) e \\(P(B)\\) como a soma de suas partes:\n\\[\nP(A) = P(A \\cap B^c) + P(A \\cap B) \\\\\nP(B) = P(B \\cap A^c) + P(B \\cap A)\n\\]\nAgora, vamos escrever a união como a soma de suas partes:\n\\[\nP(A \\cup B) = P(A \\cap B^c) + P(A \\cap B) + P(B \\cap A^c)\n\\]\nAgora, somando e substraindo \\(P(A \\cap B)\\):\n\\[\n\\begin{align*}\nP(A \\cup B) &= \\overbrace{P(A \\cap B^c) + P(A \\cap B)}^{P(A)} + \\overbrace{P(B \\cap A^c) + P(A \\cap B)}^{P(B)} - P(A \\cap B) \\\\\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B)\n\\end{align*}\n\\]\n\n(Desigualdade de Boole) Sejam \\(A_1, A_2, ..., A_n\\) então\n\n\\[\nP\\left( \\bigcup_{i=1}^{n} A_i  \\right) \\le \\sum_{i=1}^{n}P(A_i)\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/conceitos_de_probabilidade.html#definição-clássica-omega-enumerável",
    "href": "Int_Prob/conceitos_de_probabilidade.html#definição-clássica-omega-enumerável",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "Segundo Magalhães (2006), a definição clássica de probabilidade se refere à subconjuntos unitários equiprováveis. No caso enumerável finito temos:\n\\[\nP(A) = \\frac{Número\\ de\\ Elementos\\ em\\ A}{Número\\ total\\ de\\ Elementos\\ em\\ \\Omega}\n\\]\nSe \\(\\Omega\\) tiver uma quantidade infinita de elementos, precisamos tratar a a definição acima com o uso de limites.",
    "crumbs": [
      "Conceitos Básicos",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/conceitos_de_probabilidade.html#definição-clássica-geométrica-omega-não-enumerável",
    "href": "Int_Prob/conceitos_de_probabilidade.html#definição-clássica-geométrica-omega-não-enumerável",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "Quando \\(\\Omega\\) é não enumerável, o conceito se aplicará ao comprimento de intervalos, medidas de áreas ou similares, dando origem ao que chamamos de probabilidade geométrica. Por exemplo, se \\(\\Omega\\) é um intervalo onde \\(\\Omega \\in \\mathbb{R}\\), então:\n\\[\nP(A) = \\frac{Comprimento\\ de\\ A}{Comprimento\\ de\\ \\Omega}\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/conceitos_de_probabilidade.html#espaços-de-probabilidade",
    "href": "Int_Prob/conceitos_de_probabilidade.html#espaços-de-probabilidade",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "Um Espaço de Probabilidade é um constructo que provê um modelo formal de um processo aleatório. Ele é composto por uma tríplice de valores \\((\\Omega, \\mathcal{F}, P)\\) onde\n\n\\(\\Omega\\) é todo o espaço amostral\n\\(\\mathcal{F}\\) (ou \\(\\sigma\\)-álgebra) é o espaço de eventos (domínio)\n\\(P\\) é uma função de probabilidade aplicada em \\(\\mathcal{F}\\) que produz valores no intervalo \\([0,1]\\)\n\nPara um entendimento mais consistente da importância da definição de um espaço de probabilidade, bem como da importância da definição de uma \\(\\sigma\\)-álgebra, que é o domínio do espaço, recomenda-se a leitura do Capítulo 1 de James (2023), Capítulo 1 de Magalhães (2006), Capítulo 2B e 12 de Axler (2020).1 No entanto, como esta discussão é mais aprofundada, para uma visão mais geral recomendo fortemente o leitor a assitir o vídeo Bertrand’s Paradox (with 3blue1brown) - Numberphile (explicação do Exemplo 1.8 de Magalhães (2006)) para esclarecer qual o efeito da definição de diferentes espaços de probabiidade para um mesmo problema e assim produzir probabilidades significativamente diferentes dependendo da maneira como são definidos \\(\\Omega\\) e \\(\\sigma\\)-álgebra e, assim, produzindo diferentes processos geradores de eventos.",
    "crumbs": [
      "Conceitos Básicos",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/conceitos_de_probabilidade.html#definição-frequentista",
    "href": "Int_Prob/conceitos_de_probabilidade.html#definição-frequentista",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "A definição frequentista considera o limite de frequências relativas como o valor da probabilidade. Para tal, seja \\(n_{A}\\) o número de ocorrências de \\(A\\) em \\(n\\) repetições independentes do experimento em questão. Assim,\n\\[\nP(A) = \\lim_{n\\rightarrow{+\\infty}} \\frac{n_A}{n}\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/conceitos_de_probabilidade.html#footnotes",
    "href": "Int_Prob/conceitos_de_probabilidade.html#footnotes",
    "title": "Conceitos de Probabilidade",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nO conceito de \\(\\sigma\\)-álgebra (bem como de sua versão finita – Álgebra), em um primeiro momento, pode ser considerado difícil de assimilar do ponto de vista prático. No entanto, ela é fundamental para garantir uma base matemática sólida para toda a teoria da probabilidade. As propriedades desejáveis de uma \\(\\sigma\\)-álgebra garantem que o espaço de probabilidade é um espaço mensurável. Por exemplo, uma das condições é de que se \\(A_1\\) e \\(A_2\\) são dois eventos sendo \\(A_1 \\in \\mathcal{F}\\) e \\(A_2 \\in \\mathcal{F}\\), então \\((A_1 \\cup A_2) \\in \\mathcal{F}\\). Se essa condição não fosse satisfeita, os axiomas de Kolmogorov não poderiam ser naturalmente aplicados à este espaço e potencialmente inconsistências poderiam ser geradas. Por exemplo, seguindo o Exemplo 1.3 de Magalhães (2006), considerando \\(\\Omega = \\{1, 2, 3\\}\\), suponha \\(\\mathcal{F} = \\{ \\emptyset, \\Omega, \\{1\\}, \\{2\\}, \\{1,3\\}, \\{2,3\\} \\}\\) não é uma \\(\\sigma\\)-álgebra pois \\(\\{1, 2\\} \\notin \\mathcal{F}\\) e, portanto, \\(P(\\{1, 2\\})\\) é indefinido. Portanto, não poderíamos, por exemplo, aplicar o terceiro axioma de Kolmogorov para calcular \\(P(\\{1, 2\\})\\). Neste exemplo, a definição de \\(\\mathcal{F}\\) viola o Axioma do Par que é uma dos axiomas fundamentais da Teoria dos Conjuntos de Zermelo–Fraenkel. Adicionamente, discussão possui relação com outros conceitos matemáticos como Aditividade Contável de uma \\(\\sigma\\)-álgebra, o Axioma da Escolha e o Paradoxo de Banach-Tarski. Recomenda-se também assistir o vídeo The Man Who Almost Broke Math (And Himself…).↩︎",
    "crumbs": [
      "Conceitos Básicos",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/probabilidade_condicional_e_independencia.html",
    "href": "Int_Prob/probabilidade_condicional_e_independencia.html",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Definição Sejam dois eventos \\(A\\) e \\(B\\) definidos no mesmo espaço de probabilidade, a probabilidade condicional de \\(A\\) dado o evento \\(B\\), denotado por \\(P(A|B)\\) é definido por\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\ \\ \\ \\ se \\ P(B) &gt; 0,\n\\]\ne é indefinida se \\(P(B) = 0\\). Um resultado direto dessa definição é que \\(P(A|B)P(B) = P(B|A)P(A)\\).\nExemplo Suponha o lançamento de um Dado Honesto, ou seja, \\(\\Omega = \\{\\{1\\}, \\{2\\}, \\{3\\}, \\{4\\}, \\{5\\}, \\{6\\}\\}\\), qual a probabilidade de sair o número 2, dado que saiu um número par?\nSeja,\n\n\\(A\\): sair o número 2\n\\(B\\): sair par\n\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(\\text{sair 2 e par})}{P(\\text{par})}  \\overset{A \\subset B}{=} \\frac{P(\\text{sair 2})}{P(\\text{par})}  = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}\n\\]\nNote que “dado o evento \\(B\\)” significa dizer que o “evento \\(B\\)” ocorreu e, sendo assim, “limitamos” o espaço amostral para o evento B. Ou seja, não estamos mais trabalhando com \\(\\Omega\\), mas sim somente com os elementos do evento \\(B\\) sendo possíveis. Dado isto, será que este novo cenário satisfazem os axiomas de Kolmogorov caso \\(P(B)&gt;0\\)? A resposta é sim, pois:\n\n\\(P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\ge 0, \\forall A \\in \\mathcal{F}\\)\n\\(P(\\Omega|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(B)}{P(B)} = 1\\)\nSe \\(A_1, A_2, ...\\) são mutuamente excludentes de \\(\\mathcal{F}\\), então\n\n\\[\nP\\left( \\bigcup_{i=1}^{n} A_i |B \\right) = \\frac{P\\left( \\left(\\bigcup_{i=1}^{n} A_i \\right)\\cap B \\right)}{P(B)} \\overset{Lei \\ Distributiva}{=} \\frac{P\\left( \\bigcup_{i=1}^{n} \\left(A_i \\cap B \\right)\\right)}{P(B)} = \\frac{\\sum_{i=1}^{n}P\\left( A_i \\cap B \\right)}{P(B)} = \\sum_{i=1}^{n}\\left(\\frac{P(A_i \\cap B) }{P(B)}\\right) = \\sum_{i=1}^{n}P\\left( A_i | B \\right)\n\\] Desta maneira, para quaquer \\(B\\) satisfazendo \\(P(B) &gt; 0\\), qualquer função de probabilidade aplicada no subespaço de \\(B\\) também é uma função de probabilidade e goza das mesmas propriedades de uma função não-condicionada.\n\n\nAntes de apresentar o teorema da probabilidade total, apresenta-se a definição de partição do espaço amostral:\nDefinição Se \\(B_1, B_2, ..., B_n\\) representa um conjunto de eventos mutuamente excludentes satisfazendo \\(\\Omega = \\bigcup\\limits_{i=1}^{n}B_i\\) então, dizemos que \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\).\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\):\n\\[\nP(A) = P\\left(\\bigcup\\limits_{i=1}^{n}(A \\cap B_i)\\right) = \\sum\\limits_{i=1}^{n}P(A \\cap B_i) = \\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)\n\\]\nVisualmente:\n\n\n\nExemplo de uma partição de \\(\\Omega\\) para \\(n = 5\\) e um evento A (extraído de DeGroot e Schervish (2012))\n\n\nRessalta-se que o Teorema da Probabilidade Total vale também quando \\(n = \\infty\\)\n\n\n\nO Teorema de Bayese, na sua forma extendida1, é visto como a probabilidade de um evento de uma partição condicionado à um evento já ocorrido do espaço amostral. A fórmula de Bayes é definida a seguir:\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\) temos que\n\\[\nP(B_i |A) = \\frac{P(A | B_i) P(B_i)} {\\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)} \\ \\ \\ \\forall i=1,...n.\n\\] Ressalta-se que o Teorema de Bayes vale também quando \\(n = \\infty\\).\nObserve que o denominador da Fórmula de Bayes é o valor do Teorema da Probabilidade Total definida anteriormente.\nO Teorema de Bayes é particularmente útil quando estamos tratando com experimentos em múltiplas fases. Se \\(B_i\\) é um evento condicionado à um evento \\(A\\), então querer saber \\(P(B_i|A)\\) é como se fosse no sentido de retrospectiva (“backward”). É como se fosse questionar sobre a probabilidade da primeira fase, condicionada no que aconteceu na segunda fase do experimento. Por isso, o Teorema de Bayes também é chamado de teorema da probabilidade a posteriori (Morettin (1999)).\nExemplo Suponha que em uma urna nós temos três moedas: sendo duas honestas e uma viciada com duas faces “caras”. Suponha que eu retire, aleatoriamente, uma moeda urna e jogue pra cima e saia a face “cara”. Então, dado que saiu “cara”, qual a probabilidade de eu ter sorteado a moeda viciada?\nPodemos pensar neste problema da seguinte forma ilustrativa:\n\n\n\nIlustração de experimento de duas fases\n\n\nOriginalmente, \\(P(B_3) = \\frac{1}{3}\\), no entanto, a probabilidade condicionada a posteriori é:\n\\[\nP(B_3|A) = \\frac{P(A | B_3) P(B_3)} {P(A | B_1)P(B_1) + P(A | B_2)P(B_2) + P(A | B_3)P(B_3)} = \\frac{1 \\times \\frac{1}{3}} {\\frac{1}{2} \\times \\frac{1}{3} + \\frac{1}{2} \\times \\frac{1}{3} + 1\\times \\frac{1}{3}} = \\frac{\\frac{1}{3}}{\\frac{4}{6}} = \\frac{1}{2}\n\\]\nOu seja, note que a probabilidade “atualizou” de \\(\\frac{1}{3}\\) para \\(\\frac{1}{2}\\).\n\n\n\nOutro resultado importante é a regra da multiplicação abaixo:\nTeorema Sejam \\(A_1, A_2, ..., A_n\\) diferentes eventos de um espaço de probabilidade, então:\n\\[\nP(A_1 \\cap A_2 \\cap ... \\cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2 \\cap A_1)...P(A_n|A_1 \\cap ... \\cap A_{n-1})\n\\]\nOu, conforme Mood, Graybill, e Boes (1974), em notação alternativa:\n\\[\nP(A_1A_2 ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2A_1)...P(A_n|A_1... A_{n-1})\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/probabilidade_condicional_e_independencia.html#definição",
    "href": "Int_Prob/probabilidade_condicional_e_independencia.html#definição",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Sejam dois eventos \\(A\\) e \\(B\\) definidos no mesmo espaço de probabilidade, a probabilidade condicional de \\(A\\) dado o evento \\(B\\), denotado por \\(P(A|B)\\) é definido por\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\ \\ \\ \\ se \\ P(B) &gt; 0,\n\\]\ne é indefinida se \\(P(B) = 0\\)",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/probabilidade_condicional_e_independencia.html#footnotes",
    "href": "Int_Prob/probabilidade_condicional_e_independencia.html#footnotes",
    "title": "Probabilidade Condicional e Independência",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nUm vídeo interessante sobre a aplicação e explicação do Teorema de Bayes pode ser visto aqui: A Armadilha Bayesiana↩︎",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/probabilidade_condicional_e_independencia.html#teorema-da-probabilidade-total",
    "href": "Int_Prob/probabilidade_condicional_e_independencia.html#teorema-da-probabilidade-total",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Antes de apresentar o teorema da probabilidade total, apresenta-se a definição de partição do espaço amostral:\nDefinição Se \\(B_1, B_2, ..., B_n\\) representa um conjunto de eventos mutuamente excludentes satisfazendo \\(\\Omega = \\bigcup\\limits_{i=1}^{n}B_i\\) então, dizemos que \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\).\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\):\n\\[\nP(A) = P\\left(\\bigcup\\limits_{i=1}^{n}(A \\cap B_i)\\right) = \\sum\\limits_{i=1}^{n}P(A \\cap B_i) = \\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)\n\\]\nVisualmente:\n\n\n\nExemplo de uma partição de \\(\\Omega\\) para \\(n = 5\\) e um evento A (extraído de DeGroot e Schervish (2012))\n\n\nRessalta-se que o Teorema da Probabilidade Total vale também quando \\(n = \\infty\\)",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/probabilidade_condicional_e_independencia.html#teorema-de-bayes",
    "href": "Int_Prob/probabilidade_condicional_e_independencia.html#teorema-de-bayes",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "O Teorema de Bayese, na sua forma extendida1, é visto como a probabilidade de um evento de uma partição condicionado à um evento já ocorrido do espaço amostral. A fórmula de Bayes é definida a seguir:\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\) temos que\n\\[\nP(B_i |A) = \\frac{P(A | B_i) P(B_i)} {\\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)} \\ \\ \\ \\forall i=1,...n.\n\\] Ressalta-se que o Teorema de Bayes vale também quando \\(n = \\infty\\).\nObserve que o denominador da Fórmula de Bayes é o valor do Teorema da Probabilidade Total definida anteriormente.\nO Teorema de Bayes é particularmente útil quando estamos tratando com experimentos em múltiplas fases. Se \\(B_i\\) é um evento condicionado à um evento \\(A\\), então querer saber \\(P(B_i|A)\\) é como se fosse no sentido de retrospectiva (“backward”). É como se fosse questionar sobre a probabilidade da primeira fase, condicionada no que aconteceu na segunda fase do experimento. Por isso, o Teorema de Bayes também é chamado de teorema da probabilidade a posteriori (Morettin (1999)).\nExemplo Suponha que em uma urna nós temos três moedas: sendo duas honestas e uma viciada com duas faces “caras”. Suponha que eu retire, aleatoriamente, uma moeda urna e jogue pra cima e saia a face “cara”. Então, dado que saiu “cara”, qual a probabilidade de eu ter sorteado a moeda viciada?\nPodemos pensar neste problema da seguinte forma ilustrativa:\n\n\n\nIlustração de experimento de duas fases\n\n\nOriginalmente, \\(P(B_3) = \\frac{1}{3}\\), no entanto, a probabilidade condicionada a posteriori é:\n\\[\nP(B_3|A) = \\frac{P(A | B_3) P(B_3)} {P(A | B_1)P(B_1) + P(A | B_2)P(B_2) + P(A | B_3)P(B_3)} = \\frac{1 \\times \\frac{1}{3}} {\\frac{1}{2} \\times \\frac{1}{3} + \\frac{1}{2} \\times \\frac{1}{3} + 1\\times \\frac{1}{3}} = \\frac{\\frac{1}{3}}{\\frac{4}{6}} = \\frac{1}{2}\n\\]\nOu seja, note que a probabilidade “atualizou” de \\(\\frac{1}{3}\\) para \\(\\frac{1}{2}\\).",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/probabilidade_condicional_e_independencia.html#regra-da-multiplicação",
    "href": "Int_Prob/probabilidade_condicional_e_independencia.html#regra-da-multiplicação",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Outro resultado importante é a regra da multiplicação abaixo:\nTeorema Sejam \\(A_1, A_2, ..., A_n\\) diferentes eventos de um espaço de probabilidade, então:\n\\[\nP(A_1 \\cap A_2 \\cap ... \\cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2 \\cap A_1)...P(A_n|A_1 \\cap ... \\cap A_{n-1})\n\\]\nOu, conforme Mood, Graybill, e Boes (1974), em notação alternativa:\n\\[\nP(A_1A_2 ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2A_1)...P(A_n|A_1... A_{n-1})\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/4_variaveis_aleatorias.html",
    "href": "Int_Prob/4_variaveis_aleatorias.html",
    "title": "Variáveis Aleatórias",
    "section": "",
    "text": "Informalmente, uma variável aleatória (V.A.) é um valor numérico do resultado de um experimento aleatório. Formalmente, abaixo segue a definição (Magalhães (2006), James (2023)):\nDefinição Seja \\((\\Omega, \\mathcal{F}, \\mathcal{P})\\) um espaço de probabilidade. Denominamos de variável aleatória, qualquer função \\(X : \\Omega \\rightarrow \\mathbb{R}\\) tal que \\([X \\le x]\\) é evento aleatório para todo \\(x \\in \\mathbb{R}\\); isto é, \\([X \\le x] \\in \\mathcal{F}, \\forall x \\in \\mathbb{R}\\)1.\nExemplo (Mood, Graybill, e Boes (1974)) Assuma um experimento de lançar uma moeda honesta para cima. Defina a variável aleatória \\(X\\) assumir o valor \\(1\\) quando sair cara, e o valor \\(0\\) quando sair coroa. Ou seja:\n\\[\n\\begin{align*}\n\\Omega &= \\{cara, coroa\\} \\\\\nX &=\n\\begin{cases}\n  1, & \\text{ se $\\omega$ = \\{cara\\},} \\\\\n  0, & \\text{ se $\\omega$ = \\{coroa\\}}\n\\end{cases}\n\\end{align*}\n\\]\nFormalmente, precisamos mostrar que esta construção deste experimento \\(X\\) mostrando que \\(\\{\\omega: X(\\omega) \\le x\\}\\) para todo \\(x \\in \\mathbb{R}\\) pertence à \\(\\mathcal{F}\\). Primeiramente, note que \\(\\mathcal{F}\\) é composto por quatro elementos sendo \\(\\{\\emptyset, \\Omega, \\{cara\\},\\{coroa\\}\\}\\). Agora, verificamos que se \\(x &lt; 0\\), \\(\\{\\omega: X(\\omega) \\le x\\} = \\emptyset\\); e se \\(0 \\le x &lt; 0\\), \\(\\{\\omega: X(\\omega) \\le x\\} = \\{cara\\}\\); e se \\(x \\ge 1\\), \\(\\{\\omega: X(\\omega) \\le x\\} = \\Omega = \\{cara, coroa\\}\\). Então, pra cada \\(x\\) real o evento \\(\\{\\omega: X(\\omega) \\le x\\}\\) pertence à \\(\\sigma\\)-álgebra \\(\\mathcal{F}\\) e, portanto, \\(X\\) é variável aleatória.\nExemplo (Mood, Graybill, e Boes (1974)) Assuma um experimento de lançar dois dados honestos de seis lados, sendo o dado \\(i\\) e o dado \\(j\\). Defina a variável aleatória \\(X\\) assumir o valor da soma das suas faces, ou seja, \\(X(\\omega) = i+j\\), onde \\(\\Omega = \\{(i,j): i,j = 1, 2,...,6\\}\\)\nDefinição Função de Distribuição Acumulada (FDA) A FDA de uma V.A. \\(X\\) aplicada no ponto \\(x\\) denotada por \\(F_X(x)\\), é uma função com domínio nos números reais e imagem (contra domínio) no intervalo \\([0,1]\\) que satisfaz \\(F_X(x) = P(X \\le x), \\forall x \\in \\mathbb{R}\\).\nA FDA é unicamente definida para cada variável aleatória. Ou seja, uma variável aleatória \\(X\\) possui uma única respectiva função \\(F_X(.)\\).\nPara qualquer FDA de uma V.A. \\(X\\), tem-se as seguintes propriedades:\n\n\\(0 \\le F_X(x) \\le 1\\)\n\\(F_X(x)\\) é não decrescente. Isto é, se \\(x_1 \\le x_2 \\implies F_X(x_1) \\le F_X(x_2)\\)\n\\(F_X(-\\infty) = \\lim\\limits_{n \\to -\\infty}F_X(x) = 0\\)\n\\(F_X(+\\infty) = \\lim\\limits_{n \\to +\\infty}F_X(x) = 1\\)\n\nUm ponto interessante é que a definição de uma FDA poderia ser dada simplesmente por essas propriedades. Isto é, qualquer função \\(F(.)\\) que respeite as propriedades acima será FDA de alguma variável aleatória existente (mesmo sem mencioná-la!).",
    "crumbs": [
      "Conceitos Básicos",
      "Variáveis Aleatórias"
    ]
  },
  {
    "objectID": "Int_Prob/4_variaveis_aleatorias.html#footnotes",
    "href": "Int_Prob/4_variaveis_aleatorias.html#footnotes",
    "title": "Variáveis Aleatórias",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nEsta definição formal matemática, na sua integridade, pode parece difícil de assimilar num primeiro momento. Em linhas gerais, uma variável aleatória deve ser uma função mensurável dentro da sua \\(\\sigma\\)-álgebra do espaço de probabildade. Por exemplo, é possível definir uma \\(\\sigma\\)-álgebra de maneira incoveniente e fazer com que algumas variáveis aleatórias não se encaixem como função mensurável por ter que depender de eventos aleatórios que não estejam presentes em \\(\\mathcal{F}\\). Nesse sentido, o cojunto das partes e a \\(\\sigma\\)-álgebra de Borel são as preferidas, justamente por permitirem que praticamente todas as variáveis de interesse sejam mensuráveis. Para maiores detalhes, ver o exemplo 2.1 de Magalhães (2006) e as observações da Seção 2.1 de James (2023).↩︎",
    "crumbs": [
      "Conceitos Básicos",
      "Variáveis Aleatórias"
    ]
  },
  {
    "objectID": "Int_Prob/3_probabilidade_condicional_e_independencia.html",
    "href": "Int_Prob/3_probabilidade_condicional_e_independencia.html",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Definição Sejam dois eventos \\(A\\) e \\(B\\) definidos no mesmo espaço de probabilidade, a probabilidade condicional de \\(A\\) dado o evento \\(B\\), denotado por \\(P(A|B)\\) é definido por\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\ \\ \\ \\ se \\ P(B) &gt; 0,\n\\]\ne é indefinida se \\(P(B) = 0\\). Um resultado direto dessa definição é que \\(P(A|B)P(B) = P(B|A)P(A)\\).\nExemplo Suponha o lançamento de um Dado Honesto, ou seja, \\(\\Omega = \\{\\{1\\}, \\{2\\}, \\{3\\}, \\{4\\}, \\{5\\}, \\{6\\}\\}\\), qual a probabilidade de sair o número 2, dado que saiu um número par?\nSeja,\n\n\\(A\\): sair o número 2\n\\(B\\): sair par\n\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(\\text{sair 2 e par})}{P(\\text{par})}  \\overset{A \\subset B}{=} \\frac{P(\\text{sair 2})}{P(\\text{par})}  = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}\n\\]\nNote que “dado o evento \\(B\\)” significa dizer que o “evento \\(B\\)” ocorreu e, sendo assim, “limitamos” o espaço amostral para o evento B. Ou seja, não estamos mais trabalhando com \\(\\Omega\\), mas sim somente com os elementos do evento \\(B\\) sendo possíveis. Dado isto, será que este novo cenário satisfazem os axiomas de Kolmogorov caso \\(P(B)&gt;0\\)? A resposta é sim, pois:\n\n\\(P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\ge 0, \\forall A \\in \\mathcal{F}\\)\n\\(P(\\Omega|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(B)}{P(B)} = 1\\)\nSe \\(A_1, A_2, ...\\) são mutuamente excludentes de \\(\\mathcal{F}\\), então\n\n\\[\nP\\left( \\bigcup_{i=1}^{n} A_i |B \\right) = \\frac{P\\left( \\left(\\bigcup_{i=1}^{n} A_i \\right)\\cap B \\right)}{P(B)} \\overset{Lei \\ Distributiva}{=} \\frac{P\\left( \\bigcup_{i=1}^{n} \\left(A_i \\cap B \\right)\\right)}{P(B)} = \\frac{\\sum_{i=1}^{n}P\\left( A_i \\cap B \\right)}{P(B)} = \\sum_{i=1}^{n}\\left(\\frac{P(A_i \\cap B) }{P(B)}\\right) = \\sum_{i=1}^{n}P\\left( A_i | B \\right)\n\\] Desta maneira, para quaquer \\(B\\) satisfazendo \\(P(B) &gt; 0\\), qualquer função de probabilidade aplicada no subespaço de \\(B\\) também é uma função de probabilidade e goza das mesmas propriedades de uma função não-condicionada.\n\n\nAntes de apresentar o teorema da probabilidade total, apresenta-se a definição de partição do espaço amostral:\nDefinição Se \\(B_1, B_2, ..., B_n\\) representa um conjunto de eventos mutuamente excludentes satisfazendo \\(\\Omega = \\bigcup\\limits_{i=1}^{n}B_i\\) então, dizemos que \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\).\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\):\n\\[\nP(A) = P\\left(\\bigcup\\limits_{i=1}^{n}(A \\cap B_i)\\right) = \\sum\\limits_{i=1}^{n}P(A \\cap B_i) = \\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)\n\\]\nVisualmente:\n\n\n\nExemplo de uma partição de \\(\\Omega\\) para \\(n = 5\\) e um evento A (extraído de DeGroot e Schervish (2012))\n\n\nRessalta-se que o Teorema da Probabilidade Total vale também quando \\(n = \\infty\\)\n\n\n\nO Teorema de Bayese, na sua forma extendida1, é visto como a probabilidade de um evento de uma partição condicionado à um evento já ocorrido do espaço amostral. A fórmula de Bayes é definida a seguir:\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\) temos que\n\\[\nP(B_i |A) = \\frac{P(A | B_i) P(B_i)} {\\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)} \\ \\ \\ \\forall i=1,...n.\n\\] Ressalta-se que o Teorema de Bayes vale também quando \\(n = \\infty\\).\nObserve que o denominador da Fórmula de Bayes é o valor do Teorema da Probabilidade Total definida anteriormente.\nO Teorema de Bayes é particularmente útil quando estamos tratando com experimentos em múltiplas fases. Se \\(B_i\\) é um evento condicionado à um evento \\(A\\), então querer saber \\(P(B_i|A)\\) é como se fosse no sentido de retrospectiva (“backward”). É como se fosse questionar sobre a probabilidade da primeira fase, condicionada no que aconteceu na segunda fase do experimento. Por isso, o Teorema de Bayes também é chamado de teorema da probabilidade a posteriori (Morettin (1999)).\nExemplo Suponha que em uma urna nós temos três moedas: sendo duas honestas e uma viciada com duas faces “caras”. Suponha que eu retire, aleatoriamente, uma moeda urna e jogue pra cima e saia a face “cara”. Então, dado que saiu “cara”, qual a probabilidade de eu ter sorteado a moeda viciada?\nPodemos pensar neste problema da seguinte forma ilustrativa:\n\n\n\nIlustração de experimento de duas fases\n\n\nOriginalmente, \\(P(B_3) = \\frac{1}{3}\\), no entanto, a probabilidade condicionada a posteriori é:\n\\[\nP(B_3|A) = \\frac{P(A | B_3) P(B_3)} {P(A | B_1)P(B_1) + P(A | B_2)P(B_2) + P(A | B_3)P(B_3)} = \\frac{1 \\times \\frac{1}{3}} {\\frac{1}{2} \\times \\frac{1}{3} + \\frac{1}{2} \\times \\frac{1}{3} + 1\\times \\frac{1}{3}} = \\frac{\\frac{1}{3}}{\\frac{4}{6}} = \\frac{1}{2}\n\\]\nOu seja, note que a probabilidade “atualizou” de \\(\\frac{1}{3}\\) para \\(\\frac{1}{2}\\).\n\n\n\nOutro resultado importante é a regra da multiplicação abaixo:\nTeorema Sejam \\(A_1, A_2, ..., A_n\\) diferentes eventos de um espaço de probabilidade, então:\n\\[\nP(A_1 \\cap A_2 \\cap ... \\cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2 \\cap A_1)...P(A_n|A_1 \\cap ... \\cap A_{n-1})\n\\]\nOu, conforme Mood, Graybill, e Boes (1974), em notação alternativa:\n\\[\nP(A_1A_2 ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2A_1)...P(A_n|A_1... A_{n-1})\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/3_probabilidade_condicional_e_independencia.html#teorema-da-probabilidade-total",
    "href": "Int_Prob/3_probabilidade_condicional_e_independencia.html#teorema-da-probabilidade-total",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Antes de apresentar o teorema da probabilidade total, apresenta-se a definição de partição do espaço amostral:\nDefinição Se \\(B_1, B_2, ..., B_n\\) representa um conjunto de eventos mutuamente excludentes satisfazendo \\(\\Omega = \\bigcup\\limits_{i=1}^{n}B_i\\) então, dizemos que \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\).\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\):\n\\[\nP(A) = P\\left(\\bigcup\\limits_{i=1}^{n}(A \\cap B_i)\\right) = \\sum\\limits_{i=1}^{n}P(A \\cap B_i) = \\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)\n\\]\nVisualmente:\n\n\n\nExemplo de uma partição de \\(\\Omega\\) para \\(n = 5\\) e um evento A (extraído de DeGroot e Schervish (2012))\n\n\nRessalta-se que o Teorema da Probabilidade Total vale também quando \\(n = \\infty\\)",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/3_probabilidade_condicional_e_independencia.html#teorema-de-bayes",
    "href": "Int_Prob/3_probabilidade_condicional_e_independencia.html#teorema-de-bayes",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "O Teorema de Bayese, na sua forma extendida1, é visto como a probabilidade de um evento de uma partição condicionado à um evento já ocorrido do espaço amostral. A fórmula de Bayes é definida a seguir:\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\) temos que\n\\[\nP(B_i |A) = \\frac{P(A | B_i) P(B_i)} {\\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)} \\ \\ \\ \\forall i=1,...n.\n\\] Ressalta-se que o Teorema de Bayes vale também quando \\(n = \\infty\\).\nObserve que o denominador da Fórmula de Bayes é o valor do Teorema da Probabilidade Total definida anteriormente.\nO Teorema de Bayes é particularmente útil quando estamos tratando com experimentos em múltiplas fases. Se \\(B_i\\) é um evento condicionado à um evento \\(A\\), então querer saber \\(P(B_i|A)\\) é como se fosse no sentido de retrospectiva (“backward”). É como se fosse questionar sobre a probabilidade da primeira fase, condicionada no que aconteceu na segunda fase do experimento. Por isso, o Teorema de Bayes também é chamado de teorema da probabilidade a posteriori (Morettin (1999)).\nExemplo Suponha que em uma urna nós temos três moedas: sendo duas honestas e uma viciada com duas faces “caras”. Suponha que eu retire, aleatoriamente, uma moeda urna e jogue pra cima e saia a face “cara”. Então, dado que saiu “cara”, qual a probabilidade de eu ter sorteado a moeda viciada?\nPodemos pensar neste problema da seguinte forma ilustrativa:\n\n\n\nIlustração de experimento de duas fases\n\n\nOriginalmente, \\(P(B_3) = \\frac{1}{3}\\), no entanto, a probabilidade condicionada a posteriori é:\n\\[\nP(B_3|A) = \\frac{P(A | B_3) P(B_3)} {P(A | B_1)P(B_1) + P(A | B_2)P(B_2) + P(A | B_3)P(B_3)} = \\frac{1 \\times \\frac{1}{3}} {\\frac{1}{2} \\times \\frac{1}{3} + \\frac{1}{2} \\times \\frac{1}{3} + 1\\times \\frac{1}{3}} = \\frac{\\frac{1}{3}}{\\frac{4}{6}} = \\frac{1}{2}\n\\]\nOu seja, note que a probabilidade “atualizou” de \\(\\frac{1}{3}\\) para \\(\\frac{1}{2}\\).",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/3_probabilidade_condicional_e_independencia.html#regra-da-multiplicação",
    "href": "Int_Prob/3_probabilidade_condicional_e_independencia.html#regra-da-multiplicação",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Outro resultado importante é a regra da multiplicação abaixo:\nTeorema Sejam \\(A_1, A_2, ..., A_n\\) diferentes eventos de um espaço de probabilidade, então:\n\\[\nP(A_1 \\cap A_2 \\cap ... \\cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2 \\cap A_1)...P(A_n|A_1 \\cap ... \\cap A_{n-1})\n\\]\nOu, conforme Mood, Graybill, e Boes (1974), em notação alternativa:\n\\[\nP(A_1A_2 ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2A_1)...P(A_n|A_1... A_{n-1})\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/3_probabilidade_condicional_e_independencia.html#footnotes",
    "href": "Int_Prob/3_probabilidade_condicional_e_independencia.html#footnotes",
    "title": "Probabilidade Condicional e Independência",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nUm vídeo interessante sobre a aplicação e explicação do Teorema de Bayes pode ser visto aqui: A Armadilha Bayesiana↩︎",
    "crumbs": [
      "Conceitos Básicos",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/1_experimento_aleatorio.html",
    "href": "Int_Prob/1_experimento_aleatorio.html",
    "title": "Experimento Aleatório, Espaço Amostral e Eventos",
    "section": "",
    "text": "Experimentos aleatórios são situação na natureza que envolvem incertezas. A busca por avaliar as diversas probabilidades de ocorrência é um dos objetivos no estudo desses fenômenos.\nO espaço amostral é o conjunto de todos os possíveis resultados de um experimento aleatório e é representado por \\(\\Omega\\). Cada resultado possível é denominado ponto ou elemento de \\(\\Omega\\) e denotado por \\(\\omega\\). Assim, escrevemos \\(\\omega \\in \\Omega\\) para indicar que \\(\\omega\\) está em \\(\\Omega\\). O conjunto sem elementos é o conjunto vazio, denotado por \\(\\emptyset\\). Muitos autores (Magalhães (2006), James (2023), DeGroot e Schervish (2012)), denominam eventos (ou conjunto) como sendo letras maiúsculas do alfabeto, tais como A, B, etc. Assim:\nDefinição Seja \\(\\Omega\\) o espaço amostral do experimento. Todo subconjunto \\(A \\in \\Omega\\) será chamado evento. \\(\\Omega\\) é o evento certo, \\(\\emptyset\\) o evento impossível. Se \\(\\omega \\in \\Omega\\), o evento \\(\\{\\omega\\}\\) é dito elementar (ou simples).\n\n\n\n\n\nLei Comutativa: \\(A \\cup B = B \\cup A\\) e, também, \\(A \\cap B = B \\cap A\\)\nLei Associativa: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\) e, também, \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\)\nLei Distributiva: \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) e, também, \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A^c\\) (ou \\(\\bar{A}\\)) é o complementar de \\(A\\), isto é, todos os elementos de \\(\\Omega\\) exceto os de \\(A\\)\n\\(A_1 \\cup A_2 ... \\cup A_n\\) ou \\(\\bigcup\\limits_{i=1}^{n}A_i\\) é a união de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem à pelo menos um \\(A_i\\)\n\\(A_1 \\cap A_2 ... \\cap A_n\\) ou \\(\\bigcap\\limits_{i=1}^{n}A_i\\) é a intersecção de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem simultaneamente à todos os \\(A_i\\)’s.\n\\(A-B\\) é a diferença entre \\(A\\) e \\(B\\), isto é, todos os elementos de \\(A\\), exceto os que estão em \\(B\\). Outra forma de notação é \\(A \\cap B^c\\), pois \\(A-B = A \\cap B^c\\)\nSe todo o elemento de \\(A\\) é também um elemento de \\(B\\), então \\(A\\) é definido como um subconjunto de \\(B\\) e escrevemos \\(A \\subset B\\) ou \\(B \\supset A\\). Interpretamos como sendo “\\(A\\) está contido em \\(B\\)” ou “\\(B\\) contém \\(A\\)”\nDois conjuntos são disjuntos ou mutuamente excludentes se a sua interseção é vazio. Assim, \\(A\\ e\\ B\\ disjuntos \\iff A \\cap B = \\emptyset\\)\n\n\n\n\nUma maneiras mais intuitivas de visualizar essas relações entre conjuntos é via Diagramas de Venn. Abaixo, podemos ver algumas das relações:\n\n\n\nExtraído do Mood, Graybill, e Boes (1974)\n\n\n\n\n\nAs Leis de DeMorgan, ilustrada também no Diagrama de Venn anterior, são teoremas fundamentais que descrevem relações entre a união e interesecção entre conjuntos e de seus complementos.\nO caso simples pode ser descrito abaixo:\n\\[\n\\begin{align*}\n(A \\cup B)^c = A^c \\cap B^c \\\\\n(A \\cap B)^c = A^c \\cup B^c\n\\end{align*}\n\\]\nImagine as duas frases:\n\nA: “Está chovendo”\nB: “Está frio”\n\nPortanto:\n\nA negação de “Está chovendo e está frio” (\\(A \\cap B\\)) é “Não está chovendo ou não está frio” (\\(A^c \\cup B^c\\));\nA negação de “Está chovendo ou está frio” (\\(A \\cap B\\)) é “Não está chovendo e não está frio” (\\(A^c \\cap B^c\\)).\n\nCaso geral:\n\\[\n\\begin{align*}\n\\left( \\bigcup\\limits_{i=1}^{n} A_i \\right)^c = \\bigcap\\limits_{i=1}^{n} A_i^c \\\\\n\\left( \\bigcap\\limits_{i=1}^{n} A_i \\right)^c = \\bigcup\\limits_{i=1}^{n} A_i^c\n\\end{align*}\n\\]\nVale ressaltar também que essa relação vale também quando \\(n = \\infty\\), ou seja:\n\\[\n\\begin{align*}\n\\left( \\bigcup\\limits_{i=1}^{\\infty} A_i \\right)^c = \\bigcap\\limits_{i=1}^{\\infty} A_i^c \\\\\n\\left( \\bigcap\\limits_{i=1}^{\\infty} A_i \\right)^c = \\bigcup\\limits_{i=1}^{\\infty} A_i^c\n\\end{align*}\n\\]",
    "crumbs": [
      "Probabilidade",
      "Experimento Aleatório, Espaço Amostral e Eventos"
    ]
  },
  {
    "objectID": "Int_Prob/1_experimento_aleatorio.html#eventosconjuntos",
    "href": "Int_Prob/1_experimento_aleatorio.html#eventosconjuntos",
    "title": "Experimento Aleatório, Espaço Amostral e Eventos",
    "section": "",
    "text": "Lei Comutativa: \\(A \\cup B = B \\cup A\\) e, também, \\(A \\cap B = B \\cap A\\)\nLei Associativa: \\(A \\cup (B \\cup C) = (A \\cup B) \\cup C\\) e, também, \\(A \\cap (B \\cap C) = (A \\cap B) \\cap C\\)\nLei Distributiva: \\(A \\cap (B \\cup C) = (A \\cap B) \\cup (A \\cap C)\\) e, também, \\(A \\cup (B \\cap C) = (A \\cup B) \\cap (A \\cup C)\\)\n\\(A^c\\) (ou \\(\\bar{A}\\)) é o complementar de \\(A\\), isto é, todos os elementos de \\(\\Omega\\) exceto os de \\(A\\)\n\\(A_1 \\cup A_2 ... \\cup A_n\\) ou \\(\\bigcup\\limits_{i=1}^{n}A_i\\) é a união de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem à pelo menos um \\(A_i\\)\n\\(A_1 \\cap A_2 ... \\cap A_n\\) ou \\(\\bigcap\\limits_{i=1}^{n}A_i\\) é a intersecção de \\(A_1, A_2, ..., A_n\\) e representa os pontos de \\(\\Omega\\) que pertencem simultaneamente à todos os \\(A_i\\)’s.\n\\(A-B\\) é a diferença entre \\(A\\) e \\(B\\), isto é, todos os elementos de \\(A\\), exceto os que estão em \\(B\\). Outra forma de notação é \\(A \\cap B^c\\), pois \\(A-B = A \\cap B^c\\)\nSe todo o elemento de \\(A\\) é também um elemento de \\(B\\), então \\(A\\) é definido como um subconjunto de \\(B\\) e escrevemos \\(A \\subset B\\) ou \\(B \\supset A\\). Interpretamos como sendo “\\(A\\) está contido em \\(B\\)” ou “\\(B\\) contém \\(A\\)”\nDois conjuntos são disjuntos ou mutuamente excludentes se a sua interseção é vazio. Assim, \\(A\\ e\\ B\\ disjuntos \\iff A \\cap B = \\emptyset\\)\n\n\n\n\nUma maneiras mais intuitivas de visualizar essas relações entre conjuntos é via Diagramas de Venn. Abaixo, podemos ver algumas das relações:\n\n\n\nExtraído do Mood, Graybill, e Boes (1974)\n\n\n\n\n\nAs Leis de DeMorgan, ilustrada também no Diagrama de Venn anterior, são teoremas fundamentais que descrevem relações entre a união e interesecção entre conjuntos e de seus complementos.\nO caso simples pode ser descrito abaixo:\n\\[\n\\begin{align*}\n(A \\cup B)^c = A^c \\cap B^c \\\\\n(A \\cap B)^c = A^c \\cup B^c\n\\end{align*}\n\\]\nImagine as duas frases:\n\nA: “Está chovendo”\nB: “Está frio”\n\nPortanto:\n\nA negação de “Está chovendo e está frio” (\\(A \\cap B\\)) é “Não está chovendo ou não está frio” (\\(A^c \\cup B^c\\));\nA negação de “Está chovendo ou está frio” (\\(A \\cap B\\)) é “Não está chovendo e não está frio” (\\(A^c \\cap B^c\\)).\n\nCaso geral:\n\\[\n\\begin{align*}\n\\left( \\bigcup\\limits_{i=1}^{n} A_i \\right)^c = \\bigcap\\limits_{i=1}^{n} A_i^c \\\\\n\\left( \\bigcap\\limits_{i=1}^{n} A_i \\right)^c = \\bigcup\\limits_{i=1}^{n} A_i^c\n\\end{align*}\n\\]\nVale ressaltar também que essa relação vale também quando \\(n = \\infty\\), ou seja:\n\\[\n\\begin{align*}\n\\left( \\bigcup\\limits_{i=1}^{\\infty} A_i \\right)^c = \\bigcap\\limits_{i=1}^{\\infty} A_i^c \\\\\n\\left( \\bigcap\\limits_{i=1}^{\\infty} A_i \\right)^c = \\bigcup\\limits_{i=1}^{\\infty} A_i^c\n\\end{align*}\n\\]",
    "crumbs": [
      "Probabilidade",
      "Experimento Aleatório, Espaço Amostral e Eventos"
    ]
  },
  {
    "objectID": "Int_Prob/2_conceitos_de_probabilidade.html",
    "href": "Int_Prob/2_conceitos_de_probabilidade.html",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "Segundo Magalhães (2006), a definição clássica de probabilidade se refere à subconjuntos unitários equiprováveis. No caso enumerável finito temos:\n\\[\nP(A) = \\frac{Número\\ de\\ Elementos\\ em\\ A}{Número\\ total\\ de\\ Elementos\\ em\\ \\Omega}\n\\]\nSe \\(\\Omega\\) tiver uma quantidade infinita de elementos, precisamos tratar a a definição acima com o uso de limites.\n\n\n\nQuando \\(\\Omega\\) é não enumerável, o conceito se aplicará ao comprimento de intervalos, medidas de áreas ou similares, dando origem ao que chamamos de probabilidade geométrica. Por exemplo, se \\(\\Omega\\) é um intervalo onde \\(\\Omega \\in \\mathbb{R}\\), então:\n\\[\nP(A) = \\frac{Comprimento\\ de\\ A}{Comprimento\\ de\\ \\Omega}\n\\]\n\n\n\nA definição frequentista considera o limite de frequências relativas como o valor da probabilidade. Para tal, seja \\(n_{A}\\) o número de ocorrências de \\(A\\) em \\(n\\) repetições independentes do experimento em questão. Assim,\n\\[\nP(A) = \\lim_{n\\rightarrow{+\\infty}} \\frac{n_A}{n}\n\\]\n\n\n\nAs definições anteriores não são suficientes para uma formulação matemática mais rigorosa da probabilidade. Assim, na primeira metade do século XX, Kolmogorov (1933) apresentou um conjunto de axiomas matemáticos para definir probabilidade e, assim, pavimentando toda a evolução da probabilidade moderna.\nÉ importante, e ao mesmo tempo fascinante, destacar que apenas com esses três axiomas todos os teoremas da Teoria da Probabilidade são viabilizados. Assim, podemos destacar que toda a evolução da probabilidade foi pavimentada pelo trabalho de Kolmogorov (1933).\nDefinição axiomática\nAssumindo que podemos atribuir um número real \\(P(A)\\) para um evento \\(A\\):\n\nAxioma 1. \\(P(A) \\ge 0\\)\nAxioma 2. \\(P(\\Omega) = 1\\)\nAxioma 3. Se \\(A_1, A_2, ..., A_n\\) são disjuntos (2 a 2) (isto é, mutuamente excludentes), então\n\n\\[\nP\\left( \\bigcup_{k=1}^{n} A_k \\right) = \\sum_{k=1}^{n} P (A_k)\n\\]\n(Os eventos são disjuntos 2 a 2, se \\(A_i \\cap A_j = \\emptyset, \\forall i \\ne j\\))\nUma discussão mais aprofundada desses axiomas, incluindo uma versão mais conveniente para o Axioma 3 (para o caso \\(n = \\infty\\)) e uma “Axioma 4” de continuidade no vazio, que pode ser derivado dos outros axiomas, é discutida no Capítulo 1 de James (2023).\n\n\nComo comentado, os Axiomas de Kolmogorov sustentam toda a teoria da probabilidade e alguns resultados diretos são:\n\n\\(P(\\emptyset) = 0\\).\n\nProva.\n\\[\n\\begin{align*}\nP(A \\cup \\emptyset) &= P(A) + P(\\emptyset) \\\\\nP(A) &= P(A) + P(\\emptyset) \\\\\nP(\\emptyset) &= 0\n\\end{align*}\n\\]\n\nPara qualquer evento \\(A\\), \\(P(A^c) = 1-P(A)\\).\n\nProva.\n\\[\n\\begin{align*}\nP(\\Omega) &= P(A \\cup A^c) = P(A) + P(A^c) \\\\\n1 &= P(A) + P(A^c) \\overset{\\text{Isolando}}{\\implies} P(A^c) = 1-P(A)\n\\end{align*}\n\\]\n\nSe \\(A \\subset B\\), então \\(P(A) \\le P(B)\\).\n\nProva.\n\\[\n\\begin{align*}\nP(B) &= P(A \\cup (B \\cap A^c)) = P(A) + P(B \\cap A^c) \\\\\nP(B) &\\ge P(A)\n\\end{align*}\n\\]\n\nSe \\(A \\subset B\\), então \\(P(A \\cap B) = P(A)\\).\nPara qualquer evento \\(A\\), \\(0 \\le P(A) \\le 1\\).\n\nProva. Como \\(A \\subset \\Omega\\), então \\(0 \\le P(A) \\le P(\\Omega) = 1\\)\n\nPara quaisquer eventos \\(A\\) e \\(B\\), \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) (Esta relação é mais fácil de visualizar via Diagrama de Venn)\n\nProva.\nPrimeiro, vamos escrever \\(P(A)\\) e \\(P(B)\\) como a soma de suas partes:\n\\[\nP(A) = P(A \\cap B^c) + P(A \\cap B) \\\\\nP(B) = P(B \\cap A^c) + P(B \\cap A)\n\\]\nAgora, vamos escrever a união como a soma de suas partes:\n\\[\nP(A \\cup B) = P(A \\cap B^c) + P(A \\cap B) + P(B \\cap A^c)\n\\]\nAgora, somando e substraindo \\(P(A \\cap B)\\):\n\\[\n\\begin{align*}\nP(A \\cup B) &= \\overbrace{P(A \\cap B^c) + P(A \\cap B)}^{P(A)} + \\overbrace{P(B \\cap A^c) + P(A \\cap B)}^{P(B)} - P(A \\cap B) \\\\\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B)\n\\end{align*}\n\\]\n\n(Desigualdade de Boole) Sejam \\(A_1, A_2, ..., A_n\\) então\n\n\\[\nP\\left( \\bigcup_{i=1}^{n} A_i  \\right) \\le \\sum_{i=1}^{n}P(A_i)\n\\]\n\n\n\n\nUm Espaço de Probabilidade é um constructo que provê um modelo formal de um processo aleatório. Ele é composto por uma tríplice de valores \\((\\Omega, \\mathcal{F}, P)\\) onde\n\n\\(\\Omega\\) é todo o espaço amostral\n\\(\\mathcal{F}\\) (ou \\(\\sigma\\)-álgebra) é o espaço de eventos (domínio)\n\\(\\mathcal{P}\\) é uma função de probabilidade aplicada em \\(\\mathcal{F}\\) que produz valores no intervalo \\([0,1]\\)\n\nPara um entendimento mais consistente da importância da definição de um espaço de probabilidade, bem como da importância da definição de uma \\(\\sigma\\)-álgebra, que é o domínio do espaço, recomenda-se a leitura do Capítulo 1 de James (2023), Capítulo 1 de Magalhães (2006), Capítulo 1 de Rolla (2022) e Capítulo 2B e 12 de Axler (2020).1 No entanto, como esta discussão é mais aprofundada, para uma visão mais geral recomendo fortemente o leitor a assitir o vídeo Bertrand’s Paradox (with 3blue1brown) - Numberphile (explicação do Exemplo 1.8 de Magalhães (2006)) para esclarecer qual o efeito da definição de diferentes espaços de probabiidade para um mesmo problema e assim produzir probabilidades significativamente diferentes dependendo da maneira como são definidos \\(\\Omega\\) e \\(\\sigma\\)-álgebra e, assim, produzindo diferentes processos geradores de eventos.",
    "crumbs": [
      "Probabilidade",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/2_conceitos_de_probabilidade.html#definição-clássica-omega-enumerável",
    "href": "Int_Prob/2_conceitos_de_probabilidade.html#definição-clássica-omega-enumerável",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "Segundo Magalhães (2006), a definição clássica de probabilidade se refere à subconjuntos unitários equiprováveis. No caso enumerável finito temos:\n\\[\nP(A) = \\frac{Número\\ de\\ Elementos\\ em\\ A}{Número\\ total\\ de\\ Elementos\\ em\\ \\Omega}\n\\]\nSe \\(\\Omega\\) tiver uma quantidade infinita de elementos, precisamos tratar a a definição acima com o uso de limites.",
    "crumbs": [
      "Probabilidade",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/2_conceitos_de_probabilidade.html#definição-clássica-geométrica-omega-não-enumerável",
    "href": "Int_Prob/2_conceitos_de_probabilidade.html#definição-clássica-geométrica-omega-não-enumerável",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "Quando \\(\\Omega\\) é não enumerável, o conceito se aplicará ao comprimento de intervalos, medidas de áreas ou similares, dando origem ao que chamamos de probabilidade geométrica. Por exemplo, se \\(\\Omega\\) é um intervalo onde \\(\\Omega \\in \\mathbb{R}\\), então:\n\\[\nP(A) = \\frac{Comprimento\\ de\\ A}{Comprimento\\ de\\ \\Omega}\n\\]",
    "crumbs": [
      "Probabilidade",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/2_conceitos_de_probabilidade.html#definição-frequentista",
    "href": "Int_Prob/2_conceitos_de_probabilidade.html#definição-frequentista",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "A definição frequentista considera o limite de frequências relativas como o valor da probabilidade. Para tal, seja \\(n_{A}\\) o número de ocorrências de \\(A\\) em \\(n\\) repetições independentes do experimento em questão. Assim,\n\\[\nP(A) = \\lim_{n\\rightarrow{+\\infty}} \\frac{n_A}{n}\n\\]",
    "crumbs": [
      "Probabilidade",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/2_conceitos_de_probabilidade.html#probabilidade-axiomática",
    "href": "Int_Prob/2_conceitos_de_probabilidade.html#probabilidade-axiomática",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "As definições anteriores não são suficientes para uma formulação matemática mais rigorosa da probabilidade. Assim, na primeira metade do século XX, Kolmogorov (1933) apresentou um conjunto de axiomas matemáticos para definir probabilidade e, assim, pavimentando toda a evolução da probabilidade moderna.\nÉ importante, e ao mesmo tempo fascinante, destacar que apenas com esses três axiomas todos os teoremas da Teoria da Probabilidade são viabilizados. Assim, podemos destacar que toda a evolução da probabilidade foi pavimentada pelo trabalho de Kolmogorov (1933).\nDefinição axiomática\nAssumindo que podemos atribuir um número real \\(P(A)\\) para um evento \\(A\\):\n\nAxioma 1. \\(P(A) \\ge 0\\)\nAxioma 2. \\(P(\\Omega) = 1\\)\nAxioma 3. Se \\(A_1, A_2, ..., A_n\\) são disjuntos (2 a 2) (isto é, mutuamente excludentes), então\n\n\\[\nP\\left( \\bigcup_{k=1}^{n} A_k \\right) = \\sum_{k=1}^{n} P (A_k)\n\\]\n(Os eventos são disjuntos 2 a 2, se \\(A_i \\cap A_j = \\emptyset, \\forall i \\ne j\\))\nUma discussão mais aprofundada desses axiomas, incluindo uma versão mais conveniente para o Axioma 3 (para o caso \\(n = \\infty\\)) e uma “Axioma 4” de continuidade no vazio, que pode ser derivado dos outros axiomas, é discutida no Capítulo 1 de James (2023).\n\n\nComo comentado, os Axiomas de Kolmogorov sustentam toda a teoria da probabilidade e alguns resultados diretos são:\n\n\\(P(\\emptyset) = 0\\).\n\nProva.\n\\[\n\\begin{align*}\nP(A \\cup \\emptyset) &= P(A) + P(\\emptyset) \\\\\nP(A) &= P(A) + P(\\emptyset) \\\\\nP(\\emptyset) &= 0\n\\end{align*}\n\\]\n\nPara qualquer evento \\(A\\), \\(P(A^c) = 1-P(A)\\).\n\nProva.\n\\[\n\\begin{align*}\nP(\\Omega) &= P(A \\cup A^c) = P(A) + P(A^c) \\\\\n1 &= P(A) + P(A^c) \\overset{\\text{Isolando}}{\\implies} P(A^c) = 1-P(A)\n\\end{align*}\n\\]\n\nSe \\(A \\subset B\\), então \\(P(A) \\le P(B)\\).\n\nProva.\n\\[\n\\begin{align*}\nP(B) &= P(A \\cup (B \\cap A^c)) = P(A) + P(B \\cap A^c) \\\\\nP(B) &\\ge P(A)\n\\end{align*}\n\\]\n\nSe \\(A \\subset B\\), então \\(P(A \\cap B) = P(A)\\).\nPara qualquer evento \\(A\\), \\(0 \\le P(A) \\le 1\\).\n\nProva. Como \\(A \\subset \\Omega\\), então \\(0 \\le P(A) \\le P(\\Omega) = 1\\)\n\nPara quaisquer eventos \\(A\\) e \\(B\\), \\(P(A \\cup B) = P(A) + P(B) - P(A \\cap B)\\) (Esta relação é mais fácil de visualizar via Diagrama de Venn)\n\nProva.\nPrimeiro, vamos escrever \\(P(A)\\) e \\(P(B)\\) como a soma de suas partes:\n\\[\nP(A) = P(A \\cap B^c) + P(A \\cap B) \\\\\nP(B) = P(B \\cap A^c) + P(B \\cap A)\n\\]\nAgora, vamos escrever a união como a soma de suas partes:\n\\[\nP(A \\cup B) = P(A \\cap B^c) + P(A \\cap B) + P(B \\cap A^c)\n\\]\nAgora, somando e substraindo \\(P(A \\cap B)\\):\n\\[\n\\begin{align*}\nP(A \\cup B) &= \\overbrace{P(A \\cap B^c) + P(A \\cap B)}^{P(A)} + \\overbrace{P(B \\cap A^c) + P(A \\cap B)}^{P(B)} - P(A \\cap B) \\\\\nP(A \\cup B) &= P(A) + P(B) - P(A \\cap B)\n\\end{align*}\n\\]\n\n(Desigualdade de Boole) Sejam \\(A_1, A_2, ..., A_n\\) então\n\n\\[\nP\\left( \\bigcup_{i=1}^{n} A_i  \\right) \\le \\sum_{i=1}^{n}P(A_i)\n\\]",
    "crumbs": [
      "Probabilidade",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/2_conceitos_de_probabilidade.html#espaços-de-probabilidade",
    "href": "Int_Prob/2_conceitos_de_probabilidade.html#espaços-de-probabilidade",
    "title": "Conceitos de Probabilidade",
    "section": "",
    "text": "Um Espaço de Probabilidade é um constructo que provê um modelo formal de um processo aleatório. Ele é composto por uma tríplice de valores \\((\\Omega, \\mathcal{F}, P)\\) onde\n\n\\(\\Omega\\) é todo o espaço amostral\n\\(\\mathcal{F}\\) (ou \\(\\sigma\\)-álgebra) é o espaço de eventos (domínio)\n\\(\\mathcal{P}\\) é uma função de probabilidade aplicada em \\(\\mathcal{F}\\) que produz valores no intervalo \\([0,1]\\)\n\nPara um entendimento mais consistente da importância da definição de um espaço de probabilidade, bem como da importância da definição de uma \\(\\sigma\\)-álgebra, que é o domínio do espaço, recomenda-se a leitura do Capítulo 1 de James (2023), Capítulo 1 de Magalhães (2006), Capítulo 1 de Rolla (2022) e Capítulo 2B e 12 de Axler (2020).1 No entanto, como esta discussão é mais aprofundada, para uma visão mais geral recomendo fortemente o leitor a assitir o vídeo Bertrand’s Paradox (with 3blue1brown) - Numberphile (explicação do Exemplo 1.8 de Magalhães (2006)) para esclarecer qual o efeito da definição de diferentes espaços de probabiidade para um mesmo problema e assim produzir probabilidades significativamente diferentes dependendo da maneira como são definidos \\(\\Omega\\) e \\(\\sigma\\)-álgebra e, assim, produzindo diferentes processos geradores de eventos.",
    "crumbs": [
      "Probabilidade",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/2_conceitos_de_probabilidade.html#footnotes",
    "href": "Int_Prob/2_conceitos_de_probabilidade.html#footnotes",
    "title": "Conceitos de Probabilidade",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nO conceito de \\(\\sigma\\)-álgebra (bem como de sua versão finita – Álgebra), em um primeiro momento, pode ser considerado difícil de assimilar do ponto de vista prático. No entanto, ela é fundamental para garantir uma base matemática sólida para toda a teoria da probabilidade. As propriedades desejáveis de uma \\(\\sigma\\)-álgebra garantem que o espaço de probabilidade é um espaço mensurável. Por exemplo, uma das condições é de que se \\(A_1\\) e \\(A_2\\) são dois eventos sendo \\(A_1 \\in \\mathcal{F}\\) e \\(A_2 \\in \\mathcal{F}\\), então \\((A_1 \\cup A_2) \\in \\mathcal{F}\\). Se essa condição não fosse satisfeita, os axiomas de Kolmogorov não poderiam ser naturalmente aplicados à este espaço e potencialmente inconsistências poderiam ser geradas. Por exemplo, seguindo o Exemplo 1.3 de Magalhães (2006), considerando \\(\\Omega = \\{1, 2, 3\\}\\), suponha \\(\\mathcal{F} = \\{ \\emptyset, \\Omega, \\{1\\}, \\{2\\}, \\{1,3\\}, \\{2,3\\} \\}\\) não é uma \\(\\sigma\\)-álgebra pois \\(\\{1, 2\\} \\notin \\mathcal{F}\\) e, portanto, \\(P(\\{1, 2\\})\\) é indefinido. Portanto, não poderíamos, por exemplo, aplicar o terceiro axioma de Kolmogorov para calcular \\(P(\\{1, 2\\})\\). Neste exemplo, a definição de \\(\\mathcal{F}\\) viola o Axioma do Par que é uma dos axiomas fundamentais da Teoria dos Conjuntos de Zermelo–Fraenkel. Adicionamente, discussão possui relação com outros conceitos matemáticos como Aditividade Contável de uma \\(\\sigma\\)-álgebra, o Axioma da Escolha e o Paradoxo de Banach-Tarski. Recomenda-se também assistir o vídeo The Man Who Almost Broke Math (And Himself…).↩︎",
    "crumbs": [
      "Probabilidade",
      "Conceitos de Probabilidade"
    ]
  },
  {
    "objectID": "Int_Prob/4_variaveis_aleatorias.html#variáveis-aleatórias-discretas",
    "href": "Int_Prob/4_variaveis_aleatorias.html#variáveis-aleatórias-discretas",
    "title": "Variáveis Aleatórias",
    "section": "Variáveis Aleatórias Discretas",
    "text": "Variáveis Aleatórias Discretas\nDefinição Se os valores considerados de \\(X\\) são contáveis, então \\(X\\) é considerado discreto.\nNote que se \\(X\\) é contável assumindo, por exemplo, valores \\(x_1, x_2, ..., x_n, ...\\), então \\(\\Omega = \\bigcup\\limits_{i=1}^{\\infty} \\{X = x_n\\}\\), mas como os \\(x_i\\)’s podem ser vistos como eventos disjuntos, isto é, \\(\\{X = x_i\\} \\cap \\{X = x_j\\} = \\emptyset, \\forall i \\ne j\\); então, \\(1 = P(\\Omega) = \\sum\\limits_{i=1}^{\\infty}P(X = x_i)\\) pelo terceiro axioma de Kolmogorov.\nA função densidade de probabilidade, \\(f_X(.)\\) é definida como sendo\n\\[\n\\begin{align*}\nf_X(x) &=\n\\begin{cases}\n  P(X = x_i), & \\text{se}\\ x=x_i,\\ i = 1, 2, ...  \\\\\n  0, & \\text{caso contrário}\n\\end{cases}\n\\end{align*}\n\\]\nA função densidade de probabilidade de uma VA discreta também pode ser chamada de função massa de probabilidade.\nExemplo Função de densidade do lançamento de um dado honesto sendo \\(X\\) definido como sendo o valor da face.\n\n\nMostrar Código\n# Carregar o pacote ggplot2\nlibrary(ggplot2)\n\n# Dados: resultados do dado e suas probabilidades\ndados &lt;- data.frame(\n  face = 1:6,\n  probabilidade = rep(1/6, 6),\n  fracoes = '1/6'\n)\n\n# Criar o gráfico de barras\nggplot(dados, aes(x = factor(face), y = probabilidade)) +\n  geom_bar(stat = \"identity\", fill = \"#2780e3\") +\n  geom_text(aes(label = fracoes), vjust = -0.5, size = 4) +\n  labs(title = \"Função Massa de Probabilidade de um Dado Honesto\",\n       x = \"Face do Dado\",\n       y = \"Probabilidade\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nObserve que, neste caso, a FDA pode ser visualizada abaixo:\n\n\nMostrar Código\n# Código inspirado em https://stackoverflow.com/questions/52236576/r-ggplot-make-geom-step-jumps-dashed\n\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndados &lt;- tibble::tibble(\n  x = 0:6,\n  probabilidade = c(0, rep(1/6, 6)),\n  fda = cumsum(probabilidade))\n\ndados_grafico &lt;- dados %&gt;%\n  mutate(tipo = \"fda\") %&gt;%\n  bind_rows(dados %&gt;%\n              mutate(tipo = \"previa_fda\",\n                     fda = lag(fda))) %&gt;%\n  tidyr::drop_na() %&gt;%\n  arrange(x, desc(tipo))\n\nggplot(dados_grafico) + \n  geom_segment(aes(x = lag(x), y = lag(fda), xend = x, yend = fda, lty = tipo)) +\n  geom_point(data = slice(dados_grafico, -1), aes(x, fda, fill = tipo), shape = 21) + # Retira ponto mais extremo para ilustrar o -infinito\n  scale_fill_manual(values = c(\"black\", \"white\")) +\n  scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n  labs(title = \"FDA teórica de um dado honesto (6 faces)\",\n       x = \"Face x\",\n       y = \"P(X ≤ x)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  geom_segment(aes(x = 6, y = 1, xend = 7, yend = 1)) # Segmento mais extremo para ilustrar o +infinito\n\n\n\n\n\n\n\n\n\nExemplo Função de densidade do lançamento de dois dados honestos sendo \\(X\\) definido como sendo o valor da soma das duas faces.\n\n\nMostrar Código\nlibrary(ggplot2)\nlibrary(MASS)\n\n# Cria uma função que calcula P(X = x_i) onde x_i é a soma das duas faces\ncalcula_prob_soma &lt;- function(soma) {\n  # Contar combinações possíveis que resultam na soma\n  combinacoes &lt;- expand.grid(dado1=1:6, dado2=1:6)\n  total &lt;- nrow(combinacoes)\n  resultados_validos &lt;- sum(rowSums(combinacoes) == soma)\n  prob &lt;- resultados_validos / total\n  return(prob)\n}\n\n# Aplica a função acima para todo o espaço amostral Omega\nsomas &lt;- 2:12\nprobabilidades &lt;- sapply(somas, calcula_prob_soma)\n\n# Convertendo para frações em formato string\nfracoes_str &lt;- sapply(probabilidades, function(p) as.character(fractions(p)))\n\n# Criar data frame\ndados_somas &lt;- data.frame(\n  soma = somas,\n  probabilidade = probabilidades,\n  fracoes = fracoes_str\n)\n\n# Plotagem\nggplot(dados_somas, aes(x = factor(soma), y = probabilidade)) +\n  geom_bar(stat = \"identity\", fill = \"#2780e3\") +\n  geom_text(aes(label = fracoes), vjust = -0.5, size = 4) +\n  labs(title = \"Função Massa de Probabilidade da Soma de Dois Dados\",\n       x = \"Soma dos Dados\",\n       y = \"Probabilidade\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nObserve que, neste caso, a FDA pode ser visualizada abaixo:\n\n\nMostrar Código\n# Cria uma função que calcula P(X = x_i) onde x_i é a soma das duas faces\ncalcula_prob_soma &lt;- function(soma) {\n  # Contar combinações possíveis que resultam na soma\n  combinacoes &lt;- expand.grid(dado1=1:6, dado2=1:6)\n  total &lt;- nrow(combinacoes)\n  resultados_validos &lt;- sum(rowSums(combinacoes) == soma)\n  prob &lt;- resultados_validos / total\n  return(prob)\n}\n\n# Aplica a função acima para todo o espaço amostral Omega\nsomas &lt;- 0:12\nprobabilidades &lt;- sapply(somas, calcula_prob_soma)\n\n# Criar data frame\ndados_somas &lt;- tibble::tibble(\n  soma = somas,\n  probabilidade = probabilidades,\n  fda = cumsum(probabilidade)\n) %&gt;%\n  distinct(fda, .keep_all = T) # Evita segmentos redundantes\n\ndados_grafico &lt;- dados_somas %&gt;%\n  mutate(tipo = \"fda\") %&gt;%\n  bind_rows(dados_somas %&gt;%\n              mutate(tipo = \"previa_fda\",\n                     fda = lag(fda))) %&gt;%\n  tidyr::drop_na() %&gt;%\n  rename(x = soma) %&gt;%\n  arrange(x, desc(tipo))\n\nggplot(dados_grafico) + \n  geom_segment(aes(x = lag(x), y = lag(fda), xend = x, yend = fda, lty = tipo)) +\n  geom_point(data = slice(dados_grafico, -1), aes(x, fda, fill = tipo), shape = 21) + # Retira ponto mais extremo para ilustrar o -infinito\n  scale_fill_manual(values = c(\"black\", \"white\")) +\n  scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n  labs(title = \"FDA teórica da soma de dois dados honestos\",\n       x = \"Soma das Faces\",\n       y = \"P(X ≤ x)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(breaks = 0:13, limits = c(0, 13)) +\n  geom_segment(aes(x = 12, y = 1, xend = 13, yend = 1)) # Segmento mais extremo para ilustrar o +infinito",
    "crumbs": [
      "Conceitos Básicos",
      "Variáveis Aleatórias"
    ]
  },
  {
    "objectID": "Int_Prob/4_variaveis_aleatorias.html#variáveis-aleatórias-contínuas",
    "href": "Int_Prob/4_variaveis_aleatorias.html#variáveis-aleatórias-contínuas",
    "title": "Variáveis Aleatórias",
    "section": "Variáveis Aleatórias Contínuas",
    "text": "Variáveis Aleatórias Contínuas\nDefinição Uma variável aleatória \\(X\\) é dita contínua se existe uma função \\(f_X(.)\\) tal que \\(F_X(x) = \\int_\\limits{-\\infty}^{x}f_{X}(u)d(u), \\forall x \\in \\mathbb{R}\\). Se \\(X\\) é contíuna, então a função \\(f_X(x)\\) é chamada de função densidade de probabilidade de \\(X\\) aplicada no ponto \\(x\\).\nPara qualquer função densidade de uma V.A. \\(X\\), contínua tem-se as seguintes propriedades:\n\n\\(f_X(x) \\ge 0, \\forall x \\in \\mathbb{R}\\)\n\\(\\int\\limits_{-\\infty}^{+\\infty}f(x)dx = 1\\).\n\nUm ponto interessante é que a definição de uma função de densidade poderia ser dada simplesmente por essas propriedades. Isto é, qualquer função \\(f(.)\\) que respeite as propriedades acima será função de densidade de probabilidade de alguma variável aleatória existente (mesmo sem mencioná-la!).\nPara obter a probabilidade de uma variável aleatória \\(X\\) estar entre dois valores \\(a,b \\in \\mathbb{R}, a &lt; b\\), podemos usar as definições usuais de cálculo integral. Isto é:\n\\(P(a &lt; X &lt; b) = \\int\\limits_{a}^{b}f(x)dx = F_X(b) - F_X(a)\\)\nAlém disso, \\(P(X = a) = 0, \\forall a \\in \\mathbb{R}\\).\nObserve que para variáveis aleatórias contínuas nos pontos \\(a\\) e \\(b\\), o valor da probabilidade não se altera se incluímos ou excluímos na desiguldade os valores. Isto é:\n\\[\nP(a &lt; X &lt; b) = P(a \\le X &lt; b) = P(a &lt; X \\le b) = P(a \\le X \\le b)\n\\]\nExemplo (Mood, Graybill, e Boes (1974)) Seja \\(X\\) uma variável aleatória representando o tempo de uma conversa de telefone. Assuma que a FDA de \\(X\\) é dada por \\(F_X(x) = \\left( 1 - e^{-\\lambda x} \\right), x \\ge 0\\) e assuma também que \\(\\lambda &gt; 0\\). A função densidade de probabilidade correspondente é dada por \\(f_X(x) = \\lambda e^{-\\lambda x}, x \\ge 0\\). Assuma que a função é dada em medidas de minutos. Então, assumindo \\(\\lambda = \\frac{1}{5}\\), qual a probabilidade de uma ligação durar entre 5 e 10 minutos?\nEssa resposta pode ser dada pela função densidade:\n\\[\nP(5 &lt; X &lt; 10) = \\int\\limits_{5}^{10}\\lambda e^{-\\lambda x} dx = e^{-5\\lambda}-e^{-10\\lambda} = e^{-1}-e^{-2} \\approx 0.23\n\\]\nOu também pela função de distribuição acumulada:\n\\[\nP(5 &lt; X &lt; 10) = P(X &lt; 10) - P(X &lt; 5) = F_X(10) - F_X(5) = (1- e^{-\\lambda 10}) -  (1- e^{-\\lambda 5}) = e^{-1} - e^{-2}  \\approx 0.23\n\\]\nAbaixo podemos ver a representação gráfica do valor dessa probabilidade:\n\n\nMostrar Código\nlibrary(ggplot2)\n\nvalor_lambda &lt;- 1 / 5\nlower_bound &lt;- 5\nupper_bound &lt;- 10\n\n# Obs: a função interna do R possui a mesma parametrização de Mood e Graybill\n# De qualquer forma, poderíamos criar a nossa própria versão da exponencial como por exemplo:\n# dexp_2 &lt;- function(x, lambda) {ifelse(x &gt;= 0, lambda * exp(-lambda * x), 0)}\n\nx_values &lt;- seq(0, 12, by = 0.01) # Ajustar à gosto\nexp_data &lt;- data.frame(x = x_values, y = dexp(x_values, rate = valor_lambda))\n\nshaded_area_data &lt;- subset(exp_data, x &gt;= lower_bound & x &lt;= upper_bound)\nshaded_area_data &lt;- rbind(c(lower_bound, 0), shaded_area_data, c(upper_bound, 0))\n\nggplot(exp_data, aes(x = x, y = y)) +\n  geom_line(color = \"blue\") + # Densidade de Probabilidade\n  geom_polygon(data = shaded_area_data, aes(x = x, y = y), fill = \"red\", alpha = 0.5) + # Área Hachurada\n  labs(title = substitute(paste(\"Função Densidade de Probabilidade (\",lambda,\" = \", x , \")\"), list(x = valor_lambda)), # Não pode ser paste0\n       x = \"x\",\n       y = \"Valor da Densidade f(x)\") +\n  ylim(c(0,1)) +\n  theme_minimal()",
    "crumbs": [
      "Conceitos Básicos",
      "Variáveis Aleatórias"
    ]
  },
  {
    "objectID": "Int_Prob/5_variaveis_aleatorias.html",
    "href": "Int_Prob/5_variaveis_aleatorias.html",
    "title": "Conceitos Básicos",
    "section": "",
    "text": "Informalmente, uma variável aleatória (V.A.) é um valor numérico do resultado de um experimento aleatório. Formalmente, abaixo segue a definição (Magalhães (2006), James (2023)):\nDefinição Seja \\((\\Omega, \\mathcal{F}, \\mathcal{P})\\) um espaço de probabilidade. Denominamos de variável aleatória, qualquer função \\(X : \\Omega \\rightarrow \\mathbb{R}\\) tal que \\([X \\le x]\\) é evento aleatório para todo \\(x \\in \\mathbb{R}\\); isto é, \\([X \\le x] \\in \\mathcal{F}, \\forall x \\in \\mathbb{R}\\)1.\nExemplo (Mood, Graybill, e Boes (1974)) Assuma um experimento de lançar uma moeda honesta para cima. Defina a variável aleatória \\(X\\) assumir o valor \\(1\\) quando sair cara, e o valor \\(0\\) quando sair coroa. Ou seja:\n\\[\n\\begin{align*}\n\\Omega &= \\{cara, coroa\\} \\\\\nX &=\n\\begin{cases}\n  1, & \\text{ se $\\omega$ = \\{cara\\},} \\\\\n  0, & \\text{ se $\\omega$ = \\{coroa\\}}\n\\end{cases}\n\\end{align*}\n\\]\nFormalmente, precisamos mostrar que esta construção deste experimento \\(X\\) mostrando que \\(\\{\\omega: X(\\omega) \\le x\\}\\) para todo \\(x \\in \\mathbb{R}\\) pertence à \\(\\mathcal{F}\\). Primeiramente, note que \\(\\mathcal{F}\\) é composto por quatro elementos sendo \\(\\{\\emptyset, \\Omega, \\{cara\\},\\{coroa\\}\\}\\). Agora, verificamos que se \\(x &lt; 0\\), \\(\\{\\omega: X(\\omega) \\le x\\} = \\emptyset\\); e se \\(0 \\le x &lt; 0\\), \\(\\{\\omega: X(\\omega) \\le x\\} = \\{cara\\}\\); e se \\(x \\ge 1\\), \\(\\{\\omega: X(\\omega) \\le x\\} = \\Omega = \\{cara, coroa\\}\\). Então, pra cada \\(x\\) real o evento \\(\\{\\omega: X(\\omega) \\le x\\}\\) pertence à \\(\\sigma\\)-álgebra \\(\\mathcal{F}\\) e, portanto, \\(X\\) é variável aleatória.\nExemplo (Mood, Graybill, e Boes (1974)) Assuma um experimento de lançar dois dados honestos de seis lados, sendo o dado \\(i\\) e o dado \\(j\\). Defina a variável aleatória \\(X\\) assumir o valor da soma das suas faces, ou seja, \\(X(\\omega) = i+j\\), onde \\(\\Omega = \\{(i,j): i,j = 1, 2,...,6\\}\\)\nDefinição Função de Distribuição Acumulada (FDA) A FDA de uma V.A. \\(X\\) aplicada no ponto \\(x\\) denotada por \\(F_X(x)\\), é uma função com domínio nos números reais e imagem (contra domínio) no intervalo \\([0,1]\\) que satisfaz \\(F_X(x) = P(X \\le x), \\forall x \\in \\mathbb{R}\\).\nA FDA é unicamente definida para cada variável aleatória. Ou seja, uma variável aleatória \\(X\\) possui uma única respectiva função \\(F_X(.)\\).\nPara qualquer FDA de uma V.A. \\(X\\), tem-se as seguintes propriedades:\n\n\\(0 \\le F_X(x) \\le 1\\)\n\\(F_X(x)\\) é não decrescente. Isto é, se \\(x_1 \\le x_2 \\implies F_X(x_1) \\le F_X(x_2)\\)\n\\(F_X(-\\infty) = \\lim\\limits_{n \\to -\\infty}F_X(x) = 0\\)\n\\(F_X(+\\infty) = \\lim\\limits_{n \\to +\\infty}F_X(x) = 1\\)\n\nUm ponto interessante é que a definição de uma FDA poderia ser dada simplesmente por essas propriedades. Isto é, qualquer função \\(F(.)\\) que respeite as propriedades acima será FDA de alguma variável aleatória existente (mesmo sem mencioná-la!).",
    "crumbs": [
      "Variáveis Aleatórias",
      "Conceitos Básicos"
    ]
  },
  {
    "objectID": "Int_Prob/5_variaveis_aleatorias.html#variáveis-aleatórias-discretas",
    "href": "Int_Prob/5_variaveis_aleatorias.html#variáveis-aleatórias-discretas",
    "title": "Conceitos Básicos",
    "section": "Variáveis Aleatórias Discretas",
    "text": "Variáveis Aleatórias Discretas\nDefinição Se os valores considerados de \\(X\\) são contáveis, então \\(X\\) é considerado discreto.\nNote que se \\(X\\) é contável assumindo, por exemplo, valores \\(x_1, x_2, ..., x_n, ...\\), então \\(\\Omega = \\bigcup\\limits_{i=1}^{\\infty} \\{X = x_n\\}\\), mas como os \\(x_i\\)’s podem ser vistos como eventos disjuntos, isto é, \\(\\{X = x_i\\} \\cap \\{X = x_j\\} = \\emptyset, \\forall i \\ne j\\); então, \\(1 = P(\\Omega) = \\sum\\limits_{i=1}^{\\infty}P(X = x_i)\\) pelo terceiro axioma de Kolmogorov.\nA função densidade de probabilidade, \\(f_X(.)\\) é definida como sendo\n\\[\n\\begin{align*}\nf_X(x) &=\n\\begin{cases}\n  P(X = x_i), & \\text{se}\\ x=x_i,\\ i = 1, 2, ...  \\\\\n  0, & \\text{caso contrário}\n\\end{cases}\n\\end{align*}\n\\]\nA função densidade de probabilidade de uma VA discreta também pode ser chamada de função massa de probabilidade.\nExemplo Função de densidade do lançamento de um dado honesto sendo \\(X\\) definido como sendo o valor da face.\n\n\nMostrar Código\n# Carregar o pacote ggplot2\nlibrary(ggplot2)\n\n# Dados: resultados do dado e suas probabilidades\ndados &lt;- data.frame(\n  face = 1:6,\n  probabilidade = rep(1/6, 6),\n  fracoes = '1/6'\n)\n\n# Criar o gráfico de barras\nggplot(dados, aes(x = factor(face), y = probabilidade)) +\n  geom_bar(stat = \"identity\", fill = \"#2780e3\") +\n  geom_text(aes(label = fracoes), vjust = -0.5, size = 4) +\n  labs(title = \"Função Massa de Probabilidade de um Dado Honesto\",\n       x = \"Face do Dado\",\n       y = \"Probabilidade\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nObserve que, neste caso, a FDA pode ser visualizada abaixo:\n\n\nMostrar Código\n# Código inspirado em https://stackoverflow.com/questions/52236576/r-ggplot-make-geom-step-jumps-dashed\n\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndados &lt;- tibble::tibble(\n  x = 0:6,\n  probabilidade = c(0, rep(1/6, 6)),\n  fda = cumsum(probabilidade))\n\ndados_grafico &lt;- dados %&gt;%\n  mutate(tipo = \"fda\") %&gt;%\n  bind_rows(dados %&gt;%\n              mutate(tipo = \"previa_fda\",\n                     fda = lag(fda))) %&gt;%\n  tidyr::drop_na() %&gt;%\n  arrange(x, desc(tipo))\n\nggplot(dados_grafico) + \n  geom_segment(aes(x = lag(x), y = lag(fda), xend = x, yend = fda, lty = tipo)) +\n  geom_point(data = slice(dados_grafico, -1), aes(x, fda, fill = tipo), shape = 21) + # Retira ponto mais extremo para ilustrar o -infinito\n  scale_fill_manual(values = c(\"black\", \"white\")) +\n  scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n  labs(title = \"FDA teórica de um dado honesto (6 faces)\",\n       x = \"Face x\",\n       y = \"P(X ≤ x)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  geom_segment(aes(x = 6, y = 1, xend = 7, yend = 1)) # Segmento mais extremo para ilustrar o +infinito\n\n\n\n\n\n\n\n\n\nExemplo Função de densidade do lançamento de dois dados honestos sendo \\(X\\) definido como sendo o valor da soma das duas faces.\n\n\nMostrar Código\nlibrary(ggplot2)\nlibrary(MASS)\n\n# Cria uma função que calcula P(X = x_i) onde x_i é a soma das duas faces\ncalcula_prob_soma &lt;- function(soma) {\n  # Contar combinações possíveis que resultam na soma\n  combinacoes &lt;- expand.grid(dado1=1:6, dado2=1:6)\n  total &lt;- nrow(combinacoes)\n  resultados_validos &lt;- sum(rowSums(combinacoes) == soma)\n  prob &lt;- resultados_validos / total\n  return(prob)\n}\n\n# Aplica a função acima para todo o espaço amostral Omega\nsomas &lt;- 2:12\nprobabilidades &lt;- sapply(somas, calcula_prob_soma)\n\n# Convertendo para frações em formato string\nfracoes_str &lt;- sapply(probabilidades, function(p) as.character(fractions(p)))\n\n# Criar data frame\ndados_somas &lt;- data.frame(\n  soma = somas,\n  probabilidade = probabilidades,\n  fracoes = fracoes_str\n)\n\n# Plotagem\nggplot(dados_somas, aes(x = factor(soma), y = probabilidade)) +\n  geom_bar(stat = \"identity\", fill = \"#2780e3\") +\n  geom_text(aes(label = fracoes), vjust = -0.5, size = 4) +\n  labs(title = \"Função Massa de Probabilidade da Soma de Dois Dados\",\n       x = \"Soma dos Dados\",\n       y = \"Probabilidade\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nObserve que, neste caso, a FDA pode ser visualizada abaixo:\n\n\nMostrar Código\n# Cria uma função que calcula P(X = x_i) onde x_i é a soma das duas faces\ncalcula_prob_soma &lt;- function(soma) {\n  # Contar combinações possíveis que resultam na soma\n  combinacoes &lt;- expand.grid(dado1=1:6, dado2=1:6)\n  total &lt;- nrow(combinacoes)\n  resultados_validos &lt;- sum(rowSums(combinacoes) == soma)\n  prob &lt;- resultados_validos / total\n  return(prob)\n}\n\n# Aplica a função acima para todo o espaço amostral Omega\nsomas &lt;- 0:12\nprobabilidades &lt;- sapply(somas, calcula_prob_soma)\n\n# Criar data frame\ndados_somas &lt;- tibble::tibble(\n  soma = somas,\n  probabilidade = probabilidades,\n  fda = cumsum(probabilidade)\n) %&gt;%\n  distinct(fda, .keep_all = T) # Evita segmentos redundantes\n\ndados_grafico &lt;- dados_somas %&gt;%\n  mutate(tipo = \"fda\") %&gt;%\n  bind_rows(dados_somas %&gt;%\n              mutate(tipo = \"previa_fda\",\n                     fda = lag(fda))) %&gt;%\n  tidyr::drop_na() %&gt;%\n  rename(x = soma) %&gt;%\n  arrange(x, desc(tipo))\n\nggplot(dados_grafico) + \n  geom_segment(aes(x = lag(x), y = lag(fda), xend = x, yend = fda, lty = tipo)) +\n  geom_point(data = slice(dados_grafico, -1), aes(x, fda, fill = tipo), shape = 21) + # Retira ponto mais extremo para ilustrar o -infinito\n  scale_fill_manual(values = c(\"black\", \"white\")) +\n  scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n  labs(title = \"FDA teórica da soma de dois dados honestos\",\n       x = \"Soma das Faces\",\n       y = \"P(X ≤ x)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(breaks = 0:13, limits = c(0, 13)) +\n  geom_segment(aes(x = 12, y = 1, xend = 13, yend = 1)) # Segmento mais extremo para ilustrar o +infinito",
    "crumbs": [
      "Variáveis Aleatórias",
      "Conceitos Básicos"
    ]
  },
  {
    "objectID": "Int_Prob/5_variaveis_aleatorias.html#variáveis-aleatórias-contínuas",
    "href": "Int_Prob/5_variaveis_aleatorias.html#variáveis-aleatórias-contínuas",
    "title": "Conceitos Básicos",
    "section": "Variáveis Aleatórias Contínuas",
    "text": "Variáveis Aleatórias Contínuas\nDefinição Uma variável aleatória \\(X\\) é dita contínua se existe uma função \\(f_X(.)\\) tal que \\(F_X(x) = \\int_\\limits{-\\infty}^{x}f_{X}(u)d(u), \\forall x \\in \\mathbb{R}\\). Se \\(X\\) é contíuna, então a função \\(f_X(x)\\) é chamada de função densidade de probabilidade de \\(X\\) aplicada no ponto \\(x\\).\nPara qualquer função densidade de uma V.A. \\(X\\), contínua tem-se as seguintes propriedades:\n\n\\(f_X(x) \\ge 0, \\forall x \\in \\mathbb{R}\\)\n\\(\\int\\limits_{-\\infty}^{+\\infty}f(x)dx = 1\\).\n\nUm ponto interessante é que a definição de uma função de densidade poderia ser dada simplesmente por essas propriedades. Isto é, qualquer função \\(f(.)\\) que respeite as propriedades acima será função de densidade de probabilidade de alguma variável aleatória existente (mesmo sem mencioná-la!).\nPara obter a probabilidade de uma variável aleatória \\(X\\) estar entre dois valores \\(a,b \\in \\mathbb{R}, a &lt; b\\), podemos usar as definições usuais de cálculo integral. Isto é:\n\\(P(a &lt; X &lt; b) = \\int\\limits_{a}^{b}f(x)dx = F_X(b) - F_X(a)\\)\nAlém disso, \\(P(X = a) = 0, \\forall a \\in \\mathbb{R}\\).\nObserve que para variáveis aleatórias contínuas nos pontos \\(a\\) e \\(b\\), o valor da probabilidade não se altera se incluímos ou excluímos na desiguldade os valores. Isto é:\n\\[\nP(a &lt; X &lt; b) = P(a \\le X &lt; b) = P(a &lt; X \\le b) = P(a \\le X \\le b)\n\\]\nExemplo (Mood, Graybill, e Boes (1974)) Seja \\(X\\) uma variável aleatória representando o tempo de uma conversa de telefone. Assuma que a FDA de \\(X\\) é dada por \\(F_X(x) = \\left( 1 - e^{-\\lambda x} \\right), x \\ge 0\\) e assuma também que \\(\\lambda &gt; 0\\). A função densidade de probabilidade correspondente é dada por \\(f_X(x) = \\lambda e^{-\\lambda x}, x \\ge 0\\). Assuma que a função é dada em medidas de minutos. Então, assumindo \\(\\lambda = \\frac{1}{5}\\), qual a probabilidade de uma ligação durar entre 5 e 10 minutos?\nEssa resposta pode ser dada pela função densidade:\n\\[\nP(5 &lt; X &lt; 10) = \\int\\limits_{5}^{10}\\lambda e^{-\\lambda x} dx = e^{-5\\lambda}-e^{-10\\lambda} = e^{-1}-e^{-2} \\approx 0.23\n\\]\nOu também pela função de distribuição acumulada:\n\\[\nP(5 &lt; X &lt; 10) = P(X &lt; 10) - P(X &lt; 5) = F_X(10) - F_X(5) = (1- e^{-\\lambda 10}) -  (1- e^{-\\lambda 5}) = e^{-1} - e^{-2}  \\approx 0.23\n\\]\nAbaixo podemos ver a representação gráfica do valor dessa probabilidade:\n\n\nMostrar Código\nlibrary(ggplot2)\n\nvalor_lambda &lt;- 1 / 5\nlower_bound &lt;- 5\nupper_bound &lt;- 10\n\n# Obs: a função interna do R possui a mesma parametrização de Mood e Graybill\n# De qualquer forma, poderíamos criar a nossa própria versão da exponencial como por exemplo:\n# dexp_2 &lt;- function(x, lambda) {ifelse(x &gt;= 0, lambda * exp(-lambda * x), 0)}\n\nx_values &lt;- seq(0, 12, by = 0.01) # Ajustar à gosto\nexp_data &lt;- data.frame(x = x_values, y = dexp(x_values, rate = valor_lambda))\n\nshaded_area_data &lt;- subset(exp_data, x &gt;= lower_bound & x &lt;= upper_bound)\nshaded_area_data &lt;- rbind(c(lower_bound, 0), shaded_area_data, c(upper_bound, 0))\n\nggplot(exp_data, aes(x = x, y = y)) +\n  geom_line(color = \"blue\") + # Densidade de Probabilidade\n  geom_polygon(data = shaded_area_data, aes(x = x, y = y), fill = \"red\", alpha = 0.5) + # Área Hachurada\n  labs(title = substitute(paste(\"Função Densidade de Probabilidade (\",lambda,\" = \", x , \")\"), list(x = valor_lambda)), # Não pode ser paste0\n       x = \"x\",\n       y = \"Valor da Densidade f(x)\") +\n  ylim(c(0,1)) +\n  theme_minimal()",
    "crumbs": [
      "Variáveis Aleatórias",
      "Conceitos Básicos"
    ]
  },
  {
    "objectID": "Int_Prob/5_variaveis_aleatorias.html#footnotes",
    "href": "Int_Prob/5_variaveis_aleatorias.html#footnotes",
    "title": "Conceitos Básicos",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nEsta definição formal matemática, na sua integridade, pode parece difícil de assimilar num primeiro momento. Em linhas gerais, uma variável aleatória deve ser uma função mensurável dentro da sua \\(\\sigma\\)-álgebra do espaço de probabildade. Por exemplo, é possível definir uma \\(\\sigma\\)-álgebra de maneira incoveniente e fazer com que algumas variáveis aleatórias não se encaixem como função mensurável por ter que depender de eventos aleatórios que não estejam presentes em \\(\\mathcal{F}\\). Nesse sentido, o cojunto das partes e a \\(\\sigma\\)-álgebra de Borel são as preferidas, justamente por permitirem que praticamente todas as variáveis de interesse sejam mensuráveis. Para maiores detalhes, ver o exemplo 2.1 de Magalhães (2006) e as observações da Seção 2.1 de James (2023).↩︎",
    "crumbs": [
      "Variáveis Aleatórias",
      "Conceitos Básicos"
    ]
  },
  {
    "objectID": "Int_Prob/3_aplicacoes_probabilidade_combinatoria.html",
    "href": "Int_Prob/3_aplicacoes_probabilidade_combinatoria.html",
    "title": "Aplicações de Probabilidade em arranjos, permutações e combinações",
    "section": "",
    "text": "Definição O Fatorial de um número \\(n\\) é o produto de todos os naturais menores ou iguais a \\(n\\). Notação: fatorial de \\(n\\) é dado por \\(n!\\).\n\\[\nn! = n\\times(n-1)\\times(n-2)\\times ... \\times 1\n\\]\nDefinição Uma Permutação é o número de maneiras de ordenar os elementos de um conjunto, de forma que a ordem de cada elemento seja considerada e a ordem de todos os elementos seja diferente. Se em um conjunto estiver presentes \\(m\\) elementos distintos, a quantidade de maneiras diferentes que podemos ordenar é dada pelo Fatorial de \\(m\\), ou seja, por \\(m!\\).\nDefinição Um Arranjo é um agrupamento ordenado de elementos de um conjunto, onde a ordem dos elementos importa. Notação: o arranjo de \\(N\\) elementos em subgrupos de \\(n\\) elementos é dado por \\(A^N_n\\).\n\\[\nA^N_n = \\frac{N!}{(N-n)!} = N(N-1)...(N-n+1)\n\\]\nDefinição Uma Combinação é um agrupamento de elementos de um conjunto, onde a ordem dos elementos não importa. Notação: a combinação de \\(N\\) elementos em subgrupos de \\(n\\) elementos é dado por \\(C^N_n\\) ou \\({N \\choose n}\\).\n\\[\nC^N_n = \\frac{A^N_n}{n!} = \\frac{N!}{n!(N-n)!} = \\frac{N(N-1)...(N-n+1)}{n!}\n\\]\nPela definição clássica de probabilidade, a probabilidade de um evento \\(A\\) é dada por:\n\\[\nP(A) = \\frac{Número\\ de\\ Elementos\\ em\\ A}{Número\\ total\\ de\\ Elementos\\ em\\ \\Omega}\n\\]",
    "crumbs": [
      "Probabilidade",
      "Aplicações de Probabilidade em arranjos, permutações e combinações"
    ]
  },
  {
    "objectID": "Int_Prob/3_aplicacoes_probabilidade_combinatoria.html#definições",
    "href": "Int_Prob/3_aplicacoes_probabilidade_combinatoria.html#definições",
    "title": "Aplicações de Probabilidade em arranjos, permutações e combinações",
    "section": "",
    "text": "Definição O Fatorial de um número \\(n\\) é o produto de todos os naturais menores ou iguais a \\(n\\). Notação: fatorial de \\(n\\) é dado por \\(n!\\).\n\\[\nn! = n\\times(n-1)\\times(n-2)\\times ... \\times 1\n\\]\nDefinição Uma Permutação é o número de maneiras de ordenar os elementos de um conjunto, de forma que a ordem de cada elemento seja considerada e a ordem de todos os elementos seja diferente. Se em um conjunto estiver presentes \\(m\\) elementos distintos, a quantidade de maneiras diferentes que podemos ordenar é dada pelo Fatorial de \\(m\\), ou seja, por \\(m!\\).\nDefinição Um Arranjo é um agrupamento ordenado de elementos de um conjunto, onde a ordem dos elementos importa. Notação: o arranjo de \\(N\\) elementos em subgrupos de \\(n\\) elementos é dado por \\(A^N_n\\).\n\\[\nA^N_n = \\frac{N!}{(N-n)!} = N(N-1)...(N-n+1)\n\\]\nDefinição Uma Combinação é um agrupamento de elementos de um conjunto, onde a ordem dos elementos não importa. Notação: a combinação de \\(N\\) elementos em subgrupos de \\(n\\) elementos é dado por \\(C^N_n\\) ou \\({N \\choose n}\\).\n\\[\nC^N_n = \\frac{A^N_n}{n!} = \\frac{N!}{n!(N-n)!} = \\frac{N(N-1)...(N-n+1)}{n!}\n\\]\nPela definição clássica de probabilidade, a probabilidade de um evento \\(A\\) é dada por:\n\\[\nP(A) = \\frac{Número\\ de\\ Elementos\\ em\\ A}{Número\\ total\\ de\\ Elementos\\ em\\ \\Omega}\n\\]",
    "crumbs": [
      "Conceitos Básicos",
      "Aplicações de Probabilidade em arranjos, permutações e combinações"
    ]
  },
  {
    "objectID": "Int_Prob/4_probabilidade_condicional_e_independencia.html",
    "href": "Int_Prob/4_probabilidade_condicional_e_independencia.html",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Definição Sejam dois eventos \\(A\\) e \\(B\\) definidos no mesmo espaço de probabilidade, a probabilidade condicional de \\(A\\) dado o evento \\(B\\), denotado por \\(P(A|B)\\) é definido por\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)}, \\ \\ \\ \\ se \\ P(B) &gt; 0,\n\\]\ne é indefinida se \\(P(B) = 0\\). Um resultado direto dessa definição é que \\(P(A|B)P(B) = P(B|A)P(A)\\).\nExemplo Suponha o lançamento de um Dado Honesto, ou seja, \\(\\Omega = \\{\\{1\\}, \\{2\\}, \\{3\\}, \\{4\\}, \\{5\\}, \\{6\\}\\}\\), qual a probabilidade de sair o número 2, dado que saiu um número par?\nSeja,\n\n\\(A\\): sair o número 2\n\\(B\\): sair par\n\n\\[\nP(A|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(\\text{sair 2 e par})}{P(\\text{par})}  \\overset{A \\subset B}{=} \\frac{P(\\text{sair 2})}{P(\\text{par})}  = \\frac{\\frac{1}{6}}{\\frac{1}{2}} = \\frac{1}{3}\n\\]\nNote que “dado o evento \\(B\\)” significa dizer que o “evento \\(B\\)” ocorreu e, sendo assim, “limitamos” o espaço amostral para o evento B. Ou seja, não estamos mais trabalhando com \\(\\Omega\\), mas sim somente com os elementos do evento \\(B\\) sendo possíveis. Dado isto, será que este novo cenário satisfazem os axiomas de Kolmogorov caso \\(P(B)&gt;0\\)? A resposta é sim, pois:\n\n\\(P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\ge 0, \\forall A \\in \\mathcal{F}\\)\n\\(P(\\Omega|B) = \\frac{P(A \\cap B)}{P(B)} = \\frac{P(B)}{P(B)} = 1\\)\nSe \\(A_1, A_2, ...\\) são mutuamente excludentes de \\(\\mathcal{F}\\), então\n\n\\[\nP\\left( \\bigcup_{i=1}^{n} A_i |B \\right) = \\frac{P\\left( \\left(\\bigcup_{i=1}^{n} A_i \\right)\\cap B \\right)}{P(B)} \\overset{Lei \\ Distributiva}{=} \\frac{P\\left( \\bigcup_{i=1}^{n} \\left(A_i \\cap B \\right)\\right)}{P(B)} = \\frac{\\sum_{i=1}^{n}P\\left( A_i \\cap B \\right)}{P(B)} = \\sum_{i=1}^{n}\\left(\\frac{P(A_i \\cap B) }{P(B)}\\right) = \\sum_{i=1}^{n}P\\left( A_i | B \\right)\n\\] Desta maneira, para quaquer \\(B\\) satisfazendo \\(P(B) &gt; 0\\), qualquer função de probabilidade aplicada no subespaço de \\(B\\) também é uma função de probabilidade e goza das mesmas propriedades de uma função não-condicionada.\n\n\nAntes de apresentar o teorema da probabilidade total, apresenta-se a definição de partição do espaço amostral:\nDefinição Se \\(B_1, B_2, ..., B_n\\) representa um conjunto de eventos mutuamente excludentes satisfazendo \\(\\Omega = \\bigcup\\limits_{i=1}^{n}B_i\\) então, dizemos que \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\).\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\):\n\\[\nP(A) = P\\left(\\bigcup\\limits_{i=1}^{n}(A \\cap B_i)\\right) = \\sum\\limits_{i=1}^{n}P(A \\cap B_i) = \\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)\n\\]\nVisualmente:\n\n\n\nExemplo de uma partição de \\(\\Omega\\) para \\(n = 5\\) e um evento A (extraído de DeGroot e Schervish (2012))\n\n\nRessalta-se que o Teorema da Probabilidade Total vale também quando \\(n = \\infty\\)\n\n\n\nO Teorema de Bayese, na sua forma extendida1, é visto como a probabilidade de um evento de uma partição condicionado à um evento já ocorrido do espaço amostral. A fórmula de Bayes é definida a seguir:\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\) temos que\n\\[\nP(B_i |A) = \\frac{P(A | B_i) P(B_i)} {\\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)} \\ \\ \\ \\forall i=1,...n.\n\\] Ressalta-se que o Teorema de Bayes vale também quando \\(n = \\infty\\).\nObserve que o denominador da Fórmula de Bayes é o valor do Teorema da Probabilidade Total definida anteriormente.\nO Teorema de Bayes é particularmente útil quando estamos tratando com experimentos em múltiplas fases. Se \\(B_i\\) é um evento condicionado à um evento \\(A\\), então querer saber \\(P(B_i|A)\\) é como se fosse no sentido de retrospectiva (“backward”). É como se fosse questionar sobre a probabilidade da primeira fase, condicionada no que aconteceu na segunda fase do experimento. Por isso, o Teorema de Bayes também é chamado de teorema da probabilidade a posteriori (Morettin (1999)).\nExemplo Suponha que em uma urna nós temos três moedas: sendo duas honestas e uma viciada com duas faces “caras”. Suponha que eu retire, aleatoriamente, uma moeda urna e jogue pra cima e saia a face “cara”. Então, dado que saiu “cara”, qual a probabilidade de eu ter sorteado a moeda viciada?\nPodemos pensar neste problema da seguinte forma ilustrativa:\n\n\n\nIlustração de experimento de duas fases\n\n\nOriginalmente, \\(P(B_3) = \\frac{1}{3}\\), no entanto, a probabilidade condicionada a posteriori é:\n\\[\nP(B_3|A) = \\frac{P(A | B_3) P(B_3)} {P(A | B_1)P(B_1) + P(A | B_2)P(B_2) + P(A | B_3)P(B_3)} = \\frac{1 \\times \\frac{1}{3}} {\\frac{1}{2} \\times \\frac{1}{3} + \\frac{1}{2} \\times \\frac{1}{3} + 1\\times \\frac{1}{3}} = \\frac{\\frac{1}{3}}{\\frac{4}{6}} = \\frac{1}{2}\n\\]\nOu seja, note que a probabilidade “atualizou” de \\(\\frac{1}{3}\\) para \\(\\frac{1}{2}\\).\n\n\n\nOutro resultado importante é a regra da multiplicação abaixo:\nTeorema Sejam \\(A_1, A_2, ..., A_n\\) diferentes eventos de um espaço de probabilidade, então:\n\\[\nP(A_1 \\cap A_2 \\cap ... \\cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2 \\cap A_1)...P(A_n|A_1 \\cap ... \\cap A_{n-1})\n\\]\nOu, conforme Mood, Graybill, e Boes (1974), em notação alternativa:\n\\[\nP(A_1A_2 ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2A_1)...P(A_n|A_1... A_{n-1})\n\\]",
    "crumbs": [
      "Probabilidade",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/4_probabilidade_condicional_e_independencia.html#teorema-da-probabilidade-total",
    "href": "Int_Prob/4_probabilidade_condicional_e_independencia.html#teorema-da-probabilidade-total",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Antes de apresentar o teorema da probabilidade total, apresenta-se a definição de partição do espaço amostral:\nDefinição Se \\(B_1, B_2, ..., B_n\\) representa um conjunto de eventos mutuamente excludentes satisfazendo \\(\\Omega = \\bigcup\\limits_{i=1}^{n}B_i\\) então, dizemos que \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\).\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\):\n\\[\nP(A) = P\\left(\\bigcup\\limits_{i=1}^{n}(A \\cap B_i)\\right) = \\sum\\limits_{i=1}^{n}P(A \\cap B_i) = \\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)\n\\]\nVisualmente:\n\n\n\nExemplo de uma partição de \\(\\Omega\\) para \\(n = 5\\) e um evento A (extraído de DeGroot e Schervish (2012))\n\n\nRessalta-se que o Teorema da Probabilidade Total vale também quando \\(n = \\infty\\)",
    "crumbs": [
      "Probabilidade",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/4_probabilidade_condicional_e_independencia.html#teorema-de-bayes",
    "href": "Int_Prob/4_probabilidade_condicional_e_independencia.html#teorema-de-bayes",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "O Teorema de Bayese, na sua forma extendida1, é visto como a probabilidade de um evento de uma partição condicionado à um evento já ocorrido do espaço amostral. A fórmula de Bayes é definida a seguir:\nTeorema Se \\(B_1, B_2, ..., B_n\\) forma uma partição de \\(\\Omega\\) então para qualquer evento \\(A\\) temos que\n\\[\nP(B_i |A) = \\frac{P(A | B_i) P(B_i)} {\\sum\\limits_{i=1}^{n}P(A | B_i)P(B_i)} \\ \\ \\ \\forall i=1,...n.\n\\] Ressalta-se que o Teorema de Bayes vale também quando \\(n = \\infty\\).\nObserve que o denominador da Fórmula de Bayes é o valor do Teorema da Probabilidade Total definida anteriormente.\nO Teorema de Bayes é particularmente útil quando estamos tratando com experimentos em múltiplas fases. Se \\(B_i\\) é um evento condicionado à um evento \\(A\\), então querer saber \\(P(B_i|A)\\) é como se fosse no sentido de retrospectiva (“backward”). É como se fosse questionar sobre a probabilidade da primeira fase, condicionada no que aconteceu na segunda fase do experimento. Por isso, o Teorema de Bayes também é chamado de teorema da probabilidade a posteriori (Morettin (1999)).\nExemplo Suponha que em uma urna nós temos três moedas: sendo duas honestas e uma viciada com duas faces “caras”. Suponha que eu retire, aleatoriamente, uma moeda urna e jogue pra cima e saia a face “cara”. Então, dado que saiu “cara”, qual a probabilidade de eu ter sorteado a moeda viciada?\nPodemos pensar neste problema da seguinte forma ilustrativa:\n\n\n\nIlustração de experimento de duas fases\n\n\nOriginalmente, \\(P(B_3) = \\frac{1}{3}\\), no entanto, a probabilidade condicionada a posteriori é:\n\\[\nP(B_3|A) = \\frac{P(A | B_3) P(B_3)} {P(A | B_1)P(B_1) + P(A | B_2)P(B_2) + P(A | B_3)P(B_3)} = \\frac{1 \\times \\frac{1}{3}} {\\frac{1}{2} \\times \\frac{1}{3} + \\frac{1}{2} \\times \\frac{1}{3} + 1\\times \\frac{1}{3}} = \\frac{\\frac{1}{3}}{\\frac{4}{6}} = \\frac{1}{2}\n\\]\nOu seja, note que a probabilidade “atualizou” de \\(\\frac{1}{3}\\) para \\(\\frac{1}{2}\\).",
    "crumbs": [
      "Probabilidade",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/4_probabilidade_condicional_e_independencia.html#regra-da-multiplicação",
    "href": "Int_Prob/4_probabilidade_condicional_e_independencia.html#regra-da-multiplicação",
    "title": "Probabilidade Condicional e Independência",
    "section": "",
    "text": "Outro resultado importante é a regra da multiplicação abaixo:\nTeorema Sejam \\(A_1, A_2, ..., A_n\\) diferentes eventos de um espaço de probabilidade, então:\n\\[\nP(A_1 \\cap A_2 \\cap ... \\cap A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2 \\cap A_1)...P(A_n|A_1 \\cap ... \\cap A_{n-1})\n\\]\nOu, conforme Mood, Graybill, e Boes (1974), em notação alternativa:\n\\[\nP(A_1A_2 ... A_n) = P(A_1)P(A_2|A_1)P(A_3|A_2A_1)...P(A_n|A_1... A_{n-1})\n\\]",
    "crumbs": [
      "Probabilidade",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/4_probabilidade_condicional_e_independencia.html#footnotes",
    "href": "Int_Prob/4_probabilidade_condicional_e_independencia.html#footnotes",
    "title": "Probabilidade Condicional e Independência",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nUm vídeo interessante sobre a aplicação e explicação do Teorema de Bayes pode ser visto aqui: A Armadilha Bayesiana↩︎",
    "crumbs": [
      "Probabilidade",
      "Probabilidade Condicional e Independência"
    ]
  },
  {
    "objectID": "Int_Prob/3_aplicacoes_probabilidade_combinatoria.html#exemplos",
    "href": "Int_Prob/3_aplicacoes_probabilidade_combinatoria.html#exemplos",
    "title": "Aplicações de Probabilidade em arranjos, permutações e combinações",
    "section": "Exemplos:",
    "text": "Exemplos:\nAbaixo, seguem alguns exemplos:\nExemplo Um restaurante oferece oito opções para montar sua refeição, dentre as quais, o cliente pode escolher 4 destas para cada prato. Suponha que um cliente almoçará todos os dias neste restaurante, enquanto houver opções diferentes. Quantos dias este cliente poderá almoçar no restaurante, sem repetir uma refeição?1\nR.: Queremos saber de quantas maneiras diferentes podemos formar subconjuntos com quatro elementos, a partir de um conjunto com 8 elementos distintos.\nNesta escolha, a ordem dos itens escolhidos não possui nenhuma prioridade, por isso, se trata de um problema de combinação.\n\\[\nC^{8}_4 = {8 \\choose 4} = \\frac{8 \\times 7 \\times 6 \\times 5}{4 \\times 3 \\times 2 \\times 1} = 70\n\\]\nExemplo (Dantas (2013)) Seis times participam de um torneio de basquete. Cada uma das equipes enfrentam todas a demais. Quantos jogos serão realizados?\nR.: Precisamos calcular o número de amostras não ordenadas de tamanho 2 de um conjunto de 6 elementos. Logo:\n\\[\nC^{6}_2 = {6 \\choose 2} = \\frac{6 \\times 5}{2 \\times 1} = 15\n\\]\nExemplo Qual a probabilidade de um apostador ganhar o prêmio máximo da mega-sena, fazendo uma aposta mínima, ou seja, apostar exatamente nos seis números sorteados, dentre todos os sessenta números possíveis?\nR.: primeiramente, vamos calcular a quantidade de jogos diferentes de seis números podemos formar com os sessenta números da mega-sena:\n\\[\nC^{60}_6 = {60 \\choose 6} = \\frac{60!}{6!(60-6)!} = \\frac{60 \\times 59  \\times 58  \\times 57  \\times 56  \\times 55}{6 \\times 5 \\times 4 \\times 3 \\times 2 \\times 1} = 50.063.860\n\\]\nFazendo o cálculo da probabilidade pela linguagem R:\n\n\nMostrar Código\nn_sorteios_possiveis &lt;- choose(60, 6)\nprint(paste0(format(1 / n_sorteios_possiveis * 100, scientific = FALSE), \"%\"))\n\n\n[1] \"0.000001997449%\"\n\n\nLogo, a resposta é \\(\\frac{1}{50063860} = 0,000001997449\\%\\).\nExemplo (DeGroot e Schervish (2012)) Suponha que uma moeda honesta seja lançada 10 vezes e que se deseja determinar (a) a probabilidade \\(p_1\\) de obter exatamente três caras e (b) a probabilidade \\(p_2\\) de obter três ou menos caras.\nR.: a) O número total possível de sequências diferentes de 10 caras e coroas é \\(2^{10}\\), e pode-se supor que cada uma dessas sequências seja igualmente provável. O número dessas sequências que contêm exatamente três caras será igual ao número de arranjos diferentes que podem ser formados com três caras e sete coroas. Aqui estão alguns desses arranjos (onde, “H” é cara e “T” é coroa): HHHTTTTTTT, HHTHTTTTTT, HHTTHTTTTTT, TTHTHTHTTT, etc. Cada arranjo é equivalente a uma escolha de onde colocar as 3 caras entre os 10 lançamentos, então há \\(C^{10}_3\\) possibilidades. Logo, a probabilidade de obter exatamente três caras é então\n\\[\np_1 = \\frac{C^{10}_{3}}{2^{10}} \\approx 0,1172 = 11,72\\%\n\\]\nFazendo o cálculo da probabilidade pela linguagem R:\n\n\nMostrar Código\nprint(paste0(format(choose(10, 3) / (2^10), scientific = FALSE), \"%\"))\n\n\n[1] \"0.1171875%\"\n\n\n\nUsando o mesmo raciocínio da parte (a), o número de sequências no espaço amostral que contêm exatamente k caras (k = 0, 1, 2, 3) é \\(C^{10}_k\\). Portanto, a probabilidade de obter três ou menos caras é\n\n\\[\np_2 = \\frac{C^{10}_{0} \\times C^{10}_{1} \\times C^{10}_{2} \\times C^{10}_{3}}{2^{10}} = \\frac{1+10+45+120}{2^{10}} = \\frac{176}{2^{10}} \\approx 0,1719 = 17,19\\%\n\\]\nFazendo o cálculo da probabilidade pela linguagem R:\n\n\nMostrar Código\nprint(paste0(format((choose(10, 0) + choose(10, 1) + choose(10, 2) + choose(10, 3)) / (2^10), scientific = FALSE), \"%\"))\n\n\n[1] \"0.171875%\"\n\n\nExemplo (DeGroot e Schervish (2012)) Suponha que uma turma contenha 15 meninos e 30 meninas, e que 10 alunos sejam selecionados aleatoriamente para uma tarefa especial. Devemos determinar a probabilidade p de que exatamente três meninos sejam selecionados. O número de combinações diferentes dos 45 alunos que podem ser obtidas na amostra de 10 alunos é \\({45 \\choose 10}\\), e a afirmação de que os 10 alunos são selecionados aleatoriamente significa que cada uma dessas \\({45 \\choose 10}\\) combinações possíveis é igualmente provável. Portanto, devemos encontrar o número dessas combinações que contêm exatamente três meninos e sete meninas. Quando uma combinação de três meninos e sete meninas é formada, o número de combinações diferentes nas quais três meninos podem ser selecionados entre os 15 meninos disponíveis é \\({15 \\choose 3}\\), e o número de combinações diferentes nas quais sete meninas podem ser selecionadas entre as 30 meninas disponíveis é \\({30 \\choose 7}\\). Como cada uma dessas combinações de três meninos pode ser pareada com cada uma das combinações de sete meninas para formar uma amostra distinta, o número de combinações contendo exatamente três meninos é \\({15 \\choose 3}\\) \\({30 \\choose 7}\\). Portanto, a probabilidade desejada é\n\\[\np = \\frac{{15 \\choose 3} {30 \\choose 7}}{{45 \\choose 10}} \\approx 0,2904 = 29,04\\%\n\\]\nFazendo o cálculo da probabilidade pela linguagem R:\n\n\nMostrar Código\nprint(paste0(format((choose(15, 3) * choose(30, 7)) / choose(45, 10), scientific = FALSE), \"%\"))\n\n\n[1] \"0.2903557%\"",
    "crumbs": [
      "Conceitos Básicos",
      "Aplicações de Probabilidade em arranjos, permutações e combinações"
    ]
  },
  {
    "objectID": "Int_Prob/3_aplicacoes_probabilidade_combinatoria.html#footnotes",
    "href": "Int_Prob/3_aplicacoes_probabilidade_combinatoria.html#footnotes",
    "title": "Aplicações de Probabilidade em arranjos, permutações e combinações",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nRetirado deste link.↩︎",
    "crumbs": [
      "Probabilidade",
      "Aplicações de Probabilidade em arranjos, permutações e combinações"
    ]
  },
  {
    "objectID": "Int_Prob/6_vetores_aleatorios.html",
    "href": "Int_Prob/6_vetores_aleatorios.html",
    "title": "Vetores Aleatórios",
    "section": "",
    "text": "Definição (Rolla (2021)) Um vetor aleatório \\((X_1, ..., X_p)\\) é uma função \\(X: \\Omega \\rightarrow \\mathbb{R}^p\\) tal que cada coordenada \\(X_i\\) é uma variável aleatória.\nImportante destacar que a notação para vetor aleatório pode variar de acordo com o autor. Podemos encontrar a notação como \\(\\textbf{X}\\) (isto é, em negrito conforme Magalhães (2006)), \\(\\overset{\\sim}{X}\\) ou, ainda, \\(\\underset{\\sim}{X}\\) (James (2023)).\n\n\n\n\n\nDefinição A distribuição de probabilidade do vetor aleatório \\(\\textbf{X} = (X_1, X_2, ..., X_p)\\) é uma tabela que associa a cada valor \\((x_1, x_2, ..., x_p)\\) desse vetor sua correspondente probabilidade \\(P([X_1 = x_1, X_2 = x_2, ..., X_p = x_p])\\). Ela é denominada também distribuição conjunta de \\(X_1, X_2, ..., X_p\\).\nObservemos que a notação \\([X_1 = x_1, X_2 = x_2, ..., X_p = x_p]\\) representa a intersecção dos eventos \\([X_1 = x_1], [X_2 = x_2], ..., [X_p = x_p]\\) ou seja,\n\\[\n\\begin{align*}\n[X_1 = x_1, X_2 = x_2, ..., X_p = x_p] &= \\{ \\omega: X_1(\\omega) = x_1, X_2(\\omega) = x_2, ..., X_p(\\omega) = x_p \\} = \\\\ &= \\{ \\omega: X_1(\\omega) = x_1 \\} \\cap \\{ \\omega: X_2(\\omega) = x_2 \\} \\cap ...  \\cap \\{ \\omega: X_p(\\omega) = x_p \\}\n\\end{align*}\n\\]\nUma notação alternativa para \\(P([X_1 = x_1, X_2 = x_2, ..., X_p = x_p])\\) é \\(P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\\).\nExemplo Lançamento de dois dados honestos. Seja \\(X_1\\) o valor da face do primeiro dado e \\(X_2\\) o valor da face do segundo dado a distribuição conjunta do vetor aleatório \\((X_1, X_2)\\) é dada por\n\n\n\nDistribuição Conjunta de Dois Dados Honestos\n\n\nExemplo Lançamento de um dado e uma moeda, ambos honestos. Seja \\(X\\) o valor da face do primeiro dado e \\(Y\\) a variável aleatória da moeda sendo \\(Y = 1\\) se “cara” e \\(Y = 0\\) se “coroa”. Então, a distribuição conjunta do vetor aleatório \\((X, Y)\\) é dada por\n\n\n\nDistribuição Conjunta de Um Dado e Uma Moeda Honestos\n\n\nDefinição (Dantas (2013)) A função de distribuição do par de variáveis aleatórias discretas \\((X,Y)\\) é dada por:\n\\[\nF(x,y) = P(X \\le x, Y \\le y) = \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i, Y = y_i)\n\\]\nUma notação alternativa para \\(F(x,y)\\) é \\(F_{X,Y}(x,y)\\).\n\n\n\nA distribuição marginal de uma variável aleatória específica é dada ao somarmos as probabilidades “varrendo” todo o intervalo de todas as demais variáveis do vetor aleatório. Por exemplo, assuma que em um vetor aleatório \\((X,Y)\\), \\(X\\) assume os valores \\(x_1, x_2, ..., x_n\\) enquanto \\(Y\\) assume os valores \\(y_1, y_2, ..., y_m\\). Então, a ditribuição marginal de X é dada por\n\\[\nP(X = x_i) = \\sum_{j = 1}^{m} = P(X = x_i, Y = y_j).\n\\]\nAnalogamente, a dstribuição marginal de \\(Y\\) é obtida através de\n\\[\nP(Y = y_j) = \\sum_{i = 1}^{n} = P(X = x_i, Y = y_j).\n\\]\nAbaixo, destacado em vermelho seguem as distribuições marginais do exemplo anterior:\n\n\n\nDistribuição Conjunta de Um Dado e Uma Moeda Honestos com distribuições marginais\n\n\nPara o caso multidimensional (ou seja, \\(p\\)-dimensional), o procedimento é análogo.\nSeja \\(\\textbf{X} = (X_1, X_2, ..., X_p)\\) um vetor aleatório com distribuição conjunta dada por: \\(P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\\), onde \\(x_1, x_2, ..., x_p\\), percorrem o conjunto de valores de \\(X_1, X_2, ..., X_p\\), respectivamente.\nA distribuição marginal de \\(X_1\\) é obtida calculando-se, para cada valor \\(x_1\\) de \\(X_1\\):\n\\[\nP(X_1 = x_1) = \\sum_{x_2} \\dots \\sum_{x_p} P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\n\\]\nAnalogamente, para obter a marginal de qualquer subconjunto de \\((X_1, X_2, ..., X_p)\\), fazemos o somatório percorrendo o subconjunto complementar. Por exemplo, para a marginal de \\((X_1, X_2)\\), tem-se:\n\\[\nP(X_1 = x_1, X_2 = x_2) = \\sum_{x_3} \\sum_{x_4} \\dots \\sum_{x_p} P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\n\\]\n\n\n\nDefinição As variáveis aleatórias \\(X_1, X_2, ..., X_p\\) são ditas independentes se para todos os elementos \\(x_1, x_2, ..., x_p\\) das mesmas tivermos:\n\\[\nP(X_1 = x_1, X_2 = x_2, ..., X_p = x_p) = P(X_1 = x_1)P(X_2 = x_2)...P(X_p = x_p).\n\\]\nOu seja, se as variáveis são independentes, então a distribuição conjunta é o produto das marginais.\nLema As variáveis \\(X\\) e \\(Y\\) com função de distribuição \\(F_{X,Y}(x,y)\\) são independentes se, e somente se\n\\[\nF_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\n\\]\nProva\nIda:\n\\[\n\\begin{align*}\nF_{X,Y}(x,y) &= \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i, Y = y_i) \\overset{\\text{Definição de Indep.}}{=} \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i)P(Y = y_i) \\overset{\\text{Separa Somatórios}}{=} \\\\ &= \\underbrace{\\sum_{i: x_i \\le x}P(X = x_i)}_{F_{X}(x)}  \\underbrace{\\sum_{j: y_j \\le j}P(Y = y_i)}_{F_{Y}(y)} = F_X(x)F_Y(y)\n\\end{align*}\n\\]\nVolta:\n\\[\n\\begin{align*}\nF_X(x)F_Y(y) &= \\sum_{i: x_i \\le x}P(X = x_i) \\sum_{j: y_j \\le j}P(Y = y_i) \\overset{\\text{Combina Somatórios}}{=} \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i)P(Y = y_i) \\overset{\\text{Definição de Indep.}}{=} \\\\ &= \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i, Y = y_i) = F_{X,Y}(x,y)\n\\end{align*}\n\\]\n\\(\\square\\)\n\n\n\nDefinição A distribuição condicional de \\(Y\\) dado \\(X\\) associa a cada valor \\(x\\) de \\(X\\) uma distribuição de probabilidade sobre os valores de \\(Y\\), da seguinte maneira:\n\\[\nP(Y = x | X = x) = \\frac{P(X = x, Y = y)}{P(X = x)}\n\\]\nNote que isso se refere à distribuição condicional de \\(Y\\) dado \\(X\\), estamos nos referindo ao conjunto de todas as distribuições condicionais associadas a cada um dos valores de \\(X\\).\n\n\n\n\n\n\nDefinição Uma função \\(f(x,y)\\) definida para \\(- \\infty &lt; x &lt; + \\infty\\), \\(- \\infty &lt; y &lt; + \\infty\\), não-negativa e satisfazendo a condição\n\\[\n\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}f(x,y)dxdy=1\n\\]\né denominada uma função densidade de probabilidade da variável aleatória bidimensional \\((X,Y)\\) se para todo o subconjunto \\(B\\) de pontos do \\(\\mathbb{R}^2\\) tivermos:\n\\[\nP((X,Y) \\in B) = \\int\\int_{B}f(x,y)dxdy\n\\]\nSegundo Dantas (2013), a interpretação da função densidade de probabilidade no caso bidimensional é a seguinte: seja \\((x,y)\\) um ponto do plano e consideremos um retângulo de lados \\(\\Delta x\\) e \\(\\Delta y\\) construído a partir do ponto \\((x,y)\\). A probabilidade de que \\((X,Y)\\) pertença a esse retângulo é aproximadamente igual ao volume do paralelepípedo de lados \\(\\Delta x\\) e \\(\\Delta y\\) e cuja altura é \\(f(x,y)\\), ou seja,\n\n\n\nConstrução de probabilidade de uma distribuição conjunta bidimensional (Extraído de Dantas (2013))\n\n\nAbaixo, seguem alguns exemplos visuais tridimensionais:\nExemplo Função bidimensional com área destacada entre dois valores de cada variável:\nSuponha a densidade\n\\[\nf(x,y) = 9x^2y^2, \\quad 0 \\le x,y \\le 1,\n\\]\nSuponha o cálculo de probabilidade do tipo:\n\\[\nP(c \\le X \\le d, \\; e \\le Y \\le f) \\;=\\;\n\\int_c^d \\int_e^f 9x^2 y^2 \\, dy \\, dx.\n\\]\nEssa integral tem solução fechada:\n\\[\nP = (d^3 - c^3)\\,(f^3 - e^3).\n\\]\nVamos calcular e ilustrar o valor da probabilidade \\(P(0.2 \\le X \\le 0.6, 0.3 \\le Y \\le 0.8)\\):\n\n\nMostrar Código\n# Distribuição montanhosa f(x,y) = 9x^2 y^2\nif (!requireNamespace(\"plotly\", quietly = TRUE)) install.packages(\"plotly\")\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\n\nlibrary(plotly)\nlibrary(ggplot2)\n\n# --- Intervalos ---\nc1 &lt;- 0.2; d1 &lt;- 0.6   # intervalo para X\ne1 &lt;- 0.3; f1 &lt;- 0.8   # intervalo para Y\n\n# Função densidade\nf_xy &lt;- function(x, y) 9 * x^2 * y^2\n\n# Probabilidade analítica\nprob_interval &lt;- (d1^3 - c1^3) * (f1^3 - e1^3)\ncat(sprintf(\"Probabilidade P(%.2f &lt;= X &lt;= %.2f, %.2f &lt;= Y &lt;= %.2f) = %.4f\\n\",\n            c1, d1, e1, f1, prob_interval))\n\n\nProbabilidade P(0.20 &lt;= X &lt;= 0.60, 0.30 &lt;= Y &lt;= 0.80) = 0.1009\n\n\n\n\nMostrar Código\n# --- Grid para visualização ---\nx_seq &lt;- seq(0, 1, length.out = 80)\ny_seq &lt;- seq(0, 1, length.out = 80)\nZ &lt;- outer(x_seq, y_seq, f_xy)\n\n# Máscara região do intervalo\nmask_region &lt;- outer(x_seq, y_seq, function(x, y) (x &gt;= c1 & x &lt;= d1 & y &gt;= e1 & y &lt;= f1))\n\n# --- Gráfico 3D ---\np3d &lt;- plot_ly(showscale = FALSE) %&gt;%\n  add_surface(x = x_seq, y = y_seq, z = Z,\n              opacity = 0.6, name = \"densidade\") %&gt;%\n  add_surface(x = x_seq, y = y_seq,\n              z = ifelse(mask_region, Z, NA),\n              opacity = 1.0, name = \"região do intervalo\") %&gt;%\n  layout(title = \"Distribuição f(x,y) = 9x²y² com intervalo destacado\",\n         scene = list(xaxis = list(title = \"X\"),\n                      yaxis = list(title = \"Y\"),\n                      zaxis = list(title = \"densidade\")))\n\np3d\n\n\n\n\n\n\nExemplo Normal Bivariada\n\n\nMostrar Código\n# --- Dependências (instalar se não estiverem disponíveis) ---\npacotes &lt;- c(\"mvtnorm\", \"plotly\")\nnao_instalados &lt;- pacotes[!pacotes %in% installed.packages()[, \"Package\"]]\nif(length(nao_instalados)) install.packages(nao_instalados, repos = \"https://cloud.r-project.org\")\n\nlibrary(mvtnorm)  # para dmvnorm\nlibrary(plotly)   # para superfície 3D interativa\n\n# --- Parâmetros da normal bivariada ---\nmu &lt;- c(0, 0)                         # vetor de médias\nSigma &lt;- matrix(c(1.0, 0.6,           # matriz de covariância com correlação\n                  0.6, 1.0), ncol=2)\n\n# --- Grade onde avaliamos a densidade ---\nx_seq &lt;- seq(-3, 3, length.out = 121)\ny_seq &lt;- seq(-3, 3, length.out = 121)\ngrade &lt;- expand.grid(x = x_seq, y = y_seq)\n\n# Avaliar densidade bivariada na grade\ndens &lt;- dmvnorm(grade, mean = mu, sigma = Sigma)\nz_mat &lt;- matrix(dens, nrow = length(x_seq), ncol = length(y_seq))\n\n# --- Superfície 3D interativa com plotly ---\np &lt;- plot_ly(x = x_seq, y = y_seq, z = ~z_mat, showscale = TRUE) %&gt;%\n  add_surface() %&gt;%\n  layout(title = \"Densidade Normal Bivariada (interativa)\",\n         scene = list(\n           xaxis = list(title = \"X1\"),\n           yaxis = list(title = \"X2\"),\n           zaxis = list(title = \"Densidade\")\n         ))\n# Aparece no Viewer do RStudio ou no navegador\np\n\n\n\n\n\n\nDefinição (Dantas (2013)) A função de distribuição de uma variável aleatória bidimensional \\((X,Y)\\) é dada por:\n\\[\nF(x,y) = P(X \\le x, Y \\le y), \\quad x \\in \\mathbb{R}, y \\in \\mathbb{R}\n\\]\nUma notação alternativa para \\(F(x,y)\\) é \\(F_{X,Y}(x,y)\\).\nNo caso de variáveis aleatórias contínuas \\(X\\) e \\(Y\\), a probabilidade do evento \\([X \\le x, Y \\le, y]\\) é igual ao valor da integral da densidade conjunta de \\((X, Y)\\) no conjunto \\(B = [X \\le x, Y \\le, y]\\)\n\\[\nF(x,y) = \\int_{-\\infty}^{x}\\int_{-\\infty}^{y} f(u,v) dudv\n\\]\nOu com uma notação alternativa:\n\\[\nF_{X,Y}(x,y) = \\int_{-\\infty}^{x}\\int_{-\\infty}^{y} f_{X,Y}(u,v) dudv\n\\]\n\n\n\nDada a densidade conjunta das variáveis \\(X\\) e \\(Y\\), podemos determinar as densidades de \\(X\\) e de \\(Y\\) isoladamente. Essas densidades são chamadas de densidades marginais \\(f_X(x)\\) e \\(f_Y(x)\\), respectivamente. Elas são obtidas através da seguinte maneira:\n\\[\n\\begin{align*}\nf_X(x) = \\int_{-\\infty}^{+\\infty} f(x,y) dy \\\\\nf_Y(y) = \\int_{-\\infty}^{+\\infty} f(x,y) dx\n\\end{align*}\n\\]\nPara o caso multivariado, por exemplo para o vetor aleatório \\((X_1, X_2, ..., X_p)\\) para obter uma marginal em específico, por exemplo, \\(X_1\\) integramos em relação à todas às demais, isto é:\n\\[\nf_{X_1}(x_1) = \\overbrace{\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty} ... \\int_{-\\infty}^{+\\infty}}^{\\text{p-1 integrais}} f(x_1, x_2, ..., x_p) dx_2dx_3...dx_p\n\\]\n\n\n\nDefinição As variáveis aleatórias \\(X\\) e \\(Y\\), cuja densidade conjunta é \\(f(x,y)\\), para \\(x,y \\in \\mathbb{R}\\), e cujas densidades marginais são denotadas \\(f_X(x)\\) e \\(f_Y(y)\\), são ditas independentes se para todo o par de valores \\((x,y)\\) tivermos\n\\[\nf(x,y) = f_X(x)f_Y(y)\n\\]\nE no caso \\(p\\)-dimensional:\n\\[\nf_{\\textbf{X}}(x_1,x_2, ..., x_p) = f_{X_1}(x_1)f_{X_2}(x_2)...f_{X_p}(x_p)\n\\]\nOu seja, se as variáveis são independentes, então a distribuição conjunta é o produto das marginais.\nLema Analogamente ao caso discreto, as variáveis \\(X\\) e \\(Y\\) com função de distribuição \\(F_{X,Y}(x,y)\\) são independentes se, e somente se\n\\[\nF_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\n\\]\nProva Ver Seção 6.3 de Magalhães (2006).\n\\(\\square\\)\n\n\n\nDefinição A distribuição condicional de \\(Y\\) dado \\(X\\) associa a cada valor \\(x\\) de \\(X\\) uma distribuição de probabilidade sobre os valores de \\(Y\\), da seguinte maneira:\n\\[\nf_{Y|X}(y|x) = \\frac{f_{X,Y}(x,y)}{f_X(x)}\n\\]\nNote que isso se refere à distribuição condicional de \\(Y\\) dado \\(X\\), estamos nos referindo ao conjunto de todas as distribuições condicionais associadas a cada um dos valores de \\(X\\).",
    "crumbs": [
      "Variáveis Aleatórias",
      "Vetores Aleatórios"
    ]
  },
  {
    "objectID": "Int_Prob/6_vetores_aleatorios.html#vetores-aleatórios-discretos",
    "href": "Int_Prob/6_vetores_aleatorios.html#vetores-aleatórios-discretos",
    "title": "Vetores Aleatórios",
    "section": "",
    "text": "Definição A distribuição de probabilidade do vetor aleatório \\(\\textbf{X} = (X_1, X_2, ..., X_p)\\) é uma tabela que associa a cada valor \\((x_1, x_2, ..., x_p)\\) desse vetor sua correspondente probabilidade \\(P([X_1 = x_1, X_2 = x_2, ..., X_p = x_p])\\). Ela é denominada também distribuição conjunta de \\(X_1, X_2, ..., X_p\\).\nObservemos que a notação \\([X_1 = x_1, X_2 = x_2, ..., X_p = x_p]\\) representa a intersecção dos eventos \\([X_1 = x_1], [X_2 = x_2], ..., [X_p = x_p]\\) ou seja,\n\\[\n\\begin{align*}\n[X_1 = x_1, X_2 = x_2, ..., X_p = x_p] &= \\{ \\omega: X_1(\\omega) = x_1, X_2(\\omega) = x_2, ..., X_p(\\omega) = x_p \\} = \\\\ &= \\{ \\omega: X_1(\\omega) = x_1 \\} \\cap \\{ \\omega: X_2(\\omega) = x_2 \\} \\cap ...  \\cap \\{ \\omega: X_p(\\omega) = x_p \\}\n\\end{align*}\n\\]\nUma notação alternativa para \\(P([X_1 = x_1, X_2 = x_2, ..., X_p = x_p])\\) é \\(P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\\).\nExemplo Lançamento de dois dados honestos. Seja \\(X_1\\) o valor da face do primeiro dado e \\(X_2\\) o valor da face do segundo dado a distribuição conjunta do vetor aleatório \\((X_1, X_2)\\) é dada por\n\n\n\nDistribuição Conjunta de Dois Dados Honestos\n\n\nExemplo Lançamento de um dado e uma moeda, ambos honestos. Seja \\(X\\) o valor da face do primeiro dado e \\(Y\\) a variável aleatória da moeda sendo \\(Y = 1\\) se “cara” e \\(Y = 0\\) se “coroa”. Então, a distribuição conjunta do vetor aleatório \\((X, Y)\\) é dada por\n\n\n\nDistribuição Conjunta de Um Dado e Uma Moeda Honestos\n\n\nDefinição (Dantas (2013)) A função de distribuição do par de variáveis aleatórias discretas \\((X,Y)\\) é dada por:\n\\[\nF(x,y) = P(X \\le x, Y \\le y) = \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i, Y = y_i)\n\\]\nUma notação alternativa para \\(F(x,y)\\) é \\(F_{X,Y}(x,y)\\).\n\n\n\nA distribuição marginal de uma variável aleatória específica é dada ao somarmos as probabilidades “varrendo” todo o intervalo de todas as demais variáveis do vetor aleatório. Por exemplo, assuma que em um vetor aleatório \\((X,Y)\\), \\(X\\) assume os valores \\(x_1, x_2, ..., x_n\\) enquanto \\(Y\\) assume os valores \\(y_1, y_2, ..., y_m\\). Então, a ditribuição marginal de X é dada por\n\\[\nP(X = x_i) = \\sum_{j = 1}^{m} = P(X = x_i, Y = y_j).\n\\]\nAnalogamente, a dstribuição marginal de \\(Y\\) é obtida através de\n\\[\nP(Y = y_j) = \\sum_{i = 1}^{n} = P(X = x_i, Y = y_j).\n\\]\nAbaixo, destacado em vermelho seguem as distribuições marginais do exemplo anterior:\n\n\n\nDistribuição Conjunta de Um Dado e Uma Moeda Honestos com distribuições marginais\n\n\nPara o caso multidimensional (ou seja, \\(p\\)-dimensional), o procedimento é análogo.\nSeja \\(\\textbf{X} = (X_1, X_2, ..., X_p)\\) um vetor aleatório com distribuição conjunta dada por: \\(P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\\), onde \\(x_1, x_2, ..., x_p\\), percorrem o conjunto de valores de \\(X_1, X_2, ..., X_p\\), respectivamente.\nA distribuição marginal de \\(X_1\\) é obtida calculando-se, para cada valor \\(x_1\\) de \\(X_1\\):\n\\[\nP(X_1 = x_1) = \\sum_{x_2} \\dots \\sum_{x_p} P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\n\\]\nAnalogamente, para obter a marginal de qualquer subconjunto de \\((X_1, X_2, ..., X_p)\\), fazemos o somatório percorrendo o subconjunto complementar. Por exemplo, para a marginal de \\((X_1, X_2)\\), tem-se:\n\\[\nP(X_1 = x_1, X_2 = x_2) = \\sum_{x_3} \\sum_{x_4} \\dots \\sum_{x_p} P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\n\\]\n\n\n\nDefinição As variáveis aleatórias \\(X_1, X_2, ..., X_p\\) são ditas independentes se para todos os elementos \\(x_1, x_2, ..., x_p\\) das mesmas tivermos:\n\\[\nP(X_1 = x_1, X_2 = x_2, ..., X_p = x_p) = P(X_1 = x_1)P(X_2 = x_2)...P(X_p = x_p).\n\\]\nOu seja, se as variáveis são independentes, então a distribuição conjunta é o produto das marginais.\nLema As variáveis \\(X\\) e \\(Y\\) com função de distribuição \\(F_{X,Y}(x,y)\\) são independentes se, e somente se\n\\[\nF_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\n\\]\nProva\nIda:\n\\[\n\\begin{align*}\nF_{X,Y}(x,y) &= \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i, Y = y_i) \\overset{\\text{Definição de Indep.}}{=} \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i)P(Y = y_i) \\overset{\\text{Separa Somatórios}}{=} \\\\ &= \\underbrace{\\sum_{i: x_i \\le x}P(X = x_i)}_{F_{X}(x)}  \\underbrace{\\sum_{j: y_j \\le j}P(Y = y_i)}_{F_{Y}(y)} = F_X(x)F_Y(y)\n\\end{align*}\n\\]\nVolta:\n\\[\n\\begin{align*}\nF_X(x)F_Y(y) &= \\sum_{i: x_i \\le x}P(X = x_i) \\sum_{j: y_j \\le j}P(Y = y_i) \\overset{\\text{Combina Somatórios}}{=} \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i)P(Y = y_i) \\overset{\\text{Definição de Indep.}}{=} \\\\ &= \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i, Y = y_i) = F_{X,Y}(x,y)\n\\end{align*}\n\\]\n\\(\\square\\)\n\n\n\nDefinição A distribuição condicional de \\(Y\\) dado \\(X\\) associa a cada valor \\(x\\) de \\(X\\) uma distribuição de probabilidade sobre os valores de \\(Y\\), da seguinte maneira:\n\\[\nP(Y = x | X = x) = \\frac{P(X = x, Y = y)}{P(X = x)}\n\\]\nNote que isso se refere à distribuição condicional de \\(Y\\) dado \\(X\\), estamos nos referindo ao conjunto de todas as distribuições condicionais associadas a cada um dos valores de \\(X\\).",
    "crumbs": [
      "Variáveis Aleatórias",
      "Vetores Aleatórios"
    ]
  },
  {
    "objectID": "Int_Prob/5_variaveis_aleatorias_conceitos_basicos.html",
    "href": "Int_Prob/5_variaveis_aleatorias_conceitos_basicos.html",
    "title": "Conceitos Básicos",
    "section": "",
    "text": "Informalmente, uma variável aleatória (V.A.) é um valor numérico do resultado de um experimento aleatório. Formalmente, abaixo segue a definição (Magalhães (2006), James (2023)):\nDefinição Seja \\((\\Omega, \\mathcal{F}, \\mathcal{P})\\) um espaço de probabilidade. Denominamos de variável aleatória, qualquer função \\(X : \\Omega \\rightarrow \\mathbb{R}\\) tal que \\([X \\le x]\\) é evento aleatório para todo \\(x \\in \\mathbb{R}\\); isto é, \\([X \\le x] \\in \\mathcal{F}, \\forall x \\in \\mathbb{R}\\)1.\nExemplo (Mood, Graybill, e Boes (1974)) Assuma um experimento de lançar uma moeda honesta para cima. Defina a variável aleatória \\(X\\) assumir o valor \\(1\\) quando sair cara, e o valor \\(0\\) quando sair coroa. Ou seja:\n\\[\n\\begin{align*}\n\\Omega &= \\{cara, coroa\\} \\\\\nX &=\n\\begin{cases}\n  1, & \\text{ se $\\omega$ = \\{cara\\},} \\\\\n  0, & \\text{ se $\\omega$ = \\{coroa\\}}\n\\end{cases}\n\\end{align*}\n\\]\nFormalmente, precisamos mostrar que esta construção deste experimento \\(X\\) mostrando que \\(\\{\\omega: X(\\omega) \\le x\\}\\) para todo \\(x \\in \\mathbb{R}\\) pertence à \\(\\mathcal{F}\\). Primeiramente, note que \\(\\mathcal{F}\\) é composto por quatro elementos sendo \\(\\{\\emptyset, \\Omega, \\{cara\\},\\{coroa\\}\\}\\). Agora, verificamos que se \\(x &lt; 0\\), \\(\\{\\omega: X(\\omega) \\le x\\} = \\emptyset\\); e se \\(0 \\le x &lt; 0\\), \\(\\{\\omega: X(\\omega) \\le x\\} = \\{cara\\}\\); e se \\(x \\ge 1\\), \\(\\{\\omega: X(\\omega) \\le x\\} = \\Omega = \\{cara, coroa\\}\\). Então, pra cada \\(x\\) real o evento \\(\\{\\omega: X(\\omega) \\le x\\}\\) pertence à \\(\\sigma\\)-álgebra \\(\\mathcal{F}\\) e, portanto, \\(X\\) é variável aleatória.\nExemplo (Mood, Graybill, e Boes (1974)) Assuma um experimento de lançar dois dados honestos de seis lados, sendo o dado \\(i\\) e o dado \\(j\\). Defina a variável aleatória \\(X\\) assumir o valor da soma das suas faces, ou seja, \\(X(\\omega) = i+j\\), onde \\(\\Omega = \\{(i,j): i,j = 1, 2,...,6\\}\\)\nDefinição Função de Distribuição Acumulada (FDA) A FDA de uma V.A. \\(X\\) aplicada no ponto \\(x\\) denotada por \\(F_X(x)\\), é uma função com domínio nos números reais e imagem (contra domínio) no intervalo \\([0,1]\\) que satisfaz \\(F_X(x) = P(X \\le x), \\forall x \\in \\mathbb{R}\\).\nA FDA é unicamente definida para cada variável aleatória. Ou seja, uma variável aleatória \\(X\\) possui uma única respectiva função \\(F_X(.)\\).\nPara qualquer FDA de uma V.A. \\(X\\), tem-se as seguintes propriedades:\n\n\\(0 \\le F_X(x) \\le 1\\)\n\\(F_X(x)\\) é não decrescente. Isto é, se \\(x_1 \\le x_2 \\implies F_X(x_1) \\le F_X(x_2)\\)\n\\(F_X(-\\infty) = \\lim\\limits_{n \\to -\\infty}F_X(x) = 0\\)\n\\(F_X(+\\infty) = \\lim\\limits_{n \\to +\\infty}F_X(x) = 1\\)\n\nUm ponto interessante é que a definição de uma FDA poderia ser dada simplesmente por essas propriedades. Isto é, qualquer função \\(F(.)\\) que respeite as propriedades acima será FDA de alguma variável aleatória existente (mesmo sem mencioná-la!).",
    "crumbs": [
      "Variáveis Aleatórias",
      "Conceitos Básicos"
    ]
  },
  {
    "objectID": "Int_Prob/5_variaveis_aleatorias_conceitos_basicos.html#variáveis-aleatórias-discretas",
    "href": "Int_Prob/5_variaveis_aleatorias_conceitos_basicos.html#variáveis-aleatórias-discretas",
    "title": "Conceitos Básicos",
    "section": "Variáveis Aleatórias Discretas",
    "text": "Variáveis Aleatórias Discretas\nDefinição Se os valores considerados de \\(X\\) são contáveis, então \\(X\\) é considerado discreto.\nNote que se \\(X\\) é contável assumindo, por exemplo, valores \\(x_1, x_2, ..., x_n, ...\\), então \\(\\Omega = \\bigcup\\limits_{i=1}^{\\infty} \\{X = x_n\\}\\), mas como os \\(x_i\\)’s podem ser vistos como eventos disjuntos, isto é, \\(\\{X = x_i\\} \\cap \\{X = x_j\\} = \\emptyset, \\forall i \\ne j\\); então, \\(1 = P(\\Omega) = \\sum\\limits_{i=1}^{\\infty}P(X = x_i)\\) pelo terceiro axioma de Kolmogorov.\nA função densidade de probabilidade, \\(f_X(.)\\) é definida como sendo\n\\[\n\\begin{align*}\nf_X(x) &=\n\\begin{cases}\n  P(X = x_i), & \\text{se}\\ x=x_i,\\ i = 1, 2, ...  \\\\\n  0, & \\text{caso contrário}\n\\end{cases}\n\\end{align*}\n\\]\nA função densidade de probabilidade de uma VA discreta também pode ser chamada de função massa de probabilidade.\nExemplo Função de densidade do lançamento de um dado honesto sendo \\(X\\) definido como sendo o valor da face.\n\n\nMostrar Código\n# Carregar o pacote ggplot2\nlibrary(ggplot2)\n\n# Dados: resultados do dado e suas probabilidades\ndados &lt;- data.frame(\n  face = 1:6,\n  probabilidade = rep(1/6, 6),\n  fracoes = '1/6'\n)\n\n# Criar o gráfico de barras\nggplot(dados, aes(x = factor(face), y = probabilidade)) +\n  geom_bar(stat = \"identity\", fill = \"#2780e3\") +\n  geom_text(aes(label = fracoes), vjust = -0.5, size = 4) +\n  labs(title = \"Função Massa de Probabilidade de um Dado Honesto\",\n       x = \"Face do Dado\",\n       y = \"Probabilidade\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nObserve que, neste caso, a FDA pode ser visualizada abaixo:\n\n\nMostrar Código\n# Código inspirado em https://stackoverflow.com/questions/52236576/r-ggplot-make-geom-step-jumps-dashed\n\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\ndados &lt;- tibble::tibble(\n  x = 0:6,\n  probabilidade = c(0, rep(1/6, 6)),\n  fda = cumsum(probabilidade))\n\ndados_grafico &lt;- dados %&gt;%\n  mutate(tipo = \"fda\") %&gt;%\n  bind_rows(dados %&gt;%\n              mutate(tipo = \"previa_fda\",\n                     fda = lag(fda))) %&gt;%\n  tidyr::drop_na() %&gt;%\n  arrange(x, desc(tipo))\n\nggplot(dados_grafico) + \n  geom_segment(aes(x = lag(x), y = lag(fda), xend = x, yend = fda, lty = tipo)) +\n  geom_point(data = slice(dados_grafico, -1), aes(x, fda, fill = tipo), shape = 21) + # Retira ponto mais extremo para ilustrar o -infinito\n  scale_fill_manual(values = c(\"black\", \"white\")) +\n  scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n  labs(title = \"FDA teórica de um dado honesto (6 faces)\",\n       x = \"Face x\",\n       y = \"P(X ≤ x)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  geom_segment(aes(x = 6, y = 1, xend = 7, yend = 1)) # Segmento mais extremo para ilustrar o +infinito\n\n\n\n\n\n\n\n\n\nExemplo Função de densidade do lançamento de dois dados honestos sendo \\(X\\) definido como sendo o valor da soma das duas faces.\n\n\nMostrar Código\nlibrary(ggplot2)\nlibrary(MASS)\n\n# Cria uma função que calcula P(X = x_i) onde x_i é a soma das duas faces\ncalcula_prob_soma &lt;- function(soma) {\n  # Contar combinações possíveis que resultam na soma\n  combinacoes &lt;- expand.grid(dado1=1:6, dado2=1:6)\n  total &lt;- nrow(combinacoes)\n  resultados_validos &lt;- sum(rowSums(combinacoes) == soma)\n  prob &lt;- resultados_validos / total\n  return(prob)\n}\n\n# Aplica a função acima para todo o espaço amostral Omega\nsomas &lt;- 2:12\nprobabilidades &lt;- sapply(somas, calcula_prob_soma)\n\n# Convertendo para frações em formato string\nfracoes_str &lt;- sapply(probabilidades, function(p) as.character(fractions(p)))\n\n# Criar data frame\ndados_somas &lt;- data.frame(\n  soma = somas,\n  probabilidade = probabilidades,\n  fracoes = fracoes_str\n)\n\n# Plotagem\nggplot(dados_somas, aes(x = factor(soma), y = probabilidade)) +\n  geom_bar(stat = \"identity\", fill = \"#2780e3\") +\n  geom_text(aes(label = fracoes), vjust = -0.5, size = 4) +\n  labs(title = \"Função Massa de Probabilidade da Soma de Dois Dados\",\n       x = \"Soma dos Dados\",\n       y = \"Probabilidade\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nObserve que, neste caso, a FDA pode ser visualizada abaixo:\n\n\nMostrar Código\n# Cria uma função que calcula P(X = x_i) onde x_i é a soma das duas faces\ncalcula_prob_soma &lt;- function(soma) {\n  # Contar combinações possíveis que resultam na soma\n  combinacoes &lt;- expand.grid(dado1=1:6, dado2=1:6)\n  total &lt;- nrow(combinacoes)\n  resultados_validos &lt;- sum(rowSums(combinacoes) == soma)\n  prob &lt;- resultados_validos / total\n  return(prob)\n}\n\n# Aplica a função acima para todo o espaço amostral Omega\nsomas &lt;- 0:12\nprobabilidades &lt;- sapply(somas, calcula_prob_soma)\n\n# Criar data frame\ndados_somas &lt;- tibble::tibble(\n  soma = somas,\n  probabilidade = probabilidades,\n  fda = cumsum(probabilidade)\n) %&gt;%\n  distinct(fda, .keep_all = T) # Evita segmentos redundantes\n\ndados_grafico &lt;- dados_somas %&gt;%\n  mutate(tipo = \"fda\") %&gt;%\n  bind_rows(dados_somas %&gt;%\n              mutate(tipo = \"previa_fda\",\n                     fda = lag(fda))) %&gt;%\n  tidyr::drop_na() %&gt;%\n  rename(x = soma) %&gt;%\n  arrange(x, desc(tipo))\n\nggplot(dados_grafico) + \n  geom_segment(aes(x = lag(x), y = lag(fda), xend = x, yend = fda, lty = tipo)) +\n  geom_point(data = slice(dados_grafico, -1), aes(x, fda, fill = tipo), shape = 21) + # Retira ponto mais extremo para ilustrar o -infinito\n  scale_fill_manual(values = c(\"black\", \"white\")) +\n  scale_linetype_manual(values = c(\"dashed\", \"solid\")) +\n  labs(title = \"FDA teórica da soma de dois dados honestos\",\n       x = \"Soma das Faces\",\n       y = \"P(X ≤ x)\") +\n  theme_minimal() +\n  theme(legend.position = \"none\") +\n  scale_x_continuous(breaks = 0:13, limits = c(0, 13)) +\n  geom_segment(aes(x = 12, y = 1, xend = 13, yend = 1)) # Segmento mais extremo para ilustrar o +infinito",
    "crumbs": [
      "Variáveis Aleatórias",
      "Conceitos Básicos"
    ]
  },
  {
    "objectID": "Int_Prob/5_variaveis_aleatorias_conceitos_basicos.html#variáveis-aleatórias-contínuas",
    "href": "Int_Prob/5_variaveis_aleatorias_conceitos_basicos.html#variáveis-aleatórias-contínuas",
    "title": "Conceitos Básicos",
    "section": "Variáveis Aleatórias Contínuas",
    "text": "Variáveis Aleatórias Contínuas\nDefinição Uma variável aleatória \\(X\\) é dita contínua se existe uma função \\(f_X(.)\\) tal que \\(F_X(x) = \\int_\\limits{-\\infty}^{x}f_{X}(u)d(u), \\forall x \\in \\mathbb{R}\\). Se \\(X\\) é contíuna, então a função \\(f_X(x)\\) é chamada de função densidade de probabilidade de \\(X\\) aplicada no ponto \\(x\\).\nPara qualquer função densidade de uma V.A. \\(X\\), contínua tem-se as seguintes propriedades:\n\n\\(f_X(x) \\ge 0, \\forall x \\in \\mathbb{R}\\)\n\\(\\int\\limits_{-\\infty}^{+\\infty}f(x)dx = 1\\).\n\nUm ponto interessante é que a definição de uma função de densidade poderia ser dada simplesmente por essas propriedades. Isto é, qualquer função \\(f(.)\\) que respeite as propriedades acima será função de densidade de probabilidade de alguma variável aleatória existente (mesmo sem mencioná-la!).\nPara obter a probabilidade de uma variável aleatória \\(X\\) estar entre dois valores \\(a,b \\in \\mathbb{R}, a &lt; b\\), podemos usar as definições usuais de cálculo integral. Isto é:\n\\(P(a &lt; X &lt; b) = \\int\\limits_{a}^{b}f(x)dx = F_X(b) - F_X(a)\\)\nAlém disso, \\(P(X = a) = 0, \\forall a \\in \\mathbb{R}\\).\nObserve que para variáveis aleatórias contínuas nos pontos \\(a\\) e \\(b\\), o valor da probabilidade não se altera se incluímos ou excluímos na desiguldade os valores. Isto é:\n\\[\nP(a &lt; X &lt; b) = P(a \\le X &lt; b) = P(a &lt; X \\le b) = P(a \\le X \\le b)\n\\]\nExemplo (Mood, Graybill, e Boes (1974)) Seja \\(X\\) uma variável aleatória representando o tempo de uma conversa de telefone. Assuma que a FDA de \\(X\\) é dada por \\(F_X(x) = \\left( 1 - e^{-\\lambda x} \\right), x \\ge 0\\) e assuma também que \\(\\lambda &gt; 0\\). A função densidade de probabilidade correspondente é dada por \\(f_X(x) = \\lambda e^{-\\lambda x}, x \\ge 0\\). Assuma que a função é dada em medidas de minutos. Então, assumindo \\(\\lambda = \\frac{1}{5}\\), qual a probabilidade de uma ligação durar entre 5 e 10 minutos?\nEssa resposta pode ser dada pela função densidade:\n\\[\nP(5 &lt; X &lt; 10) = \\int\\limits_{5}^{10}\\lambda e^{-\\lambda x} dx = e^{-5\\lambda}-e^{-10\\lambda} = e^{-1}-e^{-2} \\approx 0.23\n\\]\nOu também pela função de distribuição acumulada:\n\\[\nP(5 &lt; X &lt; 10) = P(X &lt; 10) - P(X &lt; 5) = F_X(10) - F_X(5) = (1- e^{-\\lambda 10}) -  (1- e^{-\\lambda 5}) = e^{-1} - e^{-2}  \\approx 0.23\n\\]\nAbaixo podemos ver a representação gráfica do valor dessa probabilidade:\n\n\nMostrar Código\nlibrary(ggplot2)\n\nvalor_lambda &lt;- 1 / 5\nlower_bound &lt;- 5\nupper_bound &lt;- 10\n\n# Obs: a função interna do R possui a mesma parametrização de Mood e Graybill\n# De qualquer forma, poderíamos criar a nossa própria versão da exponencial como por exemplo:\n# dexp_2 &lt;- function(x, lambda) {ifelse(x &gt;= 0, lambda * exp(-lambda * x), 0)}\n\nx_values &lt;- seq(0, 12, by = 0.01) # Ajustar à gosto\nexp_data &lt;- data.frame(x = x_values, y = dexp(x_values, rate = valor_lambda))\n\nshaded_area_data &lt;- subset(exp_data, x &gt;= lower_bound & x &lt;= upper_bound)\nshaded_area_data &lt;- rbind(c(lower_bound, 0), shaded_area_data, c(upper_bound, 0))\n\nggplot(exp_data, aes(x = x, y = y)) +\n  geom_line(color = \"blue\") + # Densidade de Probabilidade\n  geom_polygon(data = shaded_area_data, aes(x = x, y = y), fill = \"red\", alpha = 0.5) + # Área Hachurada\n  labs(title = substitute(paste(\"Função Densidade de Probabilidade (\",lambda,\" = \", x , \")\"), list(x = valor_lambda)), # Não pode ser paste0\n       x = \"x\",\n       y = \"Valor da Densidade f(x)\") +\n  ylim(c(0,1)) +\n  theme_minimal()",
    "crumbs": [
      "Variáveis Aleatórias",
      "Conceitos Básicos"
    ]
  },
  {
    "objectID": "Int_Prob/5_variaveis_aleatorias_conceitos_basicos.html#footnotes",
    "href": "Int_Prob/5_variaveis_aleatorias_conceitos_basicos.html#footnotes",
    "title": "Conceitos Básicos",
    "section": "Notas de rodapé",
    "text": "Notas de rodapé\n\n\nEsta definição formal matemática, na sua integridade, pode parece difícil de assimilar num primeiro momento. Em linhas gerais, uma variável aleatória deve ser uma função mensurável dentro da sua \\(\\sigma\\)-álgebra do espaço de probabildade. Por exemplo, é possível definir uma \\(\\sigma\\)-álgebra de maneira incoveniente e fazer com que algumas variáveis aleatórias não se encaixem como função mensurável por ter que depender de eventos aleatórios que não estejam presentes em \\(\\mathcal{F}\\). Nesse sentido, o cojunto das partes e a \\(\\sigma\\)-álgebra de Borel são as preferidas, justamente por permitirem que praticamente todas as variáveis de interesse sejam mensuráveis. Para maiores detalhes, ver o exemplo 2.1 de Magalhães (2006) e as observações da Seção 2.1 de James (2023).↩︎",
    "crumbs": [
      "Variáveis Aleatórias",
      "Conceitos Básicos"
    ]
  },
  {
    "objectID": "Int_Prob/6_vetores_aleatorios.html#vetores-aleatórios-contínuos",
    "href": "Int_Prob/6_vetores_aleatorios.html#vetores-aleatórios-contínuos",
    "title": "Vetores Aleatórios",
    "section": "",
    "text": "Definição Uma função \\(f(x,y)\\) definida para \\(- \\infty &lt; x &lt; + \\infty\\), \\(- \\infty &lt; y &lt; + \\infty\\), não-negativa e satisfazendo a condição\n\\[\n\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}f(x,y)dxdy=1\n\\]\né denominada uma função densidade de probabilidade da variável aleatória bidimensional \\((X,Y)\\) se para todo o subconjunto \\(B\\) de pontos do \\(\\mathbb{R}^2\\) tivermos:\n\\[\nP((X,Y) \\in B) = \\int\\int_{B}f(x,y)dxdy\n\\]\nSegundo Dantas (2013), a interpretação da função densidade de probabilidade no caso bidimensional é a seguinte: seja \\((x,y)\\) um ponto do plano e consideremos um retângulo de lados \\(\\Delta x\\) e \\(\\Delta y\\) construído a partir do ponto \\((x,y)\\). A probabilidade de que \\((X,Y)\\) pertença a esse retângulo é aproximadamente igual ao volume do paralelepípedo de lados \\(\\Delta x\\) e \\(\\Delta y\\) e cuja altura é \\(f(x,y)\\), ou seja,\n\n\n\nConstrução de probabilidade de uma distribuição conjunta bidimensional (Extraído de Dantas (2013))\n\n\nAbaixo, seguem alguns exemplos visuais tridimensionais:\nExemplo Função bidimensional com área destacada entre dois valores de cada variável:\nSuponha a densidade\n\\[\nf(x,y) = 9x^2y^2, \\quad 0 \\le x,y \\le 1,\n\\]\nSuponha o cálculo de probabilidade do tipo:\n\\[\nP(c \\le X \\le d, \\; e \\le Y \\le f) \\;=\\;\n\\int_c^d \\int_e^f 9x^2 y^2 \\, dy \\, dx.\n\\]\nEssa integral tem solução fechada:\n\\[\nP = (d^3 - c^3)\\,(f^3 - e^3).\n\\]\nVamos calcular e ilustrar o valor da probabilidade \\(P(0.2 \\le X \\le 0.6, 0.3 \\le Y \\le 0.8)\\):\n\n\nMostrar Código\n# Distribuição montanhosa f(x,y) = 9x^2 y^2\nif (!requireNamespace(\"plotly\", quietly = TRUE)) install.packages(\"plotly\")\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\n\nlibrary(plotly)\nlibrary(ggplot2)\n\n# --- Intervalos ---\nc1 &lt;- 0.2; d1 &lt;- 0.6   # intervalo para X\ne1 &lt;- 0.3; f1 &lt;- 0.8   # intervalo para Y\n\n# Função densidade\nf_xy &lt;- function(x, y) 9 * x^2 * y^2\n\n# Probabilidade analítica\nprob_interval &lt;- (d1^3 - c1^3) * (f1^3 - e1^3)\ncat(sprintf(\"Probabilidade P(%.2f &lt;= X &lt;= %.2f, %.2f &lt;= Y &lt;= %.2f) = %.4f\\n\",\n            c1, d1, e1, f1, prob_interval))\n\n\nProbabilidade P(0.20 &lt;= X &lt;= 0.60, 0.30 &lt;= Y &lt;= 0.80) = 0.1009\n\n\n\n\nMostrar Código\n# --- Grid para visualização ---\nx_seq &lt;- seq(0, 1, length.out = 80)\ny_seq &lt;- seq(0, 1, length.out = 80)\nZ &lt;- outer(x_seq, y_seq, f_xy)\n\n# Máscara região do intervalo\nmask_region &lt;- outer(x_seq, y_seq, function(x, y) (x &gt;= c1 & x &lt;= d1 & y &gt;= e1 & y &lt;= f1))\n\n# --- Gráfico 3D ---\np3d &lt;- plot_ly(showscale = FALSE) %&gt;%\n  add_surface(x = x_seq, y = y_seq, z = Z,\n              opacity = 0.6, name = \"densidade\") %&gt;%\n  add_surface(x = x_seq, y = y_seq,\n              z = ifelse(mask_region, Z, NA),\n              opacity = 1.0, name = \"região do intervalo\") %&gt;%\n  layout(title = \"Distribuição f(x,y) = 9x²y² com intervalo destacado\",\n         scene = list(xaxis = list(title = \"X\"),\n                      yaxis = list(title = \"Y\"),\n                      zaxis = list(title = \"densidade\")))\n\np3d\n\n\n\n\n\n\nExemplo Normal Bivariada\n\n\nMostrar Código\n# --- Dependências (instalar se não estiverem disponíveis) ---\npacotes &lt;- c(\"mvtnorm\", \"plotly\")\nnao_instalados &lt;- pacotes[!pacotes %in% installed.packages()[, \"Package\"]]\nif(length(nao_instalados)) install.packages(nao_instalados, repos = \"https://cloud.r-project.org\")\n\nlibrary(mvtnorm)  # para dmvnorm\nlibrary(plotly)   # para superfície 3D interativa\n\n# --- Parâmetros da normal bivariada ---\nmu &lt;- c(0, 0)                         # vetor de médias\nSigma &lt;- matrix(c(1.0, 0.6,           # matriz de covariância com correlação\n                  0.6, 1.0), ncol=2)\n\n# --- Grade onde avaliamos a densidade ---\nx_seq &lt;- seq(-3, 3, length.out = 121)\ny_seq &lt;- seq(-3, 3, length.out = 121)\ngrade &lt;- expand.grid(x = x_seq, y = y_seq)\n\n# Avaliar densidade bivariada na grade\ndens &lt;- dmvnorm(grade, mean = mu, sigma = Sigma)\nz_mat &lt;- matrix(dens, nrow = length(x_seq), ncol = length(y_seq))\n\n# --- Superfície 3D interativa com plotly ---\np &lt;- plot_ly(x = x_seq, y = y_seq, z = ~z_mat, showscale = TRUE) %&gt;%\n  add_surface() %&gt;%\n  layout(title = \"Densidade Normal Bivariada (interativa)\",\n         scene = list(\n           xaxis = list(title = \"X1\"),\n           yaxis = list(title = \"X2\"),\n           zaxis = list(title = \"Densidade\")\n         ))\n# Aparece no Viewer do RStudio ou no navegador\np\n\n\n\n\n\n\nDefinição (Dantas (2013)) A função de distribuição de uma variável aleatória bidimensional \\((X,Y)\\) é dada por:\n\\[\nF(x,y) = P(X \\le x, Y \\le y), \\quad x \\in \\mathbb{R}, y \\in \\mathbb{R}\n\\]\nUma notação alternativa para \\(F(x,y)\\) é \\(F_{X,Y}(x,y)\\).\nNo caso de variáveis aleatórias contínuas \\(X\\) e \\(Y\\), a probabilidade do evento \\([X \\le x, Y \\le, y]\\) é igual ao valor da integral da densidade conjunta de \\((X, Y)\\) no conjunto \\(B = [X \\le x, Y \\le, y]\\)\n\\[\nF(x,y) = \\int_{-\\infty}^{x}\\int_{-\\infty}^{y} f(u,v) dudv\n\\]\nOu com uma notação alternativa:\n\\[\nF_{X,Y}(x,y) = \\int_{-\\infty}^{x}\\int_{-\\infty}^{y} f_{X,Y}(u,v) dudv\n\\]\n\n\n\nDada a densidade conjunta das variáveis \\(X\\) e \\(Y\\), podemos determinar as densidades de \\(X\\) e de \\(Y\\) isoladamente. Essas densidades são chamadas de densidades marginais \\(f_X(x)\\) e \\(f_Y(x)\\), respectivamente. Elas são obtidas através da seguinte maneira:\n\\[\n\\begin{align*}\nf_X(x) = \\int_{-\\infty}^{+\\infty} f(x,y) dy \\\\\nf_Y(y) = \\int_{-\\infty}^{+\\infty} f(x,y) dx\n\\end{align*}\n\\]\nPara o caso multivariado, por exemplo para o vetor aleatório \\((X_1, X_2, ..., X_p)\\) para obter uma marginal em específico, por exemplo, \\(X_1\\) integramos em relação à todas às demais, isto é:\n\\[\nf_{X_1}(x_1) = \\overbrace{\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty} ... \\int_{-\\infty}^{+\\infty}}^{\\text{p-1 integrais}} f(x_1, x_2, ..., x_p) dx_2dx_3...dx_p\n\\]\n\n\n\nDefinição As variáveis aleatórias \\(X\\) e \\(Y\\), cuja densidade conjunta é \\(f(x,y)\\), para \\(x,y \\in \\mathbb{R}\\), e cujas densidades marginais são denotadas \\(f_X(x)\\) e \\(f_Y(y)\\), são ditas independentes se para todo o par de valores \\((x,y)\\) tivermos\n\\[\nf(x,y) = f_X(x)f_Y(y)\n\\]\nE no caso \\(p\\)-dimensional:\n\\[\nf_{\\textbf{X}}(x_1,x_2, ..., x_p) = f_{X_1}(x_1)f_{X_2}(x_2)...f_{X_p}(x_p)\n\\]\nOu seja, se as variáveis são independentes, então a distribuição conjunta é o produto das marginais.\nLema Analogamente ao caso discreto, as variáveis \\(X\\) e \\(Y\\) com função de distribuição \\(F_{X,Y}(x,y)\\) são independentes se, e somente se\n\\[\nF_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\n\\]\nProva Ver Seção 6.3 de Magalhães (2006).\n\\(\\square\\)\n\n\n\nDefinição A distribuição condicional de \\(Y\\) dado \\(X\\) associa a cada valor \\(x\\) de \\(X\\) uma distribuição de probabilidade sobre os valores de \\(Y\\), da seguinte maneira:\n\\[\nf_{Y|X}(y|x) = \\frac{f_{X,Y}(x,y)}{f_X(x)}\n\\]\nNote que isso se refere à distribuição condicional de \\(Y\\) dado \\(X\\), estamos nos referindo ao conjunto de todas as distribuições condicionais associadas a cada um dos valores de \\(X\\).",
    "crumbs": [
      "Variáveis Aleatórias",
      "Vetores Aleatórios"
    ]
  },
  {
    "objectID": "Modelos_Lineares/paradoxo_simpson.html",
    "href": "Modelos_Lineares/paradoxo_simpson.html",
    "title": "O Caso do Paradoxo de Simpson",
    "section": "",
    "text": "Introdução\nO paradoxo é ilustrado abaixo:\n\n\nMostrar Código\n# paradoxo_simpson_unico.R\n# -------------------------------------------\n# Ilustração do Paradoxo de Simpson em um único gráfico\n# -------------------------------------------\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\nset.seed(42)\n\n# 1) Gerar dados\ngerar_grupo &lt;- function(g, n, media_x, intercepto, inclinação = 0.6, desvio_x = 4, desvio_erro = 3) {\n  x &lt;- rnorm(n, mean = media_x, sd = desvio_x)\n  y &lt;- intercepto + inclinação * x + rnorm(n, 0, desvio_erro)\n  tibble(grupo = g, x = x, y = y)\n}\n\ndados &lt;- bind_rows(\n  gerar_grupo(\"A\", 80,  10, 30),  # intercepto alto, valores baixos de x\n  gerar_grupo(\"B\", 150, 20, 20),  # intercepto médio, valores médios de x\n  gerar_grupo(\"C\", 270, 30, 10)   # intercepto baixo, valores altos de x\n)\n\n# 2) Gráfico: pontos, retas por grupo e reta geral tracejada\np &lt;- ggplot(dados, aes(x, y, color = grupo)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(method = \"lm\", se = FALSE, size = 1.1) +                # ajustes por grupo\n  geom_smooth(aes(color = NULL), method = \"lm\", se = FALSE,           # ajuste geral\n              linetype = \"dashed\", color = \"black\", size = 1.2) +\n  labs(\n    title = \"Paradoxo de Simpson em um único gráfico\",\n    subtitle = \"Preto tracejado = tendência geral (negativa)\\nLinhas coloridas = tendências dentro dos grupos (positivas)\",\n    x = \"Variável X\", y = \"Variável Y\", color = \"Grupo\"\n  ) +\n  theme_minimal(base_size = 13) +\n  theme(panel.grid.minor = element_blank())\n\nprint(p)",
    "crumbs": [
      "Confundimento",
      "O Caso do Paradoxo de Simpson"
    ]
  },
  {
    "objectID": "Int_Prob/7_funcoes_de_variaveis_aleatorias.html",
    "href": "Int_Prob/7_funcoes_de_variaveis_aleatorias.html",
    "title": "Funções de Variáveis Aleatórias",
    "section": "",
    "text": "Introdução\nNesta seção vamos abordar alguns tópicos referentes à funções de variáveis aleatórias. Por definição, uma função \\(g(.)\\) (por exemplo, uma transformação linear) aplicada à uma variável aleatória \\(X\\), isto é, \\(g(X)\\) também será uma variável aleatória. Analogamente, uma função \\(h(.)\\) (por exemplo, uma soma) aplicada em um vetor aleatório \\(\\textbf{X}\\), isto é, \\(h(\\textbf{X})\\) também será uma variável aleatória.\n\n\nFunções de Variáveis Aleatórias Discretas\nTeorema Seja \\(X\\) uma distribuição discreta com distribuição massa de probabilidade \\(f_X\\) e seja \\(Y = g(X)\\) para alguma função de \\(g\\) definida no conjunto de valores possíveis de \\(X\\). Para cada valor possível \\(y\\) de \\(Y\\), a distribuição massa \\(f_Y\\) de Y é\n\\[\nf_Y(y) = P(Y = y) = P(g(X) = y) = \\sum_{x:g(x) = y}f_X(x).\n\\]\nIsto é, devemos somar os valores da dsitribuição original de \\(x\\) nos novos pontos do novo domínio, isto é, o domínio de \\(y\\). Com alguns exemplos, isso ficará mais claro:\nExemplo Seja \\(X\\) uma V.A. discreta com a seguinte forma:\n\n\n\n\n\\(x\\)\n-2\n-1\n0\n1\n2\n\n\n\n\n\\(P(X = x)\\)\n1/5\n1/5\n1/5\n1/5\n1/5\n\n\n\n\nA distribuição de \\(Y = X + 2\\) é\n\n\n\n\n\\(y\\)\n0\n1\n2\n3\n4\n\n\n\n\n\\(P(Y = y)\\)\n1/5\n1/5\n1/5\n1/5\n1/5\n\n\n\n\nA distribuição de \\(Z = X^2\\) é\n\n\n\n\n\\(z\\)\n0\n1\n2\n\n\n\n\n\\(P(Z = z)\\)\n1/5\n2/5\n2/5\n\n\n\n\nTeorema Seja \\(X\\) uma distribuição discreta com distribuição massa de probabilidade \\(f_X\\). Seja \\(a \\in \\mathbb{R}, a \\ne 0\\) and \\(b \\in \\mathbb{R}\\)\n\n\nFunções de Variáveis Aleatórias Contínuas\n\n\nFunções de Vetores Aleatórios\nhttps://www.youtube.com/watch?v=tH-wuwvXmsk\nhttps://www.youtube.com/watch?v=hC2idx2-GME\n3.8 do degroot\nconvolucao",
    "crumbs": [
      "Variáveis Aleatórias",
      "Funções de Variáveis Aleatórias"
    ]
  },
  {
    "objectID": "Int_Prob/7_funcoes_de_variaveis_aleatorias.html#vetores-aleatórios-discretos",
    "href": "Int_Prob/7_funcoes_de_variaveis_aleatorias.html#vetores-aleatórios-discretos",
    "title": "Vetores Aleatórios",
    "section": "",
    "text": "Definição A distribuição de probabilidade do vetor aleatório \\(\\textbf{X} = (X_1, X_2, ..., X_p)\\) é uma tabela que associa a cada valor \\((x_1, x_2, ..., x_p)\\) desse vetor sua correspondente probabilidade \\(P([X_1 = x_1, X_2 = x_2, ..., X_p = x_p])\\). Ela é denominada também distribuição conjunta de \\(X_1, X_2, ..., X_p\\).\nObservemos que a notação \\([X_1 = x_1, X_2 = x_2, ..., X_p = x_p]\\) representa a intersecção dos eventos \\([X_1 = x_1], [X_2 = x_2], ..., [X_p = x_p]\\) ou seja,\n\\[\n\\begin{align*}\n[X_1 = x_1, X_2 = x_2, ..., X_p = x_p] &= \\{ \\omega: X_1(\\omega) = x_1, X_2(\\omega) = x_2, ..., X_p(\\omega) = x_p \\} = \\\\ &= \\{ \\omega: X_1(\\omega) = x_1 \\} \\cap \\{ \\omega: X_2(\\omega) = x_2 \\} \\cap ...  \\cap \\{ \\omega: X_p(\\omega) = x_p \\}\n\\end{align*}\n\\]\nUma notação alternativa para \\(P([X_1 = x_1, X_2 = x_2, ..., X_p = x_p])\\) é \\(P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\\).\nExemplo Lançamento de dois dados honestos. Seja \\(X_1\\) o valor da face do primeiro dado e \\(X_2\\) o valor da face do segundo dado a distribuição conjunta do vetor aleatório \\((X_1, X_2)\\) é dada por\n\n\n\nDistribuição Conjunta de Dois Dados Honestos\n\n\nExemplo Lançamento de um dado e uma moeda, ambos honestos. Seja \\(X\\) o valor da face do primeiro dado e \\(Y\\) a variável aleatória da moeda sendo \\(Y = 1\\) se “cara” e \\(Y = 0\\) se “coroa”. Então, a distribuição conjunta do vetor aleatório \\((X, Y)\\) é dada por\n\n\n\nDistribuição Conjunta de Um Dado e Uma Moeda Honestos\n\n\nDefinição (Dantas (2013)) A função de distribuição do par de variáveis aleatórias discretas \\((X,Y)\\) é dada por:\n\\[\nF(x,y) = P(X \\le x, Y \\le y) = \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i, Y = y_i)\n\\]\nUma notação alternativa para \\(F(x,y)\\) é \\(F_{X,Y}(x,y)\\).\n\n\n\nA distribuição marginal de uma variável aleatória específica é dada ao somarmos as probabilidades “varrendo” todo o intervalo de todas as demais variáveis do vetor aleatório. Por exemplo, assuma que em um vetor aleatório \\((X,Y)\\), \\(X\\) assume os valores \\(x_1, x_2, ..., x_n\\) enquanto \\(Y\\) assume os valores \\(y_1, y_2, ..., y_m\\). Então, a ditribuição marginal de X é dada por\n\\[\nP(X = x_i) = \\sum_{j = 1}^{m} = P(X = x_i, Y = y_j).\n\\]\nAnalogamente, a dstribuição marginal de \\(Y\\) é obtida através de\n\\[\nP(Y = y_j) = \\sum_{i = 1}^{n} = P(X = x_i, Y = y_j).\n\\]\nAbaixo, destacado em vermelho seguem as distribuições marginais do exemplo anterior:\n\n\n\nDistribuição Conjunta de Um Dado e Uma Moeda Honestos com distribuições marginais\n\n\nPara o caso multidimensional (ou seja, \\(p\\)-dimensional), o procedimento é análogo.\nSeja \\(\\textbf{X} = (X_1, X_2, ..., X_p)\\) um vetor aleatório com distribuição conjunta dada por: \\(P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\\), onde \\(x_1, x_2, ..., x_p\\), percorrem o conjunto de valores de \\(X_1, X_2, ..., X_p\\), respectivamente.\nA distribuição marginal de \\(X_1\\) é obtida calculando-se, para cada valor \\(x_1\\) de \\(X_1\\):\n\\[\nP(X_1 = x_1) = \\sum_{x_2} \\dots \\sum_{x_p} P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\n\\]\nAnalogamente, para obter a marginal de qualquer subconjunto de \\((X_1, X_2, ..., X_p)\\), fazemos o somatório percorrendo o subconjunto complementar. Por exemplo, para a marginal de \\((X_1, X_2)\\), tem-se:\n\\[\nP(X_1 = x_1, X_2 = x_2) = \\sum_{x_3} \\sum_{x_4} \\dots \\sum_{x_p} P(X_1 = x_1, X_2 = x_2, ..., X_p = x_p)\n\\]\n\n\n\nDefinição As variáveis aleatórias \\(X_1, X_2, ..., X_p\\) são ditas independentes se para todos os elementos \\(x_1, x_2, ..., x_p\\) das mesmas tivermos:\n\\[\nP(X_1 = x_1, X_2 = x_2, ..., X_p = x_p) = P(X_1 = x_1)P(X_2 = x_2)...P(X_p = x_p).\n\\]\nOu seja, se as variáveis são independentes, então a distribuição conjunta é o produto das marginais.\nLema As variáveis \\(X\\) e \\(Y\\) com função de distribuição \\(F_{X,Y}(x,y)\\) são independentes se, e somente se\n\\[\nF_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\n\\]\nProva\nIda:\n\\[\n\\begin{align*}\nF_{X,Y}(x,y) &= \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i, Y = y_i) \\overset{\\text{Definição de Indep.}}{=} \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i)P(Y = y_i) \\overset{\\text{Separa Somatórios}}{=} \\\\ &= \\underbrace{\\sum_{i: x_i \\le x}P(X = x_i)}_{F_{X}(x)}  \\underbrace{\\sum_{j: y_j \\le j}P(Y = y_i)}_{F_{Y}(y)} = F_X(x)F_Y(y)\n\\end{align*}\n\\]\nVolta:\n\\[\n\\begin{align*}\nF_X(x)F_Y(y) &= \\sum_{i: x_i \\le x}P(X = x_i) \\sum_{j: y_j \\le j}P(Y = y_i) \\overset{\\text{Combina Somatórios}}{=} \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i)P(Y = y_i) \\overset{\\text{Definição de Indep.}}{=} \\\\ &= \\sum_{i: x_i \\le x}\\sum_{j: y_j \\le j} P(X = x_i, Y = y_i) = F_{X,Y}(x,y)\n\\end{align*}\n\\]\n\\(\\square\\)\n\n\n\nDefinição A distribuição condicional de \\(Y\\) dado \\(X\\) associa a cada valor \\(x\\) de \\(X\\) uma distribuição de probabilidade sobre os valores de \\(Y\\), da seguinte maneira:\n\\[\nP(Y = x | X = x) = \\frac{P(X = x, Y = y)}{P(X = x)}\n\\]\nNote que isso se refere à distribuição condicional de \\(Y\\) dado \\(X\\), estamos nos referindo ao conjunto de todas as distribuições condicionais associadas a cada um dos valores de \\(X\\).",
    "crumbs": [
      "Variáveis Aleatórias",
      "Vetores Aleatórios"
    ]
  },
  {
    "objectID": "Int_Prob/7_funcoes_de_variaveis_aleatorias.html#vetores-aleatórios-contínuos",
    "href": "Int_Prob/7_funcoes_de_variaveis_aleatorias.html#vetores-aleatórios-contínuos",
    "title": "Vetores Aleatórios",
    "section": "",
    "text": "Definição Uma função \\(f(x,y)\\) definida para \\(- \\infty &lt; x &lt; + \\infty\\), \\(- \\infty &lt; y &lt; + \\infty\\), não-negativa e satisfazendo a condição\n\\[\n\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty}f(x,y)dxdy=1\n\\]\né denominada uma função densidade de probabilidade da variável aleatória bidimensional \\((X,Y)\\) se para todo o subconjunto \\(B\\) de pontos do \\(\\mathbb{R}^2\\) tivermos:\n\\[\nP((X,Y) \\in B) = \\int\\int_{B}f(x,y)dxdy\n\\]\nSegundo Dantas (2013), a interpretação da função densidade de probabilidade no caso bidimensional é a seguinte: seja \\((x,y)\\) um ponto do plano e consideremos um retângulo de lados \\(\\Delta x\\) e \\(\\Delta y\\) construído a partir do ponto \\((x,y)\\). A probabilidade de que \\((X,Y)\\) pertença a esse retângulo é aproximadamente igual ao volume do paralelepípedo de lados \\(\\Delta x\\) e \\(\\Delta y\\) e cuja altura é \\(f(x,y)\\), ou seja,\n\n\n\nConstrução de probabilidade de uma distribuição conjunta bidimensional (Extraído de Dantas (2013))\n\n\nAbaixo, seguem alguns exemplos visuais tridimensionais:\nExemplo Função bidimensional com área destacada entre dois valores de cada variável:\nSuponha a densidade\n\\[\nf(x,y) = 9x^2y^2, \\quad 0 \\le x,y \\le 1,\n\\]\nSuponha o cálculo de probabilidade do tipo:\n\\[\nP(c \\le X \\le d, \\; e \\le Y \\le f) \\;=\\;\n\\int_c^d \\int_e^f 9x^2 y^2 \\, dy \\, dx.\n\\]\nEssa integral tem solução fechada:\n\\[\nP = (d^3 - c^3)\\,(f^3 - e^3).\n\\]\nVamos calcular e ilustrar o valor da probabilidade \\(P(0.2 \\le X \\le 0.6, 0.3 \\le Y \\le 0.8)\\):\n\n\nMostrar Código\n# Distribuição montanhosa f(x,y) = 9x^2 y^2\nif (!requireNamespace(\"plotly\", quietly = TRUE)) install.packages(\"plotly\")\nif (!requireNamespace(\"ggplot2\", quietly = TRUE)) install.packages(\"ggplot2\")\n\nlibrary(plotly)\nlibrary(ggplot2)\n\n# --- Intervalos ---\nc1 &lt;- 0.2; d1 &lt;- 0.6   # intervalo para X\ne1 &lt;- 0.3; f1 &lt;- 0.8   # intervalo para Y\n\n# Função densidade\nf_xy &lt;- function(x, y) 9 * x^2 * y^2\n\n# Probabilidade analítica\nprob_interval &lt;- (d1^3 - c1^3) * (f1^3 - e1^3)\ncat(sprintf(\"Probabilidade P(%.2f &lt;= X &lt;= %.2f, %.2f &lt;= Y &lt;= %.2f) = %.4f\\n\",\n            c1, d1, e1, f1, prob_interval))\n\n\nProbabilidade P(0.20 &lt;= X &lt;= 0.60, 0.30 &lt;= Y &lt;= 0.80) = 0.1009\n\n\n\n\nMostrar Código\n# --- Grid para visualização ---\nx_seq &lt;- seq(0, 1, length.out = 80)\ny_seq &lt;- seq(0, 1, length.out = 80)\nZ &lt;- outer(x_seq, y_seq, f_xy)\n\n# Máscara região do intervalo\nmask_region &lt;- outer(x_seq, y_seq, function(x, y) (x &gt;= c1 & x &lt;= d1 & y &gt;= e1 & y &lt;= f1))\n\n# --- Gráfico 3D ---\np3d &lt;- plot_ly(showscale = FALSE) %&gt;%\n  add_surface(x = x_seq, y = y_seq, z = Z,\n              opacity = 0.6, name = \"densidade\") %&gt;%\n  add_surface(x = x_seq, y = y_seq,\n              z = ifelse(mask_region, Z, NA),\n              opacity = 1.0, name = \"região do intervalo\") %&gt;%\n  layout(title = \"Distribuição f(x,y) = 9x²y² com intervalo destacado\",\n         scene = list(xaxis = list(title = \"X\"),\n                      yaxis = list(title = \"Y\"),\n                      zaxis = list(title = \"densidade\")))\n\np3d\n\n\n\n\n\n\nExemplo Normal Bivariada\n\n\nMostrar Código\n# --- Dependências (instalar se não estiverem disponíveis) ---\npacotes &lt;- c(\"mvtnorm\", \"plotly\")\nnao_instalados &lt;- pacotes[!pacotes %in% installed.packages()[, \"Package\"]]\nif(length(nao_instalados)) install.packages(nao_instalados, repos = \"https://cloud.r-project.org\")\n\nlibrary(mvtnorm)  # para dmvnorm\nlibrary(plotly)   # para superfície 3D interativa\n\n# --- Parâmetros da normal bivariada ---\nmu &lt;- c(0, 0)                         # vetor de médias\nSigma &lt;- matrix(c(1.0, 0.6,           # matriz de covariância com correlação\n                  0.6, 1.0), ncol=2)\n\n# --- Grade onde avaliamos a densidade ---\nx_seq &lt;- seq(-3, 3, length.out = 121)\ny_seq &lt;- seq(-3, 3, length.out = 121)\ngrade &lt;- expand.grid(x = x_seq, y = y_seq)\n\n# Avaliar densidade bivariada na grade\ndens &lt;- dmvnorm(grade, mean = mu, sigma = Sigma)\nz_mat &lt;- matrix(dens, nrow = length(x_seq), ncol = length(y_seq))\n\n# --- Superfície 3D interativa com plotly ---\np &lt;- plot_ly(x = x_seq, y = y_seq, z = ~z_mat, showscale = TRUE) %&gt;%\n  add_surface() %&gt;%\n  layout(title = \"Densidade Normal Bivariada (interativa)\",\n         scene = list(\n           xaxis = list(title = \"X1\"),\n           yaxis = list(title = \"X2\"),\n           zaxis = list(title = \"Densidade\")\n         ))\n# Aparece no Viewer do RStudio ou no navegador\np\n\n\n\n\n\n\nDefinição (Dantas (2013)) A função de distribuição de uma variável aleatória bidimensional \\((X,Y)\\) é dada por:\n\\[\nF(x,y) = P(X \\le x, Y \\le y), \\quad x \\in \\mathbb{R}, y \\in \\mathbb{R}\n\\]\nUma notação alternativa para \\(F(x,y)\\) é \\(F_{X,Y}(x,y)\\).\nNo caso de variáveis aleatórias contínuas \\(X\\) e \\(Y\\), a probabilidade do evento \\([X \\le x, Y \\le, y]\\) é igual ao valor da integral da densidade conjunta de \\((X, Y)\\) no conjunto \\(B = [X \\le x, Y \\le, y]\\)\n\\[\nF(x,y) = \\int_{-\\infty}^{x}\\int_{-\\infty}^{y} f(u,v) dudv\n\\]\nOu com uma notação alternativa:\n\\[\nF_{X,Y}(x,y) = \\int_{-\\infty}^{x}\\int_{-\\infty}^{y} f_{X,Y}(u,v) dudv\n\\]\n\n\n\nDada a densidade conjunta das variáveis \\(X\\) e \\(Y\\), podemos determinar as densidades de \\(X\\) e de \\(Y\\) isoladamente. Essas densidades são chamadas de densidades marginais \\(f_X(x)\\) e \\(f_Y(x)\\), respectivamente. Elas são obtidas através da seguinte maneira:\n\\[\n\\begin{align*}\nf_X(x) = \\int_{-\\infty}^{+\\infty} f(x,y) dy \\\\\nf_Y(y) = \\int_{-\\infty}^{+\\infty} f(x,y) dx\n\\end{align*}\n\\]\nPara o caso multivariado, por exemplo para o vetor aleatório \\((X_1, X_2, ..., X_p)\\) para obter uma marginal em específico, por exemplo, \\(X_1\\) integramos em relação à todas às demais, isto é:\n\\[\nf_{X_1}(x_1) = \\overbrace{\\int_{-\\infty}^{+\\infty}\\int_{-\\infty}^{+\\infty} ... \\int_{-\\infty}^{+\\infty}}^{\\text{p-1 integrais}} f(x_1, x_2, ..., x_p) dx_2dx_3...dx_p\n\\]\n\n\n\nDefinição As variáveis aleatórias \\(X\\) e \\(Y\\), cuja densidade conjunta é \\(f(x,y)\\), para \\(x,y \\in \\mathbb{R}\\), e cujas densidades marginais são denotadas \\(f_X(x)\\) e \\(f_Y(y)\\), são ditas independentes se para todo o par de valores \\((x,y)\\) tivermos\n\\[\nf(x,y) = f_X(x)f_Y(y)\n\\]\nE no caso \\(p\\)-dimensional:\n\\[\nf_{\\textbf{X}}(x_1,x_2, ..., x_p) = f_{X_1}(x_1)f_{X_2}(x_2)...f_{X_p}(x_p)\n\\]\nOu seja, se as variáveis são independentes, então a distribuição conjunta é o produto das marginais.\nLema Analogamente ao caso discreto, as variáveis \\(X\\) e \\(Y\\) com função de distribuição \\(F_{X,Y}(x,y)\\) são independentes se, e somente se\n\\[\nF_{X,Y}(x,y) = F_{X}(x)F_{Y}(y)\n\\]\nProva Ver Seção 6.3 de Magalhães (2006).\n\\(\\square\\)\n\n\n\nDefinição A distribuição condicional de \\(Y\\) dado \\(X\\) associa a cada valor \\(x\\) de \\(X\\) uma distribuição de probabilidade sobre os valores de \\(Y\\), da seguinte maneira:\n\\[\nf_{Y|X}(y|x) = \\frac{f_{X,Y}(x,y)}{f_X(x)}\n\\]\nNote que isso se refere à distribuição condicional de \\(Y\\) dado \\(X\\), estamos nos referindo ao conjunto de todas as distribuições condicionais associadas a cada um dos valores de \\(X\\).",
    "crumbs": [
      "Variáveis Aleatórias",
      "Vetores Aleatórios"
    ]
  }
]