[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Apresentação",
    "section": "",
    "text": "Este é um website baseado no Quarto da empresa Posit.\nTemplates úteis: https://drganghe.github.io/quarto-academic-site-examples.html\nSite oficial do Quarto: https://quarto.org/docs/websites.\nPara rodar códigos em Python, é necessário instalar as bibliotecas usando o reticulate e ter o jupyter instalado.\nExemplo:\nreticulate::py_require(\"matplotlib\")\n\nAlém disso, cuidado ao setar engine jupyter que daí os códigos R não serão rodados.\nEngine Conflicts:\n\nKnitr vs. Jupyter: If you explicitly set the engine to jupyter in your YAML, R code chunks will not be executed, and only Python (or the kernel’s language) will run. For mixed R and Python, engine: knitr is typically used, relying on reticulate for Python execution.",
    "crumbs": [
      "Sobre"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Sobre",
    "section": "",
    "text": "This is a Quarto website.\nTemplates úteis: https://drganghe.github.io/quarto-academic-site-examples.html\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\nTo add a plotly graph:\nytd library(plotly) fig &lt;- plot_ly(data = iris, x = ~Sepal.Length, y = ~Petal.Length) fig}"
  },
  {
    "objectID": "LGN.html",
    "href": "LGN.html",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "Este é uma página da LGN."
  },
  {
    "objectID": "TCL.html",
    "href": "TCL.html",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Este é uma página do TCL."
  },
  {
    "objectID": "Probabilidade/TCL.html",
    "href": "Probabilidade/TCL.html",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "O Teorema Central do Limite (TCL) é um dos resultados mais famosos da Teoria da Probabilidade.\nSejam \\(X_1, X_2, ...\\) variáveis aleatórias independentes e identicamente distribuídas (\\(iid\\)) com média e variância existentes e finitas. Isto é:\n\\(-\\infty &lt; \\mu &lt; +\\infty\\)\n\\(0 &lt; \\sigma^2 &lt; +\\infty\\)\nAlém disso, defina \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n}\\).\n\n\nPela Lei dos Grandes Números, sabemos que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\), mas a qual taxa? Como que é a distribuição dessa quantidade?\nPodemos reescrever a quantidade acima como sendo \\(\\bar{X} - \\mu \\xrightarrow{n \\rightarrow + \\infty} 0\\)",
    "crumbs": [
      "Probabilidade",
      "Teorema Central do Limite"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html",
    "href": "Probabilidade/LGN.html",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei dos Grandes Números (LGN) é um dos resultados mais famosos da Teoria da Probabilidade.\nSejam \\(X_1, X_2, ...\\) variáveis aleatórias independentes e identicamente distribuídas (\\(iid\\)) com média e variância existentes e finitas. Isto é:\n\\(-\\infty &lt; \\mu &lt; +\\infty\\)\n\\(0 &lt; \\sigma^2 &lt; +\\infty\\)\nA primeira condição de finitude das médias é necessária para a Lei Forte dos Grandes Números.\nAlém disso, defina \\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n}\\).\n\n\nA Lei Forte estabelece que:\n\\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\(P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\)\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).\n\n\n\nA Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\(P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\)\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\(P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).\n\n\n\nÉ intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\(Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\)\nentão,\n\\(Lei\\ Forte \\implies Lei\\ Fraca\\)\nO contrário não vale para nenhuma das duas afirmativas acima.\n\n\n\nSuponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\(X_i \\overset{iid}{\\sim}Bernoulli(p)\\)\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\)\nEste resultado mostra que a medida que o jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy.\n\n\n\nNo R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(10, 5))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#seção-2",
    "href": "Probabilidade/LGN.html#seção-2",
    "title": "Lei dos Grandes Números",
    "section": "Seção 2",
    "text": "Seção 2\nColocando uma equação:\n\\(E = mc^2\\)\nE colocando um ggplot2:\n\n\nMostrar Código\n# Definindo parâmetros\nset.seed(123)           # Para reprodutibilidade\nn_lancamentos &lt;- 1000  # Número total de lançamentos\n\n# Simulando lançamentos: 1 representa \"cara\", 0 representa \"coroa\"\nresultados &lt;- sample(c(0, 1), size = n_lancamentos, replace = TRUE)\n\n# Calculando a média acumulada (frequência relativa de \"cara\")\nmedia_acumulada &lt;- cumsum(resultados) / (1:n_lancamentos)\n\n# Valor esperado teórico\nvalor_esperado &lt;- 0.5\n\n# Plotando o gráfico\nplot(media_acumulada, type = \"l\", col = \"blue\", lwd = 2,\n     xlab = \"Número de lançamentos\", ylab = \"Frequência relativa de 'cara'\",\n     main = \"Lei dos Grandes Números - Moeda Honesta\")\nabline(h = valor_esperado, col = \"red\", lty = 2, lwd = 2)\nlegend(\"bottomright\", legend = c(\"Frequência relativa\", \"Valor esperado (0.5)\"),\n       col = c(\"blue\", \"red\"), lty = c(1, 2), lwd = 2)\n\n\n\n\n\n\n\n\n\n\nSeção 3\nEla tem também um table of contents.\nEste é uma página da LGN citando .\n\n\nLinks Úteis:\nAula de Harvard de Lei dos Grandes Números e Teorema Central do Limite\nPágina da Wikipedia da Lei dos Grandes Números",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#lei-forte-dos-grande-números",
    "href": "Probabilidade/LGN.html#lei-forte-dos-grande-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Forte estabelece que:\n\\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\(P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\)\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#lei-fraca-dos-grande-números",
    "href": "Probabilidade/LGN.html#lei-fraca-dos-grande-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\(P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\)\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\(P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#exemplo-computacional",
    "href": "Probabilidade/LGN.html#exemplo-computacional",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "No R:\n\n\nMostrar Código\n# Carregar as bibliotecas necessárias\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Definir o número de lançamentos\nn &lt;- 500\n\n# Simular lançamentos de uma moeda honesta\nset.seed(123) # Para reprodutibilidade\nlancamentos &lt;- sample(c(\"Cara\", \"Coroa\"), n, replace = TRUE)\n\n# Calcular a proporção acumulada de caras\ndados &lt;- data.frame(lancamentos) %&gt;%\n  mutate(\n    n = row_number(),\n    proporcao_cara = cumsum(lancamentos == \"Cara\") / n\n  )\n\n# Criar o gráfico\nggplot(dados, aes(x = n, y = proporcao_cara)) +\n  geom_line(color = \"blue\") +\n  labs(title = \"Lei dos Grandes Números: Lançamento de uma Moeda Honesta\",\n       x = \"Número de Lançamentos\",\n       y = \"Proporção de Caras\") +\n  geom_hline(yintercept = 0.5, linetype = \"dashed\", color = \"red\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nNo Python:\n\n\nMostrar Código\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Definindo o número de lançamentos\nn = 500\n\n# Simulando lançamentos de uma moeda honesta\nnp.random.seed(123)  # Para reprodutibilidade\nlancamentos = np.random.choice(['Cara', 'Coroa'], size=n)\n\n# Calculando a proporção acumulada de caras\nproporcao_cara = np.cumsum(lancamentos == 'Cara') / np.arange(1, n + 1)\n\n# Criando o gráfico\nplt.figure(figsize=(10, 5))\nplt.plot(proporcao_cara, color='blue', label='Proporção de Caras')\nplt.axhline(y=0.5, color='red', linestyle='--', label='Proporção Esperada (0.5)')\nplt.title('Lei dos Grandes Números: Lançamento de uma Moeda Honesta')\nplt.xlabel('Número de Lançamentos')\nplt.ylabel('Proporção de Caras')\nplt.legend()\nplt.grid()\nplt.show()",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#relação-entre-leis-e-convergências",
    "href": "Probabilidade/LGN.html#relação-entre-leis-e-convergências",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "É intuitivo pensar afirmarmos que duas quantidades são iguais é mais “forte” do que dizer que essas duas quantidades são “altamente prováveis de estarem próximas”. Ora, se uma coisa é igual à outra, isso implica de que elas também são próximas. Tendo em vista que a Lei Forte dos Grandes Números representa a convergência quase certa e a Lei Fraca representa a convergência em probabilidade, temos que se\n\\(Convergência\\ Quase\\ Certa \\implies Convergência\\ em\\ Probabilidade\\)\nentão,\n\\(Lei\\ Forte \\implies Lei\\ Fraca\\)\nO contrário não vale para nenhuma das duas afirmativas acima.",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#exemplo-o-caso-bernoulli",
    "href": "Probabilidade/LGN.html#exemplo-o-caso-bernoulli",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "Suponha uma sequência independente de lançamentos de uma moeda honesta e a variável aleatória \\(X_i = 1\\) se cara e \\(X_i = 0\\) se coroa. Ou seja,\n\\(X_i \\overset{iid}{\\sim}Bernoulli(p)\\)\nonde \\(p = 0,5\\). Então, pela Lei Forte dos Grandes Números:\n\\(\\bar{X} = \\frac{\\sum_{i=1}^{n}{X_i}}{n} \\xrightarrow{n \\rightarrow + \\infty} p\\)\nEste resultado mostra que a medida que o jogarmos a moeda infinitas vezes, iremos convergir para um cenário em que metade dos lançamentos serão caras e metade serão coroas. Note que o resultado vale quando \\(n \\rightarrow + \\infty\\), ou seja, ele não estabelece nada em uma quantidade finita de lançamentos onde pode existir variabilidade. Por exemplo, mesmo que seja altamente improvável que nos primeiros 100 lançamentos todos os resultados sejam a face “Cara”, não existe nada matematicamente que estabeleça que isso seja impossível. No entanto, no limite do infinito as quantidades iniciais serão “engolidas” pela LGN. Para uma discussão mais aprofundada sobre esse tema recomenda-se uma leitura sobre o Gambler’s Fallacy.",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#lei-forte-dos-grandes-números",
    "href": "Probabilidade/LGN.html#lei-forte-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Forte estabelece que:\n\\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) com probabilidade 1.\nObserve que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\) é um evento. Logo, a Lei Forte poderia ser reescrita com uma notação probabilística alternativa:\n\\(P\\left(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu \\right) = 1\\)\nEste resultado estabelece que \\(\\bar{X}\\) converge quase certamente para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, no infinito, \\(\\bar{X}\\) e \\(\\mu\\) serão iguais. Ou seja, é uma convergência pontual do valor de uma variável aleatória para uma constante (a média populacional).\nA prova deste teorema implica em provar que o evento acima é um evento de probabilidade 1, o que exige maior formalidade matemática fazendo uso do Lema de Borel-Cantelli.\nProva. Ver Cáp. 5 de James (2023).",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/LGN.html#lei-fraca-dos-grandes-números",
    "href": "Probabilidade/LGN.html#lei-fraca-dos-grandes-números",
    "title": "Lei dos Grandes Números",
    "section": "",
    "text": "A Lei Fraca estabelece que \\(\\forall \\varepsilon &gt; 0\\), então:\n\\(P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\xrightarrow{n \\rightarrow + \\infty} 0\\)\nEste resultado estabelece que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\).\nProva. A prova faz uso da Desigualdade de Chebyshev:\n\\(P\\left(\\left| \\bar{X} - \\mu \\right| \\ge \\varepsilon \\right) \\overset{\\text{Des. Cheb.}}{\\le} \\frac{Var(\\bar{X})}{\\varepsilon^2} = \\frac{Var\\left(\\frac{\\sum_{i=1}^{n}{X_i}}{n}\\right)}{\\varepsilon^2} \\overset{\\text{Prop. da Constante}}{=} \\frac{Var(\\sum_{i=1}^{n}{X_i})}{n^2\\varepsilon^2} \\overset{\\text{Indep.}}{=} \\frac{\\sum_{i=1}^{n}{Var(X_i)}}{n^2\\varepsilon^2} \\overset{\\text{Ident. Dist.}}{=} \\frac{n\\sigma^2}{n^2\\varepsilon^2} = \\frac{\\sigma^2}{n\\varepsilon^2} \\xrightarrow{n \\rightarrow + \\infty} 0\\)\nEste resultado ilustra que \\(\\bar{X}\\) converge em probabilidade para \\(\\mu\\). Podemos interpretar esse resultado como sendo à medida que n cresce, é extremamente improvável que a diferença entre \\(\\bar{X}\\) e \\(\\mu\\) seja maior que \\(\\varepsilon\\).",
    "crumbs": [
      "Probabilidade",
      "Lei dos Grandes Números"
    ]
  },
  {
    "objectID": "Probabilidade/TCL.html#teorema-central-do-limite",
    "href": "Probabilidade/TCL.html#teorema-central-do-limite",
    "title": "Teorema Central do Limite",
    "section": "",
    "text": "Pela Lei dos Grandes Números, sabemos que \\(\\bar{X} \\xrightarrow{n \\rightarrow + \\infty} \\mu\\), mas a qual taxa? Como que é a distribuição dessa quantidade?\nPodemos reescrever a quantidade acima como sendo \\(\\bar{X} - \\mu \\xrightarrow{n \\rightarrow + \\infty} 0\\)",
    "crumbs": [
      "Probabilidade",
      "Teorema Central do Limite"
    ]
  }
]